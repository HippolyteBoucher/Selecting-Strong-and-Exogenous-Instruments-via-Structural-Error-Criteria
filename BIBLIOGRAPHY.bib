
@article{kleibergen_pivotal_2002,
	title = {Pivotal {Statistics} for {Testing} {Structural} {Parameters} in {Instrumental} {Variables} {Regression}},
	volume = {70},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/1468-0262.00353},
	doi = {10.1111/1468-0262.00353},
	language = {en},
	number = {5},
	urldate = {2019-04-25},
	journal = {Econometrica},
	author = {Kleibergen, Frank},
	month = sep,
	year = {2002},
	pages = {1781--1803},
	file = {Kleibergen - 2002 - Pivotal Statistics for Testing Structural Paramete.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\627GWE3X\\Kleibergen - 2002 - Pivotal Statistics for Testing Structural Paramete.pdf:application/pdf},
}

@unpublished{gautier:hal-00591732,
  TITLE = {{High-dimensional instrumental variables regression and confidence sets}},
  AUTHOR = {Gautier, Eric and Rose, Christiern},
  URL = {https://hal.archives-ouvertes.fr/hal-00591732},
  YEAR = {2021},
  MONTH = Aug,
  KEYWORDS = {Bias correction ; Robustness to identification ; Partial identification ; Unknown variance ; Variable selection ; Instrumental variables ; Sparsity ; Endogeneity ; Confidence intervals},
  PDF = {https://hal.archives-ouvertes.fr/hal-00591732v7/file/STIV%205th%20resubmission.pdf},
  HAL_ID = {hal-00591732},
  HAL_VERSION = {v7},
}
@article{moreira_conditional_2003,
	title = {A {Conditional} {Likelihood} {Ratio} {Test} for {Structural} {Models}},
	volume = {71},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/1468-0262.00438},
	doi = {10.1111/1468-0262.00438},
	language = {en},
	number = {4},
	urldate = {2019-04-25},
	journal = {Econometrica},
	author = {Moreira, Marcelo J.},
	month = jul,
	year = {2003},
	pages = {1027--1048},
	file = {Moreira - 2003 - A Conditional Likelihood Ratio Test for Structural.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\6FCIUDMG\\Moreira - 2003 - A Conditional Likelihood Ratio Test for Structural.pdf:application/pdf},
}

@article{antoine_identication-robust_2019,
  doi = {10.1016/j.jeconom.2022.01.011},
  url = {https://doi.org/10.1016/j.jeconom.2022.01.011},
  year = {2022},
  month = mar,
  publisher = {Elsevier {BV}},
  author = {Bertille Antoine and Pascal Lavergne},
  title = {Identification-robust nonparametric inference in a linear {IV} model},
  journal = {Journal of Econometrics}
}

@article{escanciano_optimal_2019,
	title = {Optimal {Linear} {Instrumental} {Variables} {Approximations}},
	abstract = {Ordinary least squares provides the optimal linear approximation to the true regression function under misspeciﬁcation. This paper investigates the Instrumental Variables (IV) version of this problem. The resulting population parameter is called the Optimal Linear IV Approximation (OLIVA). This paper shows that a necessary condition for regular identiﬁcation of the OLIVA is also suﬃcient for existence of an IV estimand in a linear IV model. The necessary condition holds for the important case of a binary endogenous treatment, leading also to a LATE interpretation with positive weights. The instrument in the IV estimand is unknown and is estimated in a ﬁrst step. A Two-Step IV (TSIV) estimator is proposed. We establish the asymptotic normality of a debiased TSIV estimator based on locally robust moments. The TSIV estimator does not require neither completeness nor identiﬁcation of the instrument. As a by-product of our analysis, we robustify the classical Hausman test for exogeneity against misspeciﬁcation of the linear model. Monte Carlo simulations suggest excellent ﬁnite sample performance for the proposed inferences.},
	language = {en},
	journal = {Working Paper},
	author = {Escanciano, Juan Carlos and Li, Wei},
	year = {2019},
	pages = {33},
	file = {Escanciano et Li - Optimal Linear Instrumental Variables Approximatio.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\LYJQGCB6\\Escanciano et Li - Optimal Linear Instrumental Variables Approximatio.pdf:application/pdf},
}

@article{boucher_simple_2019,
	title = {A {Simple} {Procedure} for {Identiﬁcation}-{Robust} {Nonparametric} {Inference} in a {Linear} {IV} {Model}},
	language = {en},
	author = {Boucher, Hippolyte},
	year = {2019},
	pages = {37},
	file = {Boucher - A Simple Procedure for Identiﬁcation-Robust Nonpar.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\QIY8J9KE\\Boucher - A Simple Procedure for Identiﬁcation-Robust Nonpar.pdf:application/pdf},
}

@article{moreira_tests_2001,
	title = {Tests with correct size when instruments can be arbitrarily weak},
	volume = {152},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407609000190},
	doi = {10.1016/j.jeconom.2009.01.012},
	abstract = {Classical exponential-family statistical theory is employed to characterize the class of exactly similar tests for a structural coeﬃcient in a simultaneous equations model with normal errors and known reduced-form covariance matrix. A score test and a variant of the Anderson-Rubin test are shown to be members of the class. When identiﬁcation is strong, the power surface for the score test is generally close to the power envelope for the class of similar tests. However, when identiﬁcation is weak, the score test no longer has power close to the envelope. Dropping the restrictive assumptions of normality and known covariance matrix, the results are shown to remain valid in large samples even in the presence of weak instruments.},
	language = {en},
	number = {2},
	urldate = {2019-04-25},
	journal = {Journal of Econometrics},
	author = {Moreira, Marcelo J.},
	month = oct,
	year = {2001},
	pages = {131--140},
	file = {Moreira - 2009 - Tests with correct size when instruments can be ar.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\7HKXDCYF\\Moreira - 2009 - Tests with correct size when instruments can be ar.pdf:application/pdf},
}

@article{boucher_master_2018,
	title = {Master 2 {Memoir} - {A} {Simple} {Procedure} for {Identification}-{Robust} {Nonparametric} {Inference} in a {Linear} {IV} {Model}},
	language = {en},
	author = {Boucher, Hippolyte},
	year = {2018},
	pages = {17},
	file = {Boucher - Master 2 Memoir - A Simple Procedure for Identific.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\4BQTWFC3\\Boucher - Master 2 Memoir - A Simple Procedure for Identific.pdf:application/pdf},
}

@techreport{mogstad_identification_2019,
	address = {Cambridge, MA},
	title = {Identification of {Causal} {Effects} with {Multiple} {Instruments}: {Problems} and {Some} {Solutions}},
	shorttitle = {Identification of {Causal} {Effects} with {Multiple} {Instruments}},
	url = {http://www.nber.org/papers/w25691.pdf},
	abstract = {Empirical researchers often combine multiple instruments for a single treatment using two stage least squares (2SLS). When treatment eﬀects are heterogeneous, a common justiﬁcation for including multiple instruments is that the 2SLS estimand can still be interpreted as a positively-weighted average of local average treatment eﬀects (LATEs). This justiﬁcation requires the well-known monotonicity condition. However, we show that with more than one instrument, this condition can only be satisﬁed if choice behavior is eﬀectively homogenous. Based on this ﬁnding, we consider the use of multiple instruments under a weaker, partial monotonicity condition. This condition is implied by standard choice theory and allows for richer heterogeneity. First, we show that the weaker partial monotonicity condition can still suﬃce for the 2SLS estimand to be a positively-weighted average of LATEs. We characterize a simple suﬃcient and necessary condition that empirical researchers can check to ensure positive weights. Second, we develop a general method for using multiple instruments to identify a wide range of causal parameters other than LATEs. The method allows researchers to combine multiple instruments to obtain more informative empirical conclusions than one would obtain by using each instrument separately.},
	language = {en},
	number = {w25691},
	urldate = {2019-05-06},
	institution = {National Bureau of Economic Research},
	author = {Mogstad, Magne and Torgovitsky, Alexander and Walters, Christopher},
	month = mar,
	year = {2019},
	doi = {10.3386/w25691},
	pages = {w25691},
	file = {Mogstad et al. - 2019 - Identification of Causal Effects with Multiple Ins.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\S5ZYVT3A\\Mogstad et al. - 2019 - Identification of Causal Effects with Multiple Ins.pdf:application/pdf},
}

@article{hansen_instrumental_2014,
	title = {Instrumental variables estimation with many weak instruments using regularized {JIVE}},
	volume = {182},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407614000918},
	doi = {10.1016/j.jeconom.2014.04.022},
	abstract = {We consider instrumental variables regression in models where the number of available instruments may be larger than the sample size and consistent model selection in the first stage may not be possible. Such a situation may arise when there are many weak instruments. With many weak instruments, existing approaches to first-stage regularization can lead to a large bias relative to standard errors. We propose a jackknife instrumental variables estimator (JIVE) with regularization at each jackknife iteration that helps alleviate this bias. We derive the limiting behavior for a ridge-regularized JIV estimator (RJIVE), verifying that the RJIVE is consistent and asymptotically normal under conditions which allow for more instruments than observations and do not require consistent model selection. We provide simulation results that demonstrate the proposed RJIVE performs favorably in terms of size of tests and risk properties relative to other many-weak instrument estimation strategies in high-dimensional settings. We also apply the RJIVE to the Angrist and Krueger (1991) example where it performs favorably relative to other manyinstrument robust procedures.},
	language = {en},
	number = {2},
	urldate = {2019-05-13},
	journal = {Journal of Econometrics},
	author = {Hansen, Christian and Kozbur, Damian},
	month = oct,
	year = {2014},
	pages = {290--308},
	file = {Hansen et Kozbur - 2014 - Instrumental variables estimation with many weak i.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\V9KTH8L9\\Hansen et Kozbur - 2014 - Instrumental variables estimation with many weak i.pdf:application/pdf},
}

@article{rajkumar_ridge_2019,
	title = {Ridge regularization for {Mean} {Squared} {Error} {Reduction} in {Regression} with {Weak} {Instruments}},
	url = {http://arxiv.org/abs/1904.08580},
	abstract = {In this paper, I show that classic two-stage least squares (2SLS) estimates are highly unstable with weak instruments. I propose a ridge estimator (ridge IV) and show that it is asymptotically normal even with weak instruments, whereas 2SLS is severely distorted and unbounded. I motivate the ridge IV estimator as a convex optimization problem with a GMM objective function and an L2 penalty. I show that ridge IV leads to sizable mean squared error reductions theoretically and validate these results in a simulation study inspired by data designs of papers published in the American Economic Review.},
	language = {en},
	urldate = {2019-05-13},
	journal = {arXiv:1904.08580 [econ, math, stat]},
	author = {Rajkumar, Karthik},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.08580},
	keywords = {Mathematics - Statistics Theory, Economics - Econometrics},
	annote = {Comment: 20 pages},
	file = {Rajkumar - 2019 - Ridge regularization for Mean Squared Error Reduct.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ZLG3PC4A\\Rajkumar - 2019 - Ridge regularization for Mean Squared Error Reduct.pdf:application/pdf},
}

@article{guggenberger_more_2019,
	title = {A more powerful subvector {Anderson} {Rubin} test in linear instrumental variables regression},
	volume = {10},
	issn = {1759-7323, 1759-7331},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.3982/QE1116},
	doi = {10.3982/QE1116},
	language = {en},
	number = {2},
	urldate = {2019-05-17},
	journal = {Quantitative Economics},
	author = {Guggenberger, Patrik and Kleibergen, Frank and Mavroeidis, Sophocles},
	month = may,
	year = {2019},
	pages = {487--526},
	file = {Guggenberger et al. - 2019 - A more powerful subvector Anderson Rubin test in l.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\Q3E8TWRA\\Guggenberger et al. - 2019 - A more powerful subvector Anderson Rubin test in l.pdf:application/pdf},
}

@article{guggenberger_asymptotic_2012,
	title = {On the {Asymptotic} {Sizes} of {Subset} {Anderson}-{Rubin} and {Lagrange} {Multiplier} {Tests} in {Linear} {Instrumental} {Variables} {Regression}},
	volume = {80},
	issn = {0012-9682},
	url = {http://doi.wiley.com/10.3982/ECTA8953},
	doi = {10.3982/ECTA8953},
	abstract = {We consider tests of a simple null hypothesis on a subset of the coefﬁcients of the exogenous and endogenous regressors in a single-equation linear instrumental variables regression model with potentially weak identiﬁcation. Existing methods of subset inference (i) rely on the assumption that the parameters not under test are strongly identiﬁed, or (ii) are based on projection-type arguments. We show that, under homoskedasticity, the subset Anderson and Rubin (1949) test that replaces unknown parameters by limited information maximum likelihood estimates has correct asymptotic size without imposing additional identiﬁcation assumptions, but that the corresponding subset Lagrange multiplier test is size distorted asymptotically.},
	language = {en},
	number = {6},
	urldate = {2019-05-17},
	journal = {Econometrica},
	author = {Guggenberger, Patrik and Kleibergen, Frank and Mavroeidis, Sophocles and Chen, Linchun},
	year = {2012},
	pages = {2649--2666},
	file = {2012 - On the Asymptotic Sizes of Subset Anderson-Rubin a.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\RKFQ9NZ7\\2012 - On the Asymptotic Sizes of Subset Anderson-Rubin a.pdf:application/pdf},
}

@article{anderson_estimation_1949,
	title = {Estimation of the {Parameters} of a {Single} {Equation} in a {Complete} {System} of {Stochastic} {Equations}},
	volume = {20},
	number = {1},
	journal = {The Annals of Mathematical Statistics},
	author = {Anderson, T. W. and Rubin, Herman},
	year = {1949},
	pages = {46--63},
	file = {euclid.aoms.1177730090.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ZA4UBHHU\\euclid.aoms.1177730090.pdf:application/pdf},
}

@article{singh_kernel_2019,
	title = {Kernel {Instrumental} {Variable} {Regression}},
	url = {http://arxiv.org/abs/1906.00232},
	abstract = {Instrumental variable regression is a strategy for learning causal relationships in observational data. If measurements of input X and output Y are confounded, the causal relationship can nonetheless be identiﬁed if an instrumental variable Z is available that inﬂuences X directly, but is conditionally independent of Y given X. The classic two-stage least squares algorithm (2SLS) simpliﬁes the estimation problem by modeling all relationships as linear functions. We propose kernel instrumental variable regression (KIV), a nonparametric generalization of 2SLS, modeling relations among X, Y , and Z as nonlinear functions in reproducing kernel Hilbert spaces (RKHSs). We prove the consistency of KIV under mild assumptions, and derive conditions under which the convergence rate achieves the minimax optimal rate for unconfounded, one-stage RKHS regression. In doing so, we obtain an efﬁcient ratio between training sample sizes used in the algorithm’s ﬁrst and second stages. In experiments, KIV outperforms state of the art alternatives for nonparametric instrumental variable regression.},
	language = {en},
	urldate = {2019-06-24},
	journal = {arXiv:1906.00232 [cs, econ, math, stat]},
	author = {Singh, Rahul and Sahani, Maneesh and Gretton, Arthur},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.00232},
	keywords = {Mathematics - Statistics Theory, Economics - Econometrics, 62, Computer Science - Machine Learning, Mathematics - Functional Analysis, Statistics - Machine Learning},
	annote = {Comment: 31 pages, 8 figures},
	file = {1906.00232.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\UXR2QH9C\\1906.00232.pdf:application/pdf},
}

@inbook{stock_testing_2005,
	title = {Testing for Weak Instruments in Linear IV Regression},
	booktitle = {Identification and Inference for Econometric Models},
	year = {2005},
	pages = {80-108},
	publisher = {Cambridge University Press},
	organization = {Cambridge University Press},
	address = {New York},
	url = {http://www.economics.harvard.edu/faculty/stock/files/TestingWeakInstr_Stock\%2BYogo.pdf},
	author = {James Stock and Motohiro Yogo},
	editor = {Donald W.K. Andrews}
}

@article{staiger_instrumental_1997,
	title = {Instrumental {Variables} {Regression} with {Weak} {Instruments}},
	volume = {65},
        number = {3},
	abstract = {This paper developsasymptoticdistributiontheory for single-equationinstrumental variablesregressionwhen the partial correlationsbetween the instrumentsand the endogenousvariablesareweak,heremodeledas localto zero.Asymptoticrepresentations are providedfor variousstatistics,includingtwo-stageleast squares(TSLS)and limited informationmaximumlikelihood(LIML)estimators,Waldstatistics,and statisticstesting overidentificationand endogeneity.The asymptoticdistributionsare found to provide good approximationtso samplingdistributionswith 10-20 observationsper instrument. The theorysuggestsconcreteguidelinesfor appliedwork,includingusing nonstandard methods for constructionof confidenceregions. These results are used to interpret Angrist and Krueger's(1991) estimates of the returns to education:whereas TSLS estimateswith manyinstrumentsapproachthe OLS estimateof 6\%, the more reliable LIMLestimateswith fewer instrumentsfall between 8\% and 10\%,with a typical95\% confidenceintervalof (5\%,15\%).},
	language = {en},
	journal = {Econometrica},
	author = {Staiger, Douglas and Stock, James},
	year = {1997},
	pages = {557--586},
	file = {Staiger et Stock - 1997 - Instrumental Variables Regression with Weak Instru.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\9A93PHZL\\Staiger et Stock - 1997 - Instrumental Variables Regression with Weak Instru.pdf:application/pdf},
}

@article{stock_survey_2002,
	title = {A {Survey} of {Weak} {Instruments} and {Weak} {Identification} in {Generalized} {Method} of {Moments}},
	volume = {20},
	issn = {0735-0015, 1537-2707},
	url = {http://www.tandfonline.com/doi/abs/10.1198/073500102288618658},
	doi = {10.1198/073500102288618658},
	language = {en},
	number = {4},
	urldate = {2019-06-24},
	journal = {Journal of Business \& Economic Statistics},
	author = {Stock, James H and Wright, Jonathan H and Yogo, Motohiro},
	month = oct,
	year = {2002},
	pages = {518--529},
	file = {Stock et al. - 2002 - A Survey of Weak Instruments and Weak Identificati.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\EA3AUQWM\\Stock et al. - 2002 - A Survey of Weak Instruments and Weak Identificati.pdf:application/pdf},
}

@article{andrews_conditional_2016,
	title = {Conditional {Inference} {With} a {Functional} {Nuisance} {Parameter}},
	volume = {84},
	issn = {0012-9682},
	url = {https://www.econometricsociety.org/doi/10.3982/ECTA12868},
	doi = {10.3982/ECTA12868},
	language = {en},
	number = {4},
	urldate = {2019-07-12},
	journal = {Econometrica},
	author = {Andrews, Isaiah and Mikusheva, Anna},
	year = {2016},
	pages = {1571--1612},
	file = {Andrews et Mikusheva - 2016 - Conditional Inference With a Functional Nuisance P.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\BZ2VKNWC\\Andrews et Mikusheva - 2016 - Conditional Inference With a Functional Nuisance P.pdf:application/pdf},
}

@article{jun_testing_2012,
	title = {Testing under {Weak} {Identification} with {Conditional} {Moment} {Restrictions}},
	volume = {28},
	issn = {0266-4666, 1469-4360},
	url = {https://www.cambridge.org/core/product/identifier/S0266466612000138/type/journal_article},
	doi = {10.1017/S0266466612000138},
	abstract = {We propose a semiparametric test for the value of coefficients in models with conditional moment restrictions that has correct size regardless of identification strength. The test is in essence an Anderson-Rubin (AR) test using nonparametrically estimated instruments to which we apply a standard error correction. We show that the test is (1) always size-correct, (2) consistent when identification is not too weak, and (3) asymptotically equivalent to an infeasible AR test when identification is sufficiently strong. We moreover prove that under homoskedasticity and strong identification our test has a limiting noncentral chi-square distribution under a sequence of local alternatives, where the noncentrality parameter is given by a quadratic form of the inverse of the semiparametric efficiency bound.},
	language = {en},
	number = {6},
	urldate = {2019-10-02},
	journal = {Econometric Theory},
	author = {Jun, Sung Jae and Pinkse, Joris},
	month = dec,
	year = {2012},
	pages = {1229--1282},
	file = {Jun et Pinkse - 2012 - TESTING UNDER WEAK IDENTIFICATION WITH CONDITIONAL.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\CNZ53UCX\\Jun et Pinkse - 2012 - TESTING UNDER WEAK IDENTIFICATION WITH CONDITIONAL.pdf:application/pdf},
}

@article{angrist_does_1991,
	title = {Does {Compulsory} {Attendance} {Affect} {Schooling} and {Earnings}},
	volume = {106 (4)},
	language = {en},
	journal = {Quaterly Journal of Economics},
	author = {Angrist, Joshua D and Krueger, Alan B},
	year = {1991},
	pages = {979--1014},
	file = {Angsist et Krueger - DOES COMPULSORY SCHOOL ATTENDANCE AFFECT SCHOOLING.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\UV2YYUZL\\Angsist et Krueger - DOES COMPULSORY SCHOOL ATTENDANCE AFFECT SCHOOLING.pdf:application/pdf},
}

@article{nunn_slave_2011,
	title = {The {Slave} {Trade} and the {Origins} of {Mistrust} in {Africa}},
	volume = {101},
	issn = {0002-8282},
	url = {http://pubs.aeaweb.org/doi/10.1257/aer.101.7.3221},
	doi = {10.1257/aer.101.7.3221},
	language = {en},
	number = {7},
	urldate = {2019-10-02},
	journal = {American Economic Review},
	author = {Nunn, Nathan and Wantchekon, Leonard},
	month = dec,
	year = {2011},
	pages = {3221--3252},
	file = {Nunn et Wantchekon - 2011 - The Slave Trade and the Origins of Mistrust in Afr.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\VCHFNU9W\\Nunn et Wantchekon - 2011 - The Slave Trade and the Origins of Mistrust in Afr.pdf:application/pdf},
}

@article{kleibergen_testing_2005,
	title = {Testing {Parameters} in {GMM} {Without} {Assuming} that {They} {Are} {Identified}},
	volume = {73},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/j.1468-0262.2005.00610.x},
	doi = {10.1111/j.1468-0262.2005.00610.x},
	abstract = {We propose a generalized method of moments (GMM) Lagrange multiplier statistic, i.e., the K statistic, that uses a Jacobian estimator based on the continuous updating estimator that is asymptotically uncorrelated with the sample average of the moments. Its asymptotic χ2 distribution therefore holds under a wider set of circumstances, like weak instruments, than the standard full rank case for the expected Jacobian under which the asymptotic χ2 distributions of the traditional statistics are valid. The behavior of the K statistic can be spurious around inﬂection points and maxima of the objective function. This inadequacy is overcome by combining the K statistic with a statistic that tests the validity of the moment equations and by an extension of Moreira’s (2003) conditional likelihood ratio statistic toward GMM. We conduct a power comparison to test for the risk aversion parameter in a stochastic discount factor model and construct its conﬁdence set for observed consumption growth and asset return series.},
	language = {en},
	number = {4},
	urldate = {2019-10-02},
	journal = {Econometrica},
	author = {Kleibergen, Frank},
	month = jul,
	year = {2005},
	pages = {1103--1123},
	file = {Kleibergen - 2005 - Testing Parameters in GMM Without Assuming that Th.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\IA3MYJEB\\Kleibergen - 2005 - Testing Parameters in GMM Without Assuming that Th.pdf:application/pdf},
}

@article{dieterle_simple_2016,
	title = {A simple diagnostic to investigate instrument validity and heterogeneous effects when using a single instrument},
	volume = {42},
	issn = {09275371},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0927537116300847},
	doi = {10.1016/j.labeco.2016.08.002},
	abstract = {Many studies that use instrumental variables are based on a ﬁrst stage linear in the instrument. Using only linear ﬁrst stages may miss important information about eﬀect heterogeneity and instrument validity. Analyzing ﬁfteen studies using linear ﬁrst stages, we ﬁnd ten with signiﬁcant nonlinearities. Six of these ten have statistically diﬀerent second stage estimates. Additional analysis is necessary when results are sensitive to ﬁrst stage choice. We provide a framework to reconcile these diﬀerences by determining those patterns of heterogeneity that are consistent with instrument validity. If these patterns violate economic reasoning, then the validity of the instrument is questioned.},
	language = {en},
	urldate = {2019-10-06},
	journal = {Labour Economics},
	author = {Dieterle, Steven G. and Snell, Andy},
	month = oct,
	year = {2016},
	pages = {76--86},
	file = {Dieterle et Snell - 2016 - A simple diagnostic to investigate instrument vali.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\BZMLYX87\\Dieterle et Snell - 2016 - A simple diagnostic to investigate instrument vali.pdf:application/pdf},
}

@article{andrews_estimation_2012,
	title = {Estimation and {Inference} {With} {Weak}, {Semi}-{Strong}, and {Strong} {Identification}},
	volume = {80},
	issn = {0012-9682},
	url = {http://doi.wiley.com/10.3982/ECTA9456},
	doi = {10.3982/ECTA9456},
	language = {en},
	number = {5},
	urldate = {2019-10-15},
	journal = {Econometrica},
	author = {Andrews, Donald W. K. and Cheng, Xu},
	year = {2012},
	pages = {2153--2211},
	file = {2012 - Estimation and Inference With Weak, Semi-Strong, a.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\75BFBPEL\\2012 - Estimation and Inference With Weak, Semi-Strong, a.pdf:application/pdf},
}

@article{andrews_optimal_2019,
  doi = {10.3982/qe1082},
  url = {https://doi.org/10.3982/qe1082},
  year = {2019},
  month = may,
  publisher = {The Econometric Society},
  volume = {10},
  number = {2},
  pages = {457--485},
  author = {Donald W. K. Andrews and Vadim Marmer and Zhengfei Yu},
  title = {On optimal inference in the linear {IV} model},
  journal = {Quantitative Economics}
}

@article{andrews_optimal_2006,
	title = {Optimal {Two}-{Sided} {Invariant} {Similar} {Tests} for {Instrumental} {Variables} {Regression}},
	volume = {74 (3)},
	language = {en},
	journal = {Econometrica},
	author = {Andrews, Donald W K and Moreira, Marcelo J and Stock, James H},
	year = {2006},
	pages = {715--752},
	file = {Andrews et al. - Optimal Two-Sided Invariant Similar Tests for Inst.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\FDJQ5GAA\\Andrews et al. - Optimal Two-Sided Invariant Similar Tests for Inst.pdf:application/pdf},
}

@article{andrews_inference_2005,
	title = {Inference with {Weak} {Instruments}},
	url = {https://www.nber.org/papers/t0313.pdf},
	urldate = {2019-10-15},
	journal = {NBER Technical Working Paper},
	author = {Andrews, Donald W K and Stock, James},
	year = {2005},
	file = {t0313.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\7WDE7WDC\\t0313.pdf:application/pdf},
}

@article{andrews_conditional_2016-1,
	title = {Conditional {Linear} {Combination} {Tests} for {Weakly} {Identified} {Models}},
	volume = {84},
	issn = {0012-9682},
	url = {https://www.econometricsociety.org/doi/10.3982/ECTA12407},
	doi = {10.3982/ECTA12407},
	language = {en},
	number = {6},
	urldate = {2019-10-15},
	journal = {Econometrica},
	author = {Andrews, Isaiah},
	year = {2016},
	pages = {2155--2182},
	file = {Andrews - 2016 - Conditional Linear Combination Tests for Weakly Id.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\IN9QEF4K\\Andrews - 2016 - Conditional Linear Combination Tests for Weakly Id.pdf:application/pdf},
}

@article{antoine_conditional_2014,
	title = {Conditional moment models under semi-strong identification},
	volume = {182},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407614000670},
	doi = {10.1016/j.jeconom.2014.04.008},
	abstract = {We consider conditional moment models under semi-strong identification. Identification strength is directly defined through the conditional moments that flatten as the sample size increases. Our new minimum distance estimator is consistent, asymptotically normal, robust to semi-strong identification, and does not rely on the choice of a user-chosen parameter, such as the number of instruments or some smoothing parameter. Heteroskedasticity-robust inference is possible through Wald testing without prior knowledge of the identification pattern. Simulations show that our estimator is competitive with alternative estimators based on many instruments, being well-centered with better coverage rates for confidence intervals.},
	language = {en},
	number = {1},
	urldate = {2019-10-15},
	journal = {Journal of Econometrics},
	author = {Antoine, Bertille and Lavergne, Pascal},
	month = sep,
	year = {2014},
	pages = {59--69},
	file = {Antoine et Lavergne - 2014 - Conditional moment models under semi-strong identi.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\YZNYZ6DV\\Antoine et Lavergne - 2014 - Conditional moment models under semi-strong identi.pdf:application/pdf},
}

@article{chernozhukov_reduced_2008,
	title = {The reduced form: {A} simple approach to inference with weak instruments},
	volume = {100},
	issn = {01651765},
	shorttitle = {The reduced form},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165176507004107},
	doi = {10.1016/j.econlet.2007.11.012},
	abstract = {In this paper, we show that conventional heteroskedasticity and autocorrelation robust inference procedures based on the reduced form provide tests and confidence intervals for structural parameters that are valid when instruments are strongly or weakly correlated to the endogenous variables. © 2008 Published by Elsevier B.V.},
	language = {en},
	number = {1},
	urldate = {2019-10-15},
	journal = {Economics Letters},
	author = {Chernozhukov, Victor and Hansen, Christian},
	month = jul,
	year = {2008},
	pages = {68--71},
	file = {Chernozhukov et Hansen - 2008 - The reduced form A simple approach to inference w.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\EK5LWI7Y\\Chernozhukov et Hansen - 2008 - The reduced form A simple approach to inference w.pdf:application/pdf},
}

@article{dufour_impossibility_1997,
	title = {Some {Impossibility} {Theorems} in {Econometrics} {With} {Applications} to {Structural} and {Dynamic} {Models}},
	volume = {65},
	issn = {00129682},
	url = {https://www.jstor.org/stable/2171740?origin=crossref},
	doi = {10.2307/2171740},
	language = {en},
	number = {6},
	urldate = {2019-10-15},
	journal = {Econometrica},
	author = {Dufour, Jean-Marie},
	month = nov,
	year = {1997},
	pages = {1365},
	file = {Dufour - 1997 - Some Impossibility Theorems in Econometrics With A.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\JN9IS6VV\\Dufour - 1997 - Some Impossibility Theorems in Econometrics With A.pdf:application/pdf},
}

@article{dufour_identification_2003,
	title = {Identification, weak instruments, and statistical inference in econometrics},
	volume = {36},
	issn = {0008-4085, 1540-5982},
	url = {http://doi.wiley.com/10.1111/1540-5982.t01-3-00001},
	doi = {10.1111/1540-5982.t01-3-00001},
	language = {en},
	number = {4},
	urldate = {2019-10-15},
	journal = {Canadian Journal of Economics/Revue Canadienne d`Economique},
	author = {Dufour, Jean-Marie},
	month = nov,
	year = {2003},
	pages = {767--808},
	file = {Dufour - 2003 - Identification, weak instruments, and statistical .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\GG98XSXZ\\Dufour - 2003 - Identification, weak instruments, and statistical .pdf:application/pdf},
}

@article{dufour_projection-based_2005,
	title = {Projection-{Based} {Statistical} {Inference} in {Linear} {Structural} {Models} with {Possibly} {Weak} {Instruments}},
	volume = {73},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/j.1468-0262.2005.00618.x},
	doi = {10.1111/j.1468-0262.2005.00618.x},
	language = {en},
	number = {4},
	urldate = {2019-10-15},
	journal = {Econometrica},
	author = {Dufour, Jean-Marie and Taamouti, Mohamed},
	month = jul,
	year = {2005},
	pages = {1351--1365},
	file = {Dufour et Taamouti - 2005 - Projection-Based Statistical Inference in Linear S.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\L7K7K4V7\\Dufour et Taamouti - 2005 - Projection-Based Statistical Inference in Linear S.pdf:application/pdf},
}

@article{dufour_further_2007,
	title = {Further results on projection-based inference in {IV} regressions with weak, collinear or missing instruments},
	volume = {139},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407606001060},
	doi = {10.1016/j.jeconom.2006.06.008},
	abstract = {We study a general family of Anderson–Rubin-type procedures, allowing for arbitrary collinearity among the instruments and endogenous variables. Using ﬁnite-sample distributional theory, we show that the proposed procedures, besides being robust to weak instruments, are also robust to the exclusion of relevant instruments and to the distribution of endogenous regressors. A solution to the problem of computing linear projections from general possibly singular quadric surfaces is derived and used to build ﬁnite-sample conﬁdence sets for individual structural parameters. The importance of robustness to excluded instruments is studied by simulation. Applications to the trade-growth relationship and to education returns are presented.},
	language = {en},
	number = {1},
	urldate = {2019-10-15},
	journal = {Journal of Econometrics},
	author = {Dufour, Jean-Marie and Taamouti, Mohamed},
	month = jul,
	year = {2007},
	pages = {133--153},
	file = {Dufour et Taamouti - 2007 - Further results on projection-based inference in I.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\FND4QG38\\Dufour et Taamouti - 2007 - Further results on projection-based inference in I.pdf:application/pdf},
}

@article{hahn_weak_2003,
	title = {Weak {Instruments}: {Diagnosis} and {Cures} in {Empirical} {Econometrics}},
	volume = {93},
	issn = {0002-8282},
	shorttitle = {Weak {Instruments}},
	url = {http://pubs.aeaweb.org/doi/10.1257/000282803321946912},
	doi = {10.1257/000282803321946912},
	language = {en},
	number = {2},
	urldate = {2019-10-15},
	journal = {American Economic Review},
	author = {Hahn, Jinyong and Hausman, Jerry},
	month = apr,
	year = {2003},
	pages = {118--125},
	file = {Hahn et Hausman - 2003 - Weak Instruments Diagnosis and Cures in Empirical.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\P78IHVBF\\Hahn et Hausman - 2003 - Weak Instruments Diagnosis and Cures in Empirical.pdf:application/pdf},
}

@article{kleibergen_generalizing_2007,
	title = {Generalizing weak instrument robust {IV} statistics towards multiple parameters, unrestricted covariance matrices and identification statistics},
	volume = {139},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407606001084},
	doi = {10.1016/j.jeconom.2006.06.010},
	abstract = {We generalize the weak instrument robust score or Lagrange multiplier and likelihood ratio instrumental variables (IV) statistics towards multiple parameters and a general covariance matrix so they can be used in the generalized method of moments (GMM). The GMM extension of Moreira’s [2003. A conditional likelihood ratio test for structural models. Econometrica 71, 1027–1048] conditional likelihood ratio statistic towards GMM preserves its expression except that it becomes conditional on a statistic that tests the rank of a matrix. We analyze the spurious power decline of Kleibergen’s [2002. Pivotal statistics for testing structural parameters in instrumental variables regression. Econometrica 70, 1781–1803, 2005. Testing parameters in GMM without assuming that they are identiﬁed. Econometrica 73, 1103–1124] score statistic and show that an independent misspeciﬁcation pre-test overcomes it. We construct identiﬁcation statistics that reﬂect if the conﬁdence sets of the parameters are bounded. A power study and the possible shapes of conﬁdence sets illustrate the analysis.},
	language = {en},
	number = {1},
	urldate = {2019-10-15},
	journal = {Journal of Econometrics},
	author = {Kleibergen, Frank},
	month = jul,
	year = {2007},
	pages = {181--216},
	file = {Kleibergen - 2007 - Generalizing weak instrument robust IV statistics .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\QNIZQH55\\Kleibergen - 2007 - Generalizing weak instrument robust IV statistics .pdf:application/pdf},
}

@article{moreira_optimal_2015,
	doi = {10.1016/j.jeconom.2019.04.038},
  url = {https://doi.org/10.1016/j.jeconom.2019.04.038},
  year = {2019},
  month = dec,
  publisher = {Elsevier {BV}},
  volume = {213},
  number = {2},
  pages = {398--433},
  author = {Humberto Moreira and Marcelo J. Moreira},
  title = {Optimal two-sided tests for instrumental variables regression with heteroskedastic and autocorrelated errors},
  journal = {Journal of Econometrics}
}

@article{moreira_optimal_2017,
	title = {Optimal {Invariant} {Tests} in an {Instrumental} {Variables} {Regression} {With} {Heteroskedastic} and {Autocorrelated} {Errors}},
	url = {http://arxiv.org/abs/1705.00231},
	abstract = {This paper uses model symmetries in the instrumental variable (IV) regression to derive an invariant test for the causal structural parameter. Contrary to popular belief, we show there exist model symmetries when equation errors are heteroskedastic and autocorrelated (HAC). Our theory is consistent with existing results for the homoskedastic model (Andrews, Moreira and Stock(2006\vphantom{\{}\} and Chamberlain (2007\vphantom{\{}\}), but in general uses information on the structural parameter beyond the Anderson-Rubin, score, and rank statistics. This suggests that tests based only the Anderson-Rubin and score statistics discard information on the causal parameter of interest. We apply our theory to construct designs in which these tests indeed have power arbitrarily close to size. Other tests, including other adaptations to the CLR test, do not suffer the same deficiencies. Finally, we use the model symmetries to propose novel weighted-average power tests for the HAC-IV model.},
	language = {en},
	urldate = {2019-10-15},
	journal = {arXiv:1705.00231 [math, stat]},
	author = {Moreira, Marcelo J. and Ridder, Geert},
	month = apr,
	year = {2017},
	note = {arXiv: 1705.00231},
	keywords = {Mathematics - Statistics Theory},
	file = {Moreira et Ridder - 2017 - Optimal Invariant Tests in an Instrumental Variabl.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\K7U8T9IL\\Moreira et Ridder - 2017 - Optimal Invariant Tests in an Instrumental Variabl.pdf:application/pdf},
}

@article{mikusheva_robust_2010,
	title = {Robust confidence sets in the presence of weak instruments},
	volume = {157},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407609003029},
	doi = {10.1016/j.jeconom.2009.12.003},
	abstract = {This paper considers instrumental variable regression with a single endogenous variable and the potential presence of weak instruments. I construct confidence sets for the coefficient on the single endogenous regressor by inverting tests robust to weak instruments. I suggest a numerically simple algorithm for finding the Conditional Likelihood Ratio (CLR) confidence sets. Full descriptions of possible forms of the CLR, Anderson–Rubin (AR) and Lagrange Multiplier (LM) confidence sets are given. I show that the CLR confidence sets have nearly the shortest expected arc length among similar symmetric invariant confidence sets in a circular model. I also prove that the CLR confidence set is asymptotically valid in a model with non-normal errors.},
	language = {en},
	number = {2},
	urldate = {2019-10-15},
	journal = {Journal of Econometrics},
	author = {Mikusheva, Anna},
	month = aug,
	year = {2010},
	pages = {236--247},
	file = {Mikusheva - 2010 - Robust confidence sets in the presence of weak ins.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\NWSVK9SU\\Mikusheva - 2010 - Robust confidence sets in the presence of weak ins.pdf:application/pdf},
}

@article{stock_gmm_2000,
	title = {{GMM} with {Weak} {Identification}},
	volume = {68},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/1468-0262.00151},
	doi = {10.1111/1468-0262.00151},
	abstract = {This paper develops asymptotic distribution theory for GMM estimators and test statistics when some or all of the parameters are weakly identiﬁed. General results are obtained and are specialized to two important cases: linear instrumental variables regression and Euler equations estimation of the CCAPM. Numerical results for the CCAPM demonstrate that weak-identiﬁcation asymptotics explains the breakdown of conventional GMM procedures documented in previous Monte Carlo studies. Conﬁdence sets immune to weak identiﬁcation are proposed. We use these results to inform an empirical investigation of various CCAPM speciﬁcations; the substantive conclusions reached differ from those obtained using conventional methods.},
	language = {en},
	number = {5},
	urldate = {2019-10-15},
	journal = {Econometrica},
	author = {Stock, James H. and Wright, Jonathan H.},
	month = sep,
	year = {2000},
	pages = {1055--1096},
	file = {Stock et Wright - 2000 - GMM with Weak Identification.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\I339XYS3\\Stock et Wright - 2000 - GMM with Weak Identification.pdf:application/pdf},
}

@techreport{andrews_optimal_2004,
	address = {Cambridge, MA},
	title = {Optimal {Invariant} {Similar} {Tests} for {Instrumental} {Variables} {Regression}},
	url = {http://www.nber.org/papers/t0299.pdf},
	language = {en},
	number = {t0299},
	urldate = {2019-10-15},
	institution = {National Bureau of Economic Research},
	author = {Andrews, Donald W.K. and Moreira, Marcelo and Stock, James},
	month = aug,
	year = {2004},
	doi = {10.3386/t0299},
	pages = {t0299},
	file = {Andrews et al. - 2004 - Optimal Invariant Similar Tests for Instrumental V.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\3Q9SWYUT\\Andrews et al. - 2004 - Optimal Invariant Similar Tests for Instrumental V.pdf:application/pdf},
}

@article{hansen_estimation_2008,
	title = {Estimation {With} {Many} {Instrumental} {Variables}},
	volume = {26},
	issn = {0735-0015, 1537-2707},
	url = {http://www.tandfonline.com/doi/abs/10.1198/073500108000000024},
	doi = {10.1198/073500108000000024},
	language = {en},
	number = {4},
	urldate = {2019-10-15},
	journal = {Journal of Business \& Economic Statistics},
	author = {Hansen, Christian and Hausman, Jerry and Newey, Whitney},
	month = oct,
	year = {2008},
	pages = {398--422},
	file = {Hansen et al. - 2008 - Estimation With Many Instrumental Variables.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\A37WBVSF\\Hansen et al. - 2008 - Estimation With Many Instrumental Variables.pdf:application/pdf},
}

@article{chamberlain_random_2004,
	title = {Random {Effects} {Estimators} with many {Instrumental} {Variables}},
	volume = {72},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/j.1468-0262.2004.00485.x},
	doi = {10.1111/j.1468-0262.2004.00485.x},
	language = {en},
	number = {1},
	urldate = {2019-10-23},
	journal = {Econometrica},
	author = {Chamberlain, Gary and Imbens, Guido},
	month = jan,
	year = {2004},
	pages = {295--306},
	file = {Chamberlain et Imbens - 2004 - Random Effects Estimators with many Instrumental V.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\56HLRRMH\\Chamberlain et Imbens - 2004 - Random Effects Estimators with many Instrumental V.pdf:application/pdf},
}

@article{newey_instrumental_2003,
	title = {Instrumental {Variable} {Estimation} of {Nonparametric} {Models}},
	volume = {71},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/1468-0262.00459},
	doi = {10.1111/1468-0262.00459},
	language = {en},
	number = {5},
	urldate = {2019-10-23},
	journal = {Econometrica},
	author = {Newey, Whitney K. and Powell, James L.},
	month = sep,
	year = {2003},
	pages = {1565--1578},
	file = {Newey et Powell - 2003 - Instrumental Variable Estimation of Nonparametric .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\DJ3IUL8D\\Newey et Powell - 2003 - Instrumental Variable Estimation of Nonparametric .pdf:application/pdf},
}

@article{darolles_nonparametric_2011,
	title = {Nonparametric {Instrumental} {Regression}},
	volume = {79},
	issn = {0012-9682},
	url = {http://doi.wiley.com/10.3982/ECTA6539},
	doi = {10.3982/ECTA6539},
	language = {en},
	number = {5},
	urldate = {2019-10-23},
	journal = {Econometrica},
	author = {Darolles, Serge and Florens, Jean-Pierre and Renault, Eric},
	year = {2011},
	pages = {1541--1565},
	file = {2011 - Nonparametric Instrumental Regression.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\HQ567DDM\\2011 - Nonparametric Instrumental Regression.pdf:application/pdf},
}

@article{andrews_testing_2007,
	title = {Testing with many weak instruments},
	volume = {138},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030440760600087X},
	doi = {10.1016/j.jeconom.2006.05.012},
	abstract = {This paper establishes the asymptotic distributions of the likelihood ratio (LR), Anderson–Rubin (AR), and Lagrange multiplier (LM) test statistics under ‘‘many weak IV asymptotics.’’ These asymptotics are relevant when the number of IVs is large and the coefﬁcients on the IVs are relatively small. The asymptotic results hold under the null and under suitable alternatives. Hence, power comparisons can be made.},
	language = {en},
	number = {1},
	urldate = {2019-10-23},
	journal = {Journal of Econometrics},
	author = {Andrews, Donald W.K. and Stock, James H.},
	month = may,
	year = {2007},
	pages = {24--46},
	file = {Andrews et Stock - 2007 - Testing with many weak instruments.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\4DEW4BF9\\Andrews et Stock - 2007 - Testing with many weak instruments.pdf:application/pdf},
}

@article{bound_problems_1995,
	title = {Problems with {Instrumental} {Variables} {Estimation} {When} the {Correlation} {Between} the {Instruments} and the {Endogeneous} {Explanatory} {Variable} is {Weak}},
	volume = {90},
	issn = {01621459},
	url = {https://www.jstor.org/stable/2291055?origin=crossref},
	doi = {10.2307/2291055},
	language = {en},
	number = {430},
	urldate = {2019-10-23},
	journal = {Journal of the American Statistical Association},
	author = {Bound, John and Jaeger, David A. and Baker, Regina M.},
	month = jun,
	year = {1995},
	pages = {443},
	file = {Bound et al. - 1995 - Problems with Instrumental Variables Estimation Wh.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\AU8UBQXH\\Bound et al. - 1995 - Problems with Instrumental Variables Estimation Wh.pdf:application/pdf},
}

@article{kleibergen_generalized_2006,
	title = {Generalized reduced rank tests using the singular value decomposition},
	volume = {133},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407605000850},
	doi = {10.1016/j.jeconom.2005.02.011},
	abstract = {We propose a novel statistic to test the rank of a matrix. The rank statistic overcomes deﬁciencies of existing rank statistics, like: a Kronecker covariance matrix for the canonical correlation rank statistic of Anderson [Annals of Mathematical Statistics (1951), 22, 327–351] sensitivity to the ordering of the variables for the LDU rank statistic of Cragg and Donald [Journal of the American Statistical Association (1996), 91, 1301–1309] and Gill and Lewbel [Journal of the American Statistical Association (1992), 87, 766–776] a limiting distribution that is not a standard chi-squared distribution for the rank statistic of Robin and Smith [Econometric Theory (2000), 16, 151–175] usage of numerical optimization for the objective function statistic of Cragg and Donald [Journal of Econometrics (1997), 76, 223–250] and ignoring the non-negativity restriction on the singular values in Ratsimalahelo [2002, Rank test based on matrix perturbation theory. Unpublished working paper, U.F.R. Science Economique, University de Franche-Comte´ ]. In the non-stationary cointegration case, the limiting distribution of the new rank statistic is identical to that of the Johansen trace statistic. r 2005 Elsevier B.V. All rights reserved.},
	language = {en},
	number = {1},
	urldate = {2019-10-28},
	journal = {Journal of Econometrics},
	author = {Kleibergen, Frank and Paap, Richard},
	month = jul,
	year = {2006},
	pages = {97--126},
	file = {Kleibergen et Paap - 2006 - Generalized reduced rank tests using the singular .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\XAXNDNVF\\Kleibergen et Paap - 2006 - Generalized reduced rank tests using the singular .pdf:application/pdf},
}

@article{andrews_weak_2018,
	title = {Weak {Instruments} in {IV} {Regression}: {Theory} and {Practice}},
	abstract = {When instruments are weakly correlated with endogenous regressors, conventional methods for instrumental variables estimation and inference become unreliable. A large literature in econometrics develops procedures for detecting weak instruments and constructing robust conﬁdence sets, but many of the results in this literature are limited to settings with independent and homoskedastic data, while data encountered in practice frequently violate these assumptions. We review the literature on weak instruments in linear IV regression with an emphasis on results for non-homoskedastic (heteroskedastic, serially correlated, or clustered) data. To assess the practical importance of weak instruments, we also report tabulations and simulations based on a survey of papers published in the American Economic Review from 2014 to 2018 that use instrumental variables. These results suggest that weak instruments remain an important issue for empirical practice, and that there are simple steps researchers can take to better handle weak instruments in applications.},
	language = {en},
	author = {Andrews, Isaiah and Stock, James and Sun, Liyang},
	year = {2018},
	pages = {41},
	file = {Andrews et al. - Weak Instruments in IV Regression Theory and Prac.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\MQAJY8ZP\\Andrews et al. - Weak Instruments in IV Regression Theory and Prac.pdf:application/pdf},
}

@article{hall_consistent_2003,
	title = {A {Consistent} {Method} for the {Selection} of {Relevant} {Instruments}},
	volume = {22},
	issn = {0747-4938, 1532-4168},
	url = {https://www.tandfonline.com/doi/full/10.1081/ETC-120024752},
	doi = {10.1081/ETC-120024752},
	language = {en},
	number = {3},
	urldate = {2019-11-07},
	journal = {Econometric Reviews},
	author = {Hall, Alastair R. and Peixe, Fernanda P. M.},
	month = jan,
	year = {2003},
	pages = {269--287},
	file = {A Consistent Method for the Selection of Relevant Instruments.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\IBWN8KYK\\A Consistent Method for the Selection of Relevant Instruments.pdf:application/pdf},
}

@article{han_gmm_2006,
	title = {{GMM} with {Many} {Moment} {Conditions}},
	volume = {74},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/j.1468-0262.2006.00652.x},
	doi = {10.1111/j.1468-0262.2006.00652.x},
	language = {en},
	number = {1},
	urldate = {2019-12-02},
	journal = {Econometrica},
	author = {Han, Chirok and Phillips, Peter C. B.},
	month = jan,
	year = {2006},
	pages = {147--192},
	file = {Han et Phillips - 2006 - GMM with Many Moment Conditions.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\SDBQNEGU\\Han et Phillips - 2006 - GMM with Many Moment Conditions.pdf:application/pdf},
}

@article{berk_valid_2013,
	title = {Valid post-selection inference},
	volume = {41},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1369836961},
	doi = {10.1214/12-AOS1077},
	language = {en},
	number = {2},
	urldate = {2019-12-05},
	journal = {The Annals of Statistics},
	author = {Berk, Richard and Brown, Lawrence and Buja, Andreas and Zhang, Kai and Zhao, Linda},
	month = apr,
	year = {2013},
	pages = {802--837},
	file = {Berk et al. - 2013 - Valid post-selection inference.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\W2XMJMRR\\Berk et al. - 2013 - Valid post-selection inference.pdf:application/pdf},
}

@article{caner_lasso-type_2009,
	title = {Lasso-{Type} {GMM} {Estimator}},
	volume = {25},
	issn = {0266-4666, 1469-4360},
	url = {https://www.cambridge.org/core/product/identifier/S0266466608090099/type/journal_article},
	doi = {10.1017/S0266466608090099},
	abstract = {This paper proposes the least absolute shrinkage and selection operator–type (Lasso-type) generalized method of moments (GMM) estimator. This Lasso-type estimator is formed by the GMM objective function with the addition of a penalty term. The exponent of the penalty term in the regular Lasso estimator is equal to one. However, the exponent of the penalty term in the Lasso-type estimator is less than one in the analysis here. The magnitude of the exponent is reduced to avoid the asymptotic bias. This estimator selects the correct model and estimates it simultaneously. In other words, this method estimates the redundant parameters as zero in the large samples and provides the standard GMM limit distribution for the estimates of the nonzero parameters in the model. The asymptotic theory for our estimator is nonstandard. We conduct a simulation study that shows that the Lasso-type GMM correctly selects the true model much more often than the Bayesian information Criterion (BIC) and another model selection procedure based on the GMM objective function.},
	language = {en},
	number = {1},
	urldate = {2019-12-06},
	journal = {Econometric Theory},
	author = {Caner, Mehmet},
	month = feb,
	year = {2009},
	pages = {270--290},
	file = {Caner - 2009 - LASSO-TYPE GMM ESTIMATOR.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\XUQU58I5\\Caner - 2009 - LASSO-TYPE GMM ESTIMATOR.pdf:application/pdf},
}

@article{cheng_select_2015,
	title = {Select the valid and relevant moments: {An} information-based {LASSO} for {GMM} with many moments},
	volume = {186},
	issn = {03044076},
	shorttitle = {Select the valid and relevant moments},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407615000433},
	doi = {10.1016/j.jeconom.2015.02.019},
	abstract = {This paper studies the selection of valid and relevant moments for the generalized method of moments (GMM) estimation. For applications with many candidate moments, our asymptotic analysis accommodates a diverging number of moments as the sample size increases. The proposed procedure achieves three objectives in one-step: (i) the valid and relevant moments are distinguished from the invalid or irrelevant ones; (ii) all desired moments are selected in one step instead of in a stepwise manner; (iii) the parameters of interest are automatically estimated with all selected moments as opposed to a post-selection estimation. The new method performs moment selection and efficient estimation simultaneously via an information-based adaptive GMM shrinkage estimation, where an appropriate penalty is attached to the standard GMM criterion to link moment selection to shrinkage estimation. The penalty is designed to signal both moment validity and relevance for consistent moment selection. We develop asymptotic results for the high-dimensional GMM shrinkage estimator, allowing for non-smooth sample moments and weakly dependent observations. For practical implementation, this one-step procedure is computationally attractive.},
	language = {en},
	number = {2},
	urldate = {2019-12-06},
	journal = {Journal of Econometrics},
	author = {Cheng, Xu and Liao, Zhipeng},
	month = jun,
	year = {2015},
	pages = {443--464},
	file = {Cheng et Liao - 2015 - Select the valid and relevant moments An informat.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\XDXG5Y3Q\\Cheng et Liao - 2015 - Select the valid and relevant moments An informat.pdf:application/pdf},
}

@article{donald_choosing_2009,
	title = {Choosing instrumental variables in conditional moment restriction models},
	volume = {152},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407609000566},
	doi = {10.1016/j.jeconom.2008.10.013},
	abstract = {Properties of GMM estimators are sensitive to the choice of instrument. Using many instruments leads to high asymptotic asymptotic efficiency but can cause high bias and/or variance in small samples. In this paper we develop and implement asymptotic mean square error (MSE) based criteria for instrument selection in estimation of conditional moment restriction models. The models we consider include various nonlinear simultaneous equations models with unknown heteroskedasticity. We develop moment selection criteria for the familiar two-step optimal GMM estimator (GMM), a bias corrected version, and generalized empirical likelihood estimators (GEL), that include the continuous updating estimator (CUE) as a special case. We also find that the CUE has lower higher-order variance than the bias-corrected GMM estimator, and that the higher-order efficiency of other GEL estimators depends on conditional kurtosis of the moments.},
	language = {en},
	number = {1},
	urldate = {2019-12-09},
	journal = {Journal of Econometrics},
	author = {Donald, Stephen G. and Imbens, Guido W. and Newey, Whitney K.},
	month = sep,
	year = {2009},
	pages = {28--36},
	file = {Donald et al. - 2009 - Choosing instrumental variables in conditional mom.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\9VZYMTDM\\Donald et al. - 2009 - Choosing instrumental variables in conditional mom.pdf:application/pdf},
}

@article{ng_selecting_2009,
	title = {Selecting {Instrumental} {Variables} in a {Data} {Rich} {Environment}},
	volume = {1},
	issn = {1941-1928},
	url = {https://www.degruyter.com/view/j/jtse.2009.1.1/jtse.2009.1.1.1014/jtse.2009.1.1.1014.xml},
	doi = {10.2202/1941-1928.1014},
	abstract = {Practitioners often have at their disposal a large number of instruments that are weakly exogenous for the parameter of interest, but using too many instruments can induce bias. We consider two ways of handling this problem. The ﬁrst is to form principal components from the observed instruments, and the second is to reduce the number of instruments by subset variable selection. For the latter, we consider boosting, a method that does not require an a priori ordering of the instruments. We also suggest a way to pre-order the instruments and then screen the instruments using the goodness of ﬁt of the ﬁrst stage regression and information criteria. Using these methods to form smaller sets of instruments from the observed data or their principal components, we ﬁnd that the principal components are often better instruments than the observed data. The exception is when the number of relevant instruments is small. Of the three methods for selecting instruments, no single method dominates. But a hard-thresholding method based on the t test generally yields estimates with small biases and root mean squared error.},
	language = {en},
	number = {1},
	urldate = {2019-12-09},
	journal = {Journal of Time Series Econometrics},
	author = {Ng, Serena and Bai, Jushan},
	month = jan,
	year = {2009},
	file = {Ng et Bai - 2009 - Selecting Instrumental Variables in a Data Rich En.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\W9APFKHB\\Ng et Bai - 2009 - Selecting Instrumental Variables in a Data Rich En.pdf:application/pdf},
}

@article{hahn_nonparametric_2018,
	title = {Nonparametric {Instrumental} {Variables} and {Regular} {Estimation}},
	volume = {34},
	issn = {0266-4666, 1469-4360},
	url = {https://www.cambridge.org/core/product/identifier/S0266466617000093/type/journal_article},
	doi = {10.1017/S0266466617000093},
	abstract = {This paper investigates whether there can exist regular estimators in models characterized by nonparametric instrumental variable (NPIV). We show by a number of examples that regular estimation is impossible in general for nonlinear functionals.},
	language = {en},
	number = {3},
	urldate = {2020-01-13},
	journal = {Econometric Theory},
	author = {Hahn, Jinyong and Liao, Zhipeng},
	month = jun,
	year = {2018},
	pages = {574--597},
	file = {Hahn et Liao - 2018 - NONPARAMETRIC INSTRUMENTAL VARIABLES AND REGULAR E.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\BH5LHKYK\\Hahn et Liao - 2018 - NONPARAMETRIC INSTRUMENTAL VARIABLES AND REGULAR E.pdf:application/pdf},
}

@article{belloni_high-dimensional_2018,
	title = {High-{Dimensional} {Econometrics} and {Regularized} {GMM}},
	url = {http://arxiv.org/abs/1806.01888},
	abstract = {This chapter presents key concepts and theoretical results for analyzing estimation and inference in high-dimensional models. High-dimensional models are characterized by having a number of unknown parameters that is not vanishingly small relative to the sample size. We first present results in a framework where estimators of parameters of interest may be represented directly as approximate means. Within this context, we review fundamental results including high-dimensional central limit theorems, bootstrap approximation of high-dimensional limit distributions, and moderate deviation theory. We also review key concepts underlying inference when many parameters are of interest such as multiple testing with family-wise error rate or false discovery rate control. We then turn to a general high-dimensional minimum distance framework with a special focus on generalized method of moments problems where we present results for estimation and inference about model parameters. The presented results cover a wide array of econometric applications, and we discuss several leading special cases including high-dimensional linear regression and linear instrumental variables models to illustrate the general results.},
	language = {en},
	urldate = {2020-01-13},
	journal = {arXiv:1806.01888 [econ, math, stat]},
	author = {Belloni, Alexandre and Chernozhukov, Victor and Chetverikov, Denis and Hansen, Christian and Kato, Kengo},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.01888},
	keywords = {Mathematics - Statistics Theory, Economics - Econometrics},
	annote = {Comment: 104 pages, 4 figures},
	file = {Belloni et al. - 2018 - High-Dimensional Econometrics and Regularized GMM.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\336GZKW9\\Belloni et al. - 2018 - High-Dimensional Econometrics and Regularized GMM.pdf:application/pdf},
}

@article{chernozhukov_valid_2015,
	title = {Valid {Post}-{Selection} and {Post}-{Regularization} {Inference}: {An} {Elementary}, {General} {Approach}},
	volume = {7},
	issn = {1941-1383, 1941-1391},
	shorttitle = {Valid {Post}-{Selection} and {Post}-{Regularization} {Inference}},
	url = {http://arxiv.org/abs/1501.03430},
	doi = {10.1146/annurev-economics-012315-015826},
	abstract = {We present an expository, general analysis of valid post-selection or post-regularization inference about a low-dimensional target parameter in the presence of a very high-dimensional nuisance parameter that is estimated using selection or regularization methods. Our analysis provides a set of high-level conditions under which inference for the low-dimensional parameter based on testing or point estimation methods will be regular despite selection or regularization biases occurring in the estimation of the high-dimensional nuisance parameter. The results may be applied to establish uniform validity of post-selection or post-regularization inference procedures for low-dimensional target parameters over large classes of models. The high-level conditions allow one to clearly see the types of structure needed to achieve valid post-regularization inference and encompass many existing results. A key element of the structure we employ and discuss in detail is the use of so-called orthogonal or “immunized” estimating equations that are locally insensitive to small mistakes in estimation of the high-dimensional nuisance parameter. As an illustration, we use the high-level conditions to provide readily veriﬁable suﬃcient conditions for a class of aﬃne-quadratic models that include the usual linear model and linear instrumental variables model as special cases. As a further application and illustration, we use these results to provide an analysis of post-selection inference in a linear instrumental variables model with many regressors and many instruments. We conclude with a review of other developments in postselection inference and note that many of the developments can be viewed as special cases of the general encompassing framework of orthogonal estimating equations provided in this paper.},
	language = {en},
	number = {1},
	urldate = {2020-01-14},
	journal = {Annual Review of Economics},
	author = {Chernozhukov, Victor and Hansen, Christian and Spindler, Martin},
	month = aug,
	year = {2015},
	note = {arXiv: 1501.03430},
	keywords = {Mathematics - Statistics Theory, Economics - Econometrics},
	pages = {649--688},
	annote = {Comment: 47 pages},
	file = {1501.03430.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\JYV9XE4L\\1501.03430.pdf:application/pdf},
}

@article{belloni_sparse_2012,
	title = {Sparse {Models} and {Methods} for {Optimal} {Instruments} {With} an {Application} to {Eminent} {Domain}},
	volume = {80},
	issn = {0012-9682},
	url = {http://doi.wiley.com/10.3982/ECTA9626},
	doi = {10.3982/ECTA9626},
	language = {en},
	number = {6},
	urldate = {2020-01-14},
	journal = {Econometrica},
	author = {Belloni, Alexandre and Chen, Daniel and Chernozhukov, Victor and Hansen, Christian},
	year = {2012},
	pages = {2369--2429},
	file = {Belloni et al. - 2012 - Sparse Models and Methods for Optimal Instruments .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\7R76G8H6\\Belloni et al. - 2012 - Sparse Models and Methods for Optimal Instruments .pdf:application/pdf},
}

@article{caner_near_2014,
	title = {Near exogeneity and weak identification in generalized empirical likelihood estimators: {Many} moment asymptotics},
	volume = {182},
	issn = {03044076},
	shorttitle = {Near exogeneity and weak identification in generalized empirical likelihood estimators},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407614001031},
	doi = {10.1016/j.jeconom.2014.05.001},
	abstract = {This paper investigates the Generalized Empirical Likelihood (GEL) estimators when there are local violations of the exogeneity condition (near exogeneity) in the case of many weak moments. We also examine the tradeoff between the degree of violation of the exogeneity and the number of nearly exogenous instruments. In this respect, this paper extends many weak moment asymptotics of Newey and Windmeijer (2009a). The overidentifying restrictions test can detect both mild and large violations of exogeneity. In the case of minor violations, the Anderson–Rubin (1949) and Wald tests are not size distorted.},
	language = {en},
	number = {2},
	urldate = {2020-01-15},
	journal = {Journal of Econometrics},
	author = {Caner, Mehmet},
	month = oct,
	year = {2014},
	pages = {247--268},
	file = {Caner - 2014 - Near exogeneity and weak identification in general.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\W6S5FC3X\\Caner - 2014 - Near exogeneity and weak identification in general.pdf:application/pdf},
}

@article{caner_adaptive_2018,
	title = {Adaptive {Elastic} {Net} {GMM} {Estimation} {With} {Many} {Invalid} {Moment} {Conditions}: {Simultaneous} {Model} and {Moment} {Selection}},
	volume = {36},
	issn = {0735-0015, 1537-2707},
	shorttitle = {Adaptive {Elastic} {Net} {GMM} {Estimation} {With} {Many} {Invalid} {Moment} {Conditions}},
	url = {https://www.tandfonline.com/doi/full/10.1080/07350015.2015.1129344},
	doi = {10.1080/07350015.2015.1129344},
	language = {en},
	number = {1},
	urldate = {2020-01-15},
	journal = {Journal of Business \& Economic Statistics},
	author = {Caner, Mehmet and Han, Xu and Lee, Yoonseok},
	month = jan,
	year = {2018},
	pages = {24--46},
	file = {Caner et al. - 2018 - Adaptive Elastic Net GMM Estimation With Many Inva.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\3QSDN9T3\\Caner et al. - 2018 - Adaptive Elastic Net GMM Estimation With Many Inva.pdf:application/pdf},
}

@article{caner_hybrid_2015,
	title = {Hybrid generalized empirical likelihood estimators: {Instrument} selection with adaptive lasso},
	volume = {187},
	issn = {03044076},
	shorttitle = {Hybrid generalized empirical likelihood estimators},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030440761500069X},
	doi = {10.1016/j.jeconom.2015.01.007},
	abstract = {In this paper, we use the adaptive lasso estimator to choose the relevant instruments and eliminate the irrelevant instruments. The limit theory of Zou (2006) is extended from univariate iid case to heteroskedastic and non Gaussian data. Then we use the selected instruments in generalized empirical likelihood estimators (GEL). In this sense, these are called hybrid GEL. It is also shown that the lasso estimators are not model selection consistent whereas the adaptive lasso can select the correct model with fixed number of instruments. In simulations we show that hybrid GEL estimators have smaller bias and mean squared error than the other estimators in certain cases.},
	language = {en},
	number = {1},
	urldate = {2020-01-15},
	journal = {Journal of Econometrics},
	author = {Caner, Mehmet and Fan, Qingliang},
	month = jul,
	year = {2015},
	pages = {256--274},
	file = {Caner et Fan - 2015 - Hybrid generalized empirical likelihood estimators.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\EDNQ7328\\Caner et Fan - 2015 - Hybrid generalized empirical likelihood estimators.pdf:application/pdf},
}

@article{caner_moment_2016,
	title = {Moment and {IV} {Selection} {Approaches}: {A} {Comparative} {Simulation} {Study}},
	volume = {35},
	issn = {0747-4938, 1532-4168},
	shorttitle = {Moment and {IV} {Selection} {Approaches}},
	url = {http://www.tandfonline.com/doi/full/10.1080/07474938.2015.1092804},
	doi = {10.1080/07474938.2015.1092804},
	language = {en},
	number = {8-10},
	urldate = {2020-01-15},
	journal = {Econometric Reviews},
	author = {Caner, Mehmet and Maasoumi, Esfandiar and Riquelme, Juan Andrés},
	month = nov,
	year = {2016},
	pages = {1562--1581},
	file = {Caner et al. - 2016 - Moment and IV Selection Approaches A Comparative .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ACCFPAMV\\Caner et al. - 2016 - Moment and IV Selection Approaches A Comparative .pdf:application/pdf},
}

@article{gandhi_measuring_2019,
	title = {Measuring {Substitution} {Patterns} in {Differentiated} {Products} {Industries}},
	url = {http://www.nber.org/papers/w26375.pdf},
	doi = {10.3386/w26375},
	abstract = {We study the estimation of substitution patterns within the discrete choice framework developed by Berry (1994) and Berry, Levinsohn, and Pakes (1995). Our objective, is to illustrate the consequences of using weak instruments in this non-linear GMM context, and propose a new class of instruments that can be used to estimate a large family of models with aggregate data. We argue that relevant instruments should reflect the (exogenous) degree of differentiation of each product in a market (Differentiation IVs), and provide a series of examples to illustrate the performance of simple instrument functions.},
	language = {en},
	urldate = {2020-01-20},
	journal = {Working Paper},
	author = {Gandhi, Amit and Houde, Jean-François},
	month = oct,
	year = {2019},
	file = {Gandhi et Houde - 2019 - Measuring Substitution Patterns in Differentiated .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\KWCL3HWL\\Gandhi et Houde - 2019 - Measuring Substitution Patterns in Differentiated .pdf:application/pdf},
}

@article{angrist_credibility_2010,
	title = {The {Credibility} {Revolution} in {Empirical} {Economics}: {How} {Better} {Research} {Design} is {Taking} the {Con} out of {Econometrics}},
	volume = {24},
	issn = {0895-3309},
	shorttitle = {The {Credibility} {Revolution} in {Empirical} {Economics}},
	url = {http://pubs.aeaweb.org/doi/10.1257/jep.24.2.3},
	doi = {10.1257/jep.24.2.3},
	language = {en},
	number = {2},
	urldate = {2020-01-20},
	journal = {Journal of Economic Perspectives},
	author = {Angrist, Joshua D and Pischke, Jörn-Steffen},
	month = may,
	year = {2010},
	pages = {3--30},
	file = {Angrist et Pischke - 2010 - The Credibility Revolution in Empirical Economics.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\84VUEXZ4\\Angrist et Pischke - 2010 - The Credibility Revolution in Empirical Economics.pdf:application/pdf},
}

@article{gandhi_measuring_2015,
	title = {Measuring {Substitution} {Patterns} in {Diﬀerentiated} {Products} {Industries} – {The} {Missing} {Instruments} –},
	language = {en},
	author = {Gandhi, Amit and Houde, Jean-Francois},
	year = {2015},
	pages = {39},
	file = {Gandhi et Houde - Measuring Substitution Patterns in Diﬀerentiated P.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\JIVWWQ7X\\Gandhi et Houde - Measuring Substitution Patterns in Diﬀerentiated P.pdf:application/pdf},
}

@article{inoue_testing_nodate,
	title = {Testing for {Weak} {Identiﬁcation} in {Possibly} {Nonlinear} {Models}},
	abstract = {In this paper we propose a chi-square test for identiﬁcation. Our proposed test statistic is based on the distance between two shrinkage extremum estimators. The two estimators converge in probability to the same limit when identiﬁcation is strong, and their asymptotic distributions are diﬀerent when identiﬁcation is weak. The proposed test is consistent not only for the alternative hypothesis of no identiﬁcation but also for the alternative of weak identiﬁcation, which is conﬁrmed by our Monte Carlo results. We apply the proposed technique to test whether the structural parameters of a representative Taylor-rule monetary policy reaction function are identiﬁed.},
	language = {en},
	author = {Inoue, Atsushi and Rossi, Barbara},
	pages = {48},
	file = {Inoue et Rossi - Testing for Weak Identiﬁcation in Possibly Nonline.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\C6SZFDNR\\Inoue et Rossi - Testing for Weak Identiﬁcation in Possibly Nonline.pdf:application/pdf},
}


@article{chaudhuri_new_2011,
  doi = {10.1016/j.jeconom.2011.05.012},
  url = {https://doi.org/10.1016/j.jeconom.2011.05.012},
  year = {2011},
  volume = {164},
  number = {2},
  pages = {239--251},
  month = may,
  publisher = {Elsevier {BV}},
  author = {Saraswata Chaudhuri and Eric Zivot},
  title = {A new method of projection-based inference in {GMM} with weakly identified nuisance parameters},
  journal = {Journal of Econometrics}
}

@article{andrews_consistent_2001,
	title = {Consistent model and moment selection procedures for {GMM} estimation with application to dynamic panel data models},
	volume = {101},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407600000774},
	doi = {10.1016/S0304-4076(00)00077-4},
	language = {en},
	number = {1},
	urldate = {2020-09-15},
	journal = {Journal of Econometrics},
	author = {Andrews, Donald W.K. and Lu, Biao},
	month = mar,
	year = {2001},
	pages = {123--164},
	file = {Andrews et Lu - 2001 - Consistent model and moment selection procedures f.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ACCVISNF\\Andrews et Lu - 2001 - Consistent model and moment selection procedures f.pdf:application/pdf},
}

@article{sargan_estimation_1958,
	title = {The {Estimation} of {Economic} {Relationships} using {Instrumental} {Variables}},
	volume = {26},
	issn = {00129682},
	url = {https://www.jstor.org/stable/1907619?origin=crossref},
	doi = {10.2307/1907619},
	language = {en},
	number = {3},
	urldate = {2020-11-04},
	journal = {Econometrica},
	author = {Sargan, J. D.},
	month = jul,
	year = {1958},
	pages = {393},
	file = {Sargan - 1958 - The Estimation of Economic Relationships using Ins.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\XHJRELEB\\Sargan - 1958 - The Estimation of Economic Relationships using Ins.pdf:application/pdf},
}

@article{horowitz_applied_2011,
	title = {Applied {Nonparametric} {Instrumental} {Variables} {Estimation}},
	volume = {79},
	issn = {0012-9682},
	url = {http://doi.wiley.com/10.3982/ECTA8662},
	doi = {10.3982/ECTA8662},
	language = {en},
	number = {2},
	urldate = {2020-11-26},
	journal = {Econometrica},
	author = {Horowitz, Joel L.},
	year = {2011},
	pages = {347--394},
	file = {2011 - Applied Nonparametric Instrumental Variables Estim.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\6MVN5R2A\\2011 - Applied Nonparametric Instrumental Variables Estim.pdf:application/pdf},
}

@article{newey_nonparametric_2013,
	title = {Nonparametric {Instrumental} {Variables} {Estimation}},
	volume = {103},
	issn = {0002-8282},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.103.3.550},
	doi = {10.1257/aer.103.3.550},
	abstract = {In many economic models, objects of interest are functions which satisfy conditional moment restrictions. Economics does not restrict the functional form of these models, motivating nonparametric methods. In this paper we review identification results and describe a simple nonparametric instrumental variables (NPIV) estimator. We also consider a simple method of inference. In addition we show how the ability to uncover nonlinearities with conditional moment restrictions is related to the strength of the instruments. We point to applications where important nonlinearities can be found with NPIV and applications where they cannot.},
	language = {en},
	number = {3},
	urldate = {2020-12-14},
	journal = {American Economic Review},
	author = {Newey, Whitney K},
	month = may,
	year = {2013},
	pages = {550--556},
	file = {Newey - 2013 - Nonparametric Instrumental Variables Estimation.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\9XBE5MLZ\\Newey - 2013 - Nonparametric Instrumental Variables Estimation.pdf:application/pdf},
}

@article{hall_judging_nodate,
	title = {Judging {Instrument} {Relevance} in {Instrumental} {Variables} {Estimation}},
	language = {en},
	author = {Hall, Alastair R and Rudebusch, Glenn D and Wilcox, David W},
	pages = {16},
	file = {Hall et al. - Judging Instrument Relevance in Instrumental Varia.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\NGA5R9B8\\Hall et al. - Judging Instrument Relevance in Instrumental Varia.pdf:application/pdf},
}

@article{donald_choosing_2001-1,
	title = {Choosing the {Number} of {Instruments}},
	volume = {69},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/1468-0262.00238},
	doi = {10.1111/1468-0262.00238},
	abstract = {Properties of instrumental variable estimators are sensitive to the choice of valid instruments, even in large cross-section applications. In this paper we address this problem by deriving simple mean-square error criteria that can be minimized to choose the instrument set. We develop these criteria for two-stage least squares Ž2SLS., limited information maximum likelihood ŽLIML., and a bias adjusted version of 2SLS ŽB2SLS.. We give a theoretical derivation of the mean-square error and show optimality. In Monte Carlo experiments we ﬁnd that the instrument choice generally yields an improvement in performance. Also, in the Angrist and Krueger Ž1991. returns to education application, when the instrument set is chosen in the way we consider, it turns out that both 2SLS and LIML give similar Žlarge. returns to education.},
	language = {en},
	number = {5},
	urldate = {2021-02-10},
	journal = {Econometrica},
	author = {Donald, Stephen G. and Newey, Whitney K.},
	month = sep,
	year = {2001},
	pages = {1161--1191},
	file = {Donald et Newey - 2001 - Choosing the Number of Instruments.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\XCZLKUXM\\Donald et Newey - 2001 - Choosing the Number of Instruments.pdf:application/pdf},
}

@article{harding_finite_nodate,
	title = {Finite {Sample} {Bias} {Corrected} {IV} {Estimation} for {Weak} and {Many} {Instruments}},
	abstract = {This paper considers the finite sample distribution of the 2SLS estimator and derives bounds on its exact bias in the presence of weak and/or many instruments. We then contrast the behavior of the exact bias expressions and the asymptotic expansions currently popular in the literature, including a consideration of the no-moment problem exhibited by many Nagar-type estimators. After deriving a finite sample unbiased k-class estimator, we introduce a double k-class estimator based on Nagar (1962) that dominates k-class estimators (including 2SLS), especially in the cases of weak and/or many instruments. We demonstrate these properties in Monte Carlo simulations showing that our preferred estimators outperforms Fuller (1977) estimators in terms of mean bias and MSE.},
	language = {en},
	author = {Harding, Matthew and Hausman, Jerry and Palmer, Christopher},
	pages = {27},
	file = {Harding et al. - Finite Sample Bias Corrected IV Estimation for Wea.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\U9A6F4IA\\Harding et al. - Finite Sample Bias Corrected IV Estimation for Wea.pdf:application/pdf},
}

@article{dhaultfoeuille_new_2010,
	title = {A new instrumental method for dealing with endogenous selection},
	volume = {154},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407609001468},
	doi = {10.1016/j.jeconom.2009.06.005},
	abstract = {This paper develops a new method for dealing with endogenous selection. The usual instrumental strategy based on the independence between the outcome and the instrument is likely to fail when selection is directly driven by the dependent variable. Instead, we suggest to rely on the independence between the instrument and the selection variable, conditional on the outcome. This approach may be particularly suitable for nonignorable nonresponse, binary models with missing covariates or Roy models with an unobserved sector. The nonparametric identiﬁcation of the joint distribution of the variables is obtained under a completeness assumption, which has been used recently in several nonparametric instrumental problems. Even if the conditional independence between the instrument and the selection variable fails to hold, the approach provides sharp bounds on parameters of interest under weaker monotonicity conditions. Apart from identiﬁcation, nonparametric and parametric estimations are also considered. Finally, the method is applied to estimate the eﬀect of grade retention in French primary schools.},
	language = {en},
	number = {1},
	urldate = {2021-02-10},
	journal = {Journal of Econometrics},
	author = {d’Haultfoeuille, Xavier},
	month = jan,
	year = {2010},
	pages = {1--15},
	file = {d’Haultfoeuille - 2010 - A new instrumental method for dealing with endogen.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\IPY3G2TX\\d’Haultfoeuille - 2010 - A new instrumental method for dealing with endogen.pdf:application/pdf},
}

@phdthesis{tchatoka_exogeneity_2010,
	title = {Exogeneity, {Weak} {Identiﬁcation} and {Instrument} {Selection} in {Econometrics}},
	language = {fr},
	author = {Tchatoka, Firmin Sabro Doko},
	year = {2010},
	file = {Tchatoka - Exogeneity, Weak Identiﬁcation and Instrument Sele.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\LDSFURTU\\Tchatoka - Exogeneity, Weak Identiﬁcation and Instrument Sele.pdf:application/pdf},
}

@article{windmeijer_selecting_2016,
	title = {Selecting ({In}){Valid} {Instruments} for {Instrumental} {Variables} {Estimation}},
	abstract = {We investigate the behaviour of the Lasso for identifying invalid instruments in linear models, as proposed recently by Kang, Zhang, Cai and Small (2015, Journal of the American Statistical Association, in press), where invalid instruments are such that they enter the model as explanatory variables. We show that for this setup, the Lasso may not select all invalid instruments in large samples if they are relatively strong. Consistent selection also depends on the correlation structure of the instruments. We propose an initial estimator that is consistent when less than 50\% of the instruments are invalid, but its consistency does not depend on the relative strength of the instruments or their correlation structure. This estimator can therefore be used for adaptive Lasso estimation. We develop an alternative selection method based on Hansen’s J-test of overidentifying restrictions, but limiting the number of models to be evaluated. This latter selection procedure is consistent under weaker conditions on the number of invalid instruments and is aligned with the general identi…cation result for this particular model.},
	language = {en},
	author = {Windmeijer, Frank and Farbmacher, Helmut and Davies, Neil and Smith, George Davey and White, Ian},
	year = {2016},
	pages = {35},
	file = {Windmeijer et al. - Selecting (In)Valid Instruments for Instrumental V.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\G635X8BV\\Windmeijer et al. - Selecting (In)Valid Instruments for Instrumental V.pdf:application/pdf},
}

@article{olea_robust_2013,
	title = {A {Robust} {Test} for {Weak} {Instruments}},
	volume = {31},
	issn = {0735-0015, 1537-2707},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.2013.806694},
	doi = {10.1080/00401706.2013.806694},
	language = {en},
	number = {3},
	urldate = {2021-02-10},
	journal = {Journal of Business \& Economic Statistics},
	author = {Olea, José Luis Montiel and Pflueger, Carolin},
	month = jul,
	year = {2013},
	pages = {358--369},
	file = {Olea et Pflueger - 2013 - A Robust Test for Weak Instruments.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\5M8UNKCA\\Olea et Pflueger - 2013 - A Robust Test for Weak Instruments.pdf:application/pdf},
}

@article{stock_testing_2003,
	title = {Testing for {Weak} {Instruments} in {Linear} {IV} {Regression}},
	abstract = {Weak instruments can produce biased IV estimators and hypothesis tests with large size distortions. But what, precisely, are weak instruments, and how does one detect them in practice? This paper proposes quantitative definitions of weak instruments based on the maximum IV estimator bias, or the maximum Wald test size distortion, when there are multiple endogenous regressors. We tabulate critical values that enable using the first-stage F-statistic (or, when there are multiple endogenous regressors, the Cragg-Donald (1993) statistic) to test whether given instruments are weak.},
	language = {en},
	author = {Stock, James H and Yogo, Motohiro},
	year = {2003},
	pages = {53},
	file = {Stock - Testing for Weak Instruments in Linear IV Regressi.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\H7ANW4MY\\Stock - Testing for Weak Instruments in Linear IV Regressi.pdf:application/pdf},
}

@article{andrews_validity_2009,
	title = {Validity of {Subsampling} and "{Plug}-in {Asymptotic}" {Inference} for {Parameters} {Defined} by {Moment} {Inequalities}},
	volume = {25},
	issn = {0266-4666},
	url = {https://www.jstor.org/stable/20532460},
	abstract = {This paper considers inference for parameters defined by moment inequalities and equalities. The parameters need not be identified. For a specified class of test statistics, this paper establishes the uniform asymptotic validity of subsampling, m out of n bootstrap, and "plug-in asymptotic" tests and confidence intervals for such parameters. Establishing uniform asymptotic" validity is crucial in moment inequality problems because the pointwise asymptotic distributions of the test statistics of interest have discontinuities as functions of the true distribution that generates the observations. The size results are quite general because they hold without specifying the particular form of the moment conditions-only 2 + δ moments finite are required. The results allow for independent and identically distributed (i.i.d.) and dependent observations and for preliminary consistent estimation of identified parameters.},
	number = {3},
	urldate = {2021-02-10},
	journal = {Econometric Theory},
	author = {Andrews, Donald W. K. and Guggenberger, Patrik},
	year = {2009},
	note = {Publisher: Cambridge University Press},
	pages = {669--709},
}

@article{bekker_alternative_1994,
	title = {Alternative {Approximations} to the {Distributions} of {Instrumental} {Variable} {Estimators}},
	volume = {62},
	issn = {0012-9682},
	url = {http://www.jstor.org/stable/2951662},
	doi = {10.2307/2951662},
	abstract = {The paper considers the OLS, the IV, and two method-of-moments estimators, MM and MMK, of the coefficients of a single equation, where the explanatory variables are correlated with the disturbance term. The MM and MMK estimators are generalizations of the LIML and LIMLK estimators, respectively. Multivariate first-order approximations to the distributions are derived under normality, using a parameter sequence where the number of instruments increases as the number of observations increases. Numerical results show these approximations are more accurate, compared to large-sample approximations, even if the number of instruments is small. The moments of the multivariate limit distributions of the MM and MMK estimators can be consistently estimated under a variety of parameter sequences, including the large-sample sequence. The new approximate confidence regions perform well in terms of exact levels, compared to traditional ones. The IV estimator of the coefficient of a single explanatory endogenous variable is interpreted as a shrinkage estimator, which is dominated, in practical cases, by the MM and MMK estimators in terms of nearness to the true value in the sense of Pitman.},
	number = {3},
	urldate = {2021-02-10},
	journal = {Econometrica},
	author = {Bekker, Paul A.},
	year = {1994},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {657--681},
	file = {JSTOR Full Text PDF:C\:\\Users\\Hippo\\Zotero\\storage\\QAWSJ2ZT\\Bekker - 1994 - Alternative Approximations to the Distributions of.pdf:application/pdf},
}

@article{newey_higher_2004,
	title = {Higher {Order} {Properties} of {Gmm} and {Generalized} {Empirical} {Likelihood} {Estimators}},
	volume = {72},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/j.1468-0262.2004.00482.x},
	doi = {10.1111/j.1468-0262.2004.00482.x},
	abstract = {In an effort to improve the small sample properties of generalized method of moments (GMM) estimators, a number of alternative estimators have been suggested. These include empirical likelihood (EL), continuous updating, and exponential tilting estimators. We show that these estimators share a common structure, being members of a class of generalized empirical likelihood (GEL) estimators. We use this structure to compare their higher order asymptotic properties. We ﬁnd that GEL has no asymptotic bias due to correlation of the moment functions with their Jacobian, eliminating an important source of bias for GMM in models with endogeneity. We also ﬁnd that EL has no asymptotic bias from estimating the optimal weight matrix, eliminating a further important source of bias for GMM in panel data models. We give bias corrected GMM and GEL estimators. We also show that bias corrected EL inherits the higher order property of maximum likelihood, that it is higher order asymptotically efﬁcient relative to the other bias corrected estimators.},
	language = {en},
	number = {1},
	urldate = {2021-02-11},
	journal = {Econometrica},
	author = {Newey, WhitneyK. and Smith, Richard J.},
	month = jan,
	year = {2004},
	pages = {219--255},
	file = {Newey et Smith - 2004 - Higher Order Properties of Gmm and Generalized Emp.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\8RPSN62B\\Newey et Smith - 2004 - Higher Order Properties of Gmm and Generalized Emp.pdf:application/pdf},
}

@article{anderson_evaluation_1979,
	title = {Evaluation of the {Distribution} {Function} of the {Two}-{Stage} {Least} {Squares} {Estimate}},
	volume = {47},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/1912353},
	doi = {10.2307/1912353},
	number = {1},
	urldate = {2021-02-22},
	journal = {Econometrica},
	author = {Anderson, T. W. and Sawa, Takamitsu},
	year = {1979},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {163--182},
	file = {JSTOR Full Text PDF:C\:\\Users\\Hippo\\Zotero\\storage\\KYH32928\\Anderson et Sawa - 1979 - Evaluation of the Distribution Function of the Two.pdf:application/pdf},
}

@article{anderson_asymptotic_1977,
	title = {Asymptotic {Expansions} of the {Distributions} of {Estimates} in {Simultaneous} {Equations} for {Alternative} {Parameter} {Sequences}},
	volume = {45},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/1911225},
	doi = {10.2307/1911225},
	abstract = {The distributions of the LIML and TSLS estimates of the coefficient of an endogenous variable in a single equation can be approximated by asymptotic expansions. This paper relates the expansions in terms of the noncentrality parameter and the sample size going to infinity, the noncentrality parameter going to infinity with the sample size held fixed, and the standard deviation of the disturbance going to zero (``small-σ'').},
	number = {2},
	urldate = {2021-02-22},
	journal = {Econometrica},
	author = {Anderson, T. W.},
	year = {1977},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {509--518},
	file = {JSTOR Full Text PDF:C\:\\Users\\Hippo\\Zotero\\storage\\VY3EN8FV\\Anderson - 1977 - Asymptotic Expansions of the Distributions of Esti.pdf:application/pdf},
}

@article{hahn_estimation_2004,
	title = {Estimation with weak instruments: {Accuracy} of higher‐order bias and {MSE} approximations},
	volume = {7},
	issn = {1368-4221, 1368-423X},
	shorttitle = {Estimation with weak instruments},
	url = {https://academic.oup.com/ectj/article/7/1/272-306/5073366},
	doi = {10.1111/j.1368-423X.2004.00131.x},
	abstract = {In this paper, we consider parameter estimation in a linear simultaneous equations model. It is well known that two-stage least squares (2SLS) estimators may perform poorly when the instruments are weak. In this case 2SLS tends to suffer from the substantial small sample biases. It is also known that LIML and Nagar-type estimators are less biased than 2SLS but suffer from large small sample variability. We construct a bias-corrected version of 2SLS based on the Jackknife principle. Using higher-order expansions we show that the MSE of our Jackknife 2SLS estimator is approximately the same as the MSE of the Nagar type estimator. We also compare the Jackknife 2SLS with an estimator suggested by Fuller (Econometrica 45, 933-54) that significantly decreases the small sample variability of LIML. Monte Carlo simulations show that even in relatively large samples the MSE of LIML and Nagar can be substantially larger than for Jackknife 2SLS. The Jackknife 2SLS estimator and Fuller's estimator give the best overall performance. Based on our Monte Carlo experiments we conduct informal statistical tests of the accuracy of approximate bias and MSE formulas. We find that higher-order expansions traditionally used to rank LIML, 2SLS and other IV estimators are unreliable when identification of the model is weak. Overall, our results show that only estimators with well-defined finite sample moments should be used when identification of the model is weak.},
	language = {en},
	number = {1},
	urldate = {2021-02-24},
	journal = {The Econometrics Journal},
	author = {Hahn, Jinyong and Hausman, Jerry and Kuersteiner, Guido},
	month = jun,
	year = {2004},
	pages = {272--306},
	file = {Hahn et al. - 2004 - Estimation with weak instruments Accuracy of high.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\XFDPL2YC\\Hahn et al. - 2004 - Estimation with weak instruments Accuracy of high.pdf:application/pdf},
}

@article{acemoglu_colonial_2001,
	title = {The {Colonial} {Origins} of {Comparative} {Development}: {An} {Empirical} {Investigation}},
	volume = {91},
	url = {http://www.jstor.org/stable/2677930},
	language = {en},
	number = {5},
	journal = {The American Economic Review},
	author = {Acemoglu, Daron and Johnson, Simon and Robinson, James A.},
	year = {2001},
	pages = {1369--1401},
	file = {Acemoglu et al. - 2001 - The Colonial Origins of Comparative Development A.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\5ZYN8SWG\\Acemoglu et al. - 2001 - The Colonial Origins of Comparative Development A.pdf:application/pdf},
}

@article{autor_china_2013,
	title = {The {China} {Syndrome}: {Local} {Labor} {Market} {Effects} of {Import} {Competition} in the {United} {States}},
	volume = {103},
	issn = {0002-8282},
	shorttitle = {The {China} {Syndrome}},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.103.6.2121},
	doi = {10.1257/aer.103.6.2121},
	abstract = {We analyze the effect of rising Chinese import competition between 1990 and 2007 on US local labor markets, exploiting cross-market variation in import exposure stemming from initial differences in industry specialization and instrumenting for US imports using changes in Chinese imports by other high-income countries. Rising imports cause higher unemployment, lower labor force participation, and reduced wages in local labor markets that house import-competing manufacturing industries. In our main specification, import competition explains one-quarter of the contemporaneous aggregate decline in US manufacturing employment. Transfer benefits payments for unemployment, disability, retirement, and healthcare also rise sharply in more trade-exposed labor markets. (JEL E24, F14, F16, J23, J31, L60, O47, R12, R23)},
	language = {en},
	number = {6},
	urldate = {2021-03-01},
	journal = {American Economic Review},
	author = {Autor, David H and Dorn, David and Hanson, Gordon H},
	month = oct,
	year = {2013},
	pages = {2121--2168},
	file = {Autor et al. - 2013 - The China Syndrome Local Labor Market Effects of .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\LA252KJ3\\Autor et al. - 2013 - The China Syndrome Local Labor Market Effects of .pdf:application/pdf},
}

@article{stock_asymptotic_2005,
	title = {Asymptotic {Distributions} of {Instrumental} {Variables} {Statistics} with {Many} {Weak} {Instruments}},
	url = {https://scholar.harvard.edu/files/stock/files/asymptoticdistributions.pdf},
	urldate = {2021-03-01},
	author = {Stock, James and Yogo, Motohiro},
	year = {2005},
	file = {asymptoticdistributions.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\QFUHFPTG\\asymptoticdistributions.pdf:application/pdf},
}

@article{skeels_stockyogo_2018,
	title = {On the {Stock}–{Yogo} {Tables}},
	volume = {6},
	issn = {2225-1146},
	url = {http://www.mdpi.com/2225-1146/6/4/44},
	doi = {10.3390/econometrics6040044},
	abstract = {A standard test for weak instruments compares the ﬁrst-stage F-statistic to a table of critical values obtained by Stock and Yogo (2005) using simulations. We derive a closed-form solution for the expectation from which these critical values are derived, as well as present some second-order asymptotic approximations that may be of value in the presence of multiple endogenous regressors. Inspection of this new result provides insights not available from simulation, and will allow software implementations to be generalised and improved. Finally, we explore the calculation of p-values for the ﬁrst-stage F-statistic weak instruments test.},
	language = {en},
	number = {4},
	urldate = {2021-03-01},
	journal = {Econometrics},
	author = {Skeels, Christopher and Windmeijer, Frank},
	month = nov,
	year = {2018},
	pages = {44},
	file = {Skeels et Windmeijer - 2018 - On the Stock–Yogo Tables.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\I66W7JG2\\Skeels et Windmeijer - 2018 - On the Stock–Yogo Tables.pdf:application/pdf},
}

@unpublished{linnemer_most_2017,
	title = {The {Most} {Cited} {Articles} from the {Top}-5 {Journals} (1991-2015)},
	url = {https://hal.archives-ouvertes.fr/hal-01634432},
	abstract = {This paper documents what are the most cited articles published in the top-5 economics journals during the period 1991-2015. EconLit is used to collect bibliographic information about these articles, and we gathered yearly citations for each article through the Web of Science database. We present different sorts of citation lists. Our most basic one ranks articles on the basis of the cumulated number of citations received between year of publication and 2015. To facilitate the comparison of articles of different ages, we also consider rankings by subperiods, and on the basis of normalized citations per year. Finally we report lists by field of economic research, as defined by the JEL codes of the articles. The paper contains Internet links to all articles, allowing an easy and direct access to arguably the most influential economics literature published in the last 25 years.},
	urldate = {2021-03-01},
	author = {Linnemer, Laurent and Visser, Michael},
	month = nov,
	year = {2017},
	annote = {working paper or preprint},
	file = {HAL PDF Full Text:C\:\\Users\\Hippo\\Zotero\\storage\\YEC9WL65\\Linnemer et Visser - 2017 - The Most Cited Articles from the Top-5 Journals (1.pdf:application/pdf},
}

@article{chao_consistent_2005,
	title = {Consistent {Estimation} with a {Large} {Number} of {Weak} {Instruments}},
	volume = {73},
	issn = {0012-9682, 1468-0262},
	url = {http://doi.wiley.com/10.1111/j.1468-0262.2005.00632.x},
	doi = {10.1111/j.1468-0262.2005.00632.x},
	abstract = {This paper analyzes the conditions under which consistent estimation can be achieved in instrumental variables (IV) regression when the available instruments are weak and the number of instruments, Kn, goes to inﬁnity with the sample size. We show that consistent estimation depends importantly on the strength of the instruments as measured by rn, the rate of growth of the so-called concentration parameter, and also on Kn. In particular, when Kn → ∞, the concentration parameter can grow, even if each individual instrument is only weakly correlated with the endogenous explanatory variables, and consistency of certain estimators can be established under weaker conditions than have previously been assumed in the literature. Hence, the use of many weak instruments may actually improve the performance of certain point estimators. More speciﬁcally, we ﬁnd that the limited information maximum likelihood (LIML) estimator an√d the bias-corrected two-stage least squares (B2SLS) estimator are consistent when Kn/rn → 0 while the two-stage least squares (2SLS) estimator is consistent only if Kn/rn → 0 as n → ∞. These consistency results suggest that LIML and B2SLS are more robust to instrument weakness than 2SLS.},
	language = {en},
	number = {5},
	urldate = {2021-03-01},
	journal = {Econometrica},
	author = {Chao, John C. and Swanson, Norman R.},
	month = sep,
	year = {2005},
	pages = {1673--1692},
	file = {Chao et Swanson - 2005 - Consistent Estimation with a Large Number of Weak .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ZPR7Z3WJ\\Chao et Swanson - 2005 - Consistent Estimation with a Large Number of Weak .pdf:application/pdf},
}

@article{andrews_validity_2009-1,
	title = {Validity of {Subsampling} and "{Plug}-in {Asymptotic}" {Inference} for {Parameters} {Defined} by {Moment} {Inequalities}},
	volume = {25},
	issn = {0266-4666, 1469-4360},
	url = {https://www.cambridge.org/core/product/identifier/S0266466608090257/type/journal_article},
	doi = {10.1017/S0266466608090257},
	abstract = {This paper considers inference for parameters defined by moment inequalities and equalities. The parameters need not be identified. For a specified class of test statistics, this paper establishes the uniform asymptotic validity of subsampling,
              m
              out of
              n
              bootstrap, and “plug-in asymptotic” tests and confidence intervals for such parameters. Establishing uniform asymptotic validity is crucial in moment inequality problems because the pointwise asymptotic distributions of the test statistics of interest have discontinuities as functions of the true distribution that generates the observations.
            
            
              The size results are quite general because they hold without specifying the particular form of the moment conditions—only 2 +
              δ
              moments finite are required. The results allow for independent and identically distributed (i.i.d.) and dependent observations and for preliminary consistent estimation of identified parameters.},
	language = {en},
	number = {3},
	urldate = {2021-03-03},
	journal = {Econometric Theory},
	author = {Andrews, Donald W.K. and Guggenberger, Patrik},
	month = jun,
	year = {2009},
	pages = {669--709},
	file = {Andrews et Guggenberger - 2009 - VALIDITY OF SUBSAMPLING AND “PLUG-IN ASYMPTOTIC” I.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\R7N4TFBR\\Andrews et Guggenberger - 2009 - VALIDITY OF SUBSAMPLING AND “PLUG-IN ASYMPTOTIC” I.pdf:application/pdf},
}

@article{cattaneo_alternative_nodate,
	title = {Alternative {Asymptotics} and the {Partially} {Linear} {Model} with {Many} {Regressors}},
	abstract = {Many empirical studies estimate the structural e¤ect of some variable on an outcome of interest while allowing for many covariates. We present inference methods that account for many covariates. The methods are based on asymptotics where the number of covariates grows as fast as the sample size. We …nd a limiting normal distribution with variance that is larger than the standard one. We also …nd that with homoskedasticity this larger variance can be accounted for by using degrees of freedom adjusted standard errors. We link this asymptotic theory to previous results for many instruments and for small bandwidths distributional approximations.},
	language = {en},
	author = {Cattaneo, Matias D and Jansson, Michael and Newey, Whitney K},
	pages = {30},
	file = {Cattaneo et al. - Alternative Asymptotics and the Partially Linear M.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\RJ288RIA\\Cattaneo et al. - Alternative Asymptotics and the Partially Linear M.pdf:application/pdf},
}

@article{andrews_asymptotic_2010,
	title = {Asymptotic {Size} and a {Problem} with {Subsampling} and with the m out of n {Bootstrap}},
	volume = {26},
	issn = {0266-4666, 1469-4360},
	url = {https://www.cambridge.org/core/product/identifier/S0266466609100051/type/journal_article},
	doi = {10.1017/S0266466609100051},
	abstract = {This paper considers inference based on a test statistic that has a limit distribution that is discontinuous in a parameter. The paper shows that subsampling and
              m
              out of
              n
              bootstrap tests based on such a test statistic often have asymptotic size—defined as the limit of exact size—that is greater than the nominal level of the tests. This is due to a lack of uniformity in the pointwise asymptotics. We determine precisely the asymptotic size of such tests under a general set of high-level conditions that are relatively easy to verify. The results show that the asymptotic size of subsampling and
              m
              out of
              n
              bootstrap tests is distorted in some examples but not in others.},
	language = {en},
	number = {2},
	urldate = {2021-03-03},
	journal = {Econometric Theory},
	author = {Andrews, Donald W.K. and Guggenberger, Patrik},
	month = apr,
	year = {2010},
	pages = {426--468},
	file = {Andrews et Guggenberger - 2010 - ASYMPTOTIC SIZE AND A PROBLEM WITH SUBSAMPLING AND.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\D8PDU9KW\\Andrews et Guggenberger - 2010 - ASYMPTOTIC SIZE AND A PROBLEM WITH SUBSAMPLING AND.pdf:application/pdf},
}

@article{bekker_instrumental_2005,
	title = {Instrumental variable estimation based on grouped data},
	volume = {59},
	issn = {0039-0402, 1467-9574},
	url = {http://doi.wiley.com/10.1111/j.1467-9574.2005.00296.x},
	doi = {10.1111/j.1467-9574.2005.00296.x},
	abstract = {The paper considers the estimation of the coeﬃcients of a single equation in the presence of dummy intruments. We derive pseudo ML and GMM estimators based on moment restrictions induced either by the structural form or by the reduced form of the model. The performance of the estimators is evaluated for the non-Gaussian case. We allow for heteroscedasticity. The asymptotic distributions are based on parameter sequences where the number of instruments increases at the same rate as the sample size. Relaxing the usual Gaussian assumption is shown to aﬀect the normal asymptotic distributions. As a result also recently suggested new speciﬁcation tests for the validity of instruments depend on Gaussianity. Monte Carlo simulations conﬁrm the accuracy of the asymptotic approach.},
	language = {en},
	number = {3},
	urldate = {2021-03-08},
	journal = {Statistica Neerlandica},
	author = {Bekker, Paul A. and Ploeg, Jan},
	month = aug,
	year = {2005},
	pages = {239--267},
	file = {Bekker et Ploeg - 2005 - Instrumental variable estimation based on grouped .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\L3T67UTB\\Bekker et Ploeg - 2005 - Instrumental variable estimation based on grouped .pdf:application/pdf},
}

@article{abadie_instrumental_2019,
	title = {Instrumental {Variable} {Estimation} with {First}-{Stage} {Heterogeneity}},
	abstract = {We propose a simple data-driven procedure that exploits heterogeneity in the ﬁrst stage correlation between an instrument and an endogenous variable to improve the asymptotic mean squared error (MSE) of instrumental variable estimators. We show that the resulting gains in asymptotic MSE can be quite large in settings where there is substantial heterogeneity in the ﬁrst-stage parameters. We also show that a naive procedure used in some applied work, which consists of selecting the composition of the sample based on the value of the ﬁrst-stage tstatistic, may cause substantial over-rejection of a null hypothesis on a second stage parameter. We apply the methods to study 1) the return to schooling using the minimum school leaving age as the exogenous instrument and 2) the eﬀect of local economic conditions on voter turnout using energy supply shocks as the source of identiﬁcation.},
	language = {en},
	author = {Abadie, Alberto and Gu, Jiaying},
	year = {2019},
	pages = {74},
	file = {Abadie et Gu - Instrumental Variable Estimation with First-Stage .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\5M6475LW\\Abadie et Gu - Instrumental Variable Estimation with First-Stage .pdf:application/pdf},
}

@article{poskitt_inference_2013,
	title = {Inference in the {Presence} of {Weak} {Instruments}: {A} {Selected} {Survey}},
	volume = {6},
	issn = {1551-3076, 1551-3084},
	shorttitle = {Inference in the {Presence} of {Weak} {Instruments}},
	url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-econometrics/ECO-017},
	doi = {10.1561/0800000017},
	language = {en},
	number = {1},
	urldate = {2021-03-08},
	journal = {Foundations and Trends® in Econometrics},
	author = {Poskitt, D. S.},
	year = {2013},
	pages = {1--99},
	file = {Poskitt - 2013 - Inference in the Presence of Weak Instruments A S.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\L5GU3YLB\\Poskitt - 2013 - Inference in the Presence of Weak Instruments A S.pdf:application/pdf},
}

@article{angrist_jacknife_1995,
	title = {Jacknife {Instrumental} {Variable} {Estimation}},
	url = {https://www.nber.org/system/files/working_papers/t0172/t0172.pdf},
	urldate = {2021-03-08},
	author = {Angrist, Joshua and Imbens, Guido W and Krueger, Alan B},
	year = {1995},
	file = {Angrist et al. - Jacknife Instrumental Variable Estimation.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\9CB7JNVW\\Angrist et al. - Jacknife Instrumental Variable Estimation.pdf:application/pdf},
}

@article{mikusheva_inference_2019,
	doi = {10.1093/restud/rdab097},
  url = {https://doi.org/10.1093/restud/rdab097},
  year = {2021},
  month = dec,
  publisher = {Oxford University Press ({OUP})},
  volume = {89},
  number = {5},
  pages = {2663--2686},
  author = {Anna Mikusheva and Liyang Sun},
  title = {Inference with Many Weak Instruments},
  journal = {The Review of Economic Studies}
}

@article{nagar_bias_1959,
	title = {The {Bias} and {Moment} {Matrix} of the {General} k-{Class} {Estimators} of the {Parameters} in {Simultaneous} {Equations}},
	volume = {27},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/1909352},
	doi = {10.2307/1909352},
	abstract = {In this article we study the small sample properties of the so called general k-class estimators of simultaneous equations. Two members of the family of k-class estimators are found, one of which is unbiased to the degree of our approximation and the other possesses a minimum second moment around the true parameter value, again to the order of our approximation.},
	number = {4},
	urldate = {2021-03-08},
	journal = {Econometrica},
	author = {Nagar, A. L.},
	year = {1959},
	pages = {575--595},
	file = {Nagar - 1959 - The Bias and Moment Matrix of the General k-Class .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\9LEBHRWM\\Nagar - 1959 - The Bias and Moment Matrix of the General k-Class .pdf:application/pdf},
}

@article{abadie_instrumental_2019-1,
	title = {Instrumental {Variable} {Estimation} with {First}-{Stage} {Heterogeneity}},
	abstract = {We propose a simple data-driven procedure that exploits heterogeneity in the ﬁrst stage correlation between an instrument and an endogenous variable to improve the asymptotic mean squared error (MSE) of instrumental variable estimators. We show that the resulting gains in asymptotic MSE can be quite large in settings where there is substantial heterogeneity in the ﬁrst-stage parameters. We also show that a naive procedure used in some applied work, which consists of selecting the composition of the sample based on the value of the ﬁrst-stage tstatistic, may cause substantial over-rejection of a null hypothesis on a second stage parameter. We apply the methods to study 1) the return to schooling using the minimum school leaving age as the exogenous instrument and 2) the eﬀect of local economic conditions on voter turnout using energy supply shocks as the source of identiﬁcation.},
	language = {en},
	author = {Abadie, Alberto and Gu, Jiaying},
	year = {2019},
	pages = {74},
	file = {Abadie et Gu - Instrumental Variable Estimation with First-Stage .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\YBWRZ5K9\\Abadie et Gu - Instrumental Variable Estimation with First-Stage .pdf:application/pdf},
}

@article{hahn_new_2002,
	title = {A {New} {Specification} {Test} for the {Validity} of {Instrumental} {Variables}},
	volume = {70},
	issn = {1468-0262},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0262.00272},
	doi = {https://doi.org/10.1111/1468-0262.00272},
	abstract = {We develop a new specification test for IV estimators adopting a particular second order approximation of Bekker. The new specification test compares the difference of the forward (conventional) 2SLS estimator of the coefficient of the right-hand side endogenous variable with the reverse 2SLS estimator of the same unknown parameter when the normalization is changed. Under the null hypothesis that conventional first order asymptotics provide a reliable guide to inference, the two estimates should be very similar. Our test sees whether the resulting difference in the two estimates satisfies the results of second order asymptotic theory. Essentially the same idea is applied to develop another new specification test using second-order unbiased estimators of the type first proposed by Nagar. If the forward and reverse Nagar-type estimators are not significantly different we recommend estimation by LIML, which we demonstrate is the optimal linear combination of the Nagar-type estimators (to second order). We also demonstrate the high degree of similarity for k-class estimators between the approach of Bekker and the Edgeworth expansion approach of Rothenberg. An empirical example and Monte Carlo evidence demonstrate the operation of the new specification test.},
	language = {en},
	number = {1},
	urldate = {2021-03-08},
	journal = {Econometrica},
	author = {Hahn, Jinyong and Hausman, Jerry},
	year = {2002},
	keywords = {2SLS, finite sample bias, instrumental variable estimation, second order approximation, specification tests, weak instruments},
	pages = {163--189},
	file = {Snapshot:C\:\\Users\\Hippo\\Zotero\\storage\\5EL3FF6D\\1468-0262.html:text/html;Version soumise:C\:\\Users\\Hippo\\Zotero\\storage\\4IEDV7VA\\Hahn et Hausman - 2002 - A New Specification Test for the Validity of Instr.pdf:application/pdf},
}

@article{andrews_unbiased_2017,
	title = {Unbiased instrumental variables estimation under known first-stage sign: {Unbiased} {IV} estimation},
	volume = {8},
	issn = {17597323},
	shorttitle = {Unbiased instrumental variables estimation under known first-stage sign},
	url = {http://doi.wiley.com/10.3982/QE700},
	doi = {10.3982/QE700},
	language = {en},
	number = {2},
	urldate = {2021-03-08},
	journal = {Quantitative Economics},
	author = {Andrews, Isaiah and Armstrong, Timothy B.},
	month = jul,
	year = {2017},
	pages = {479--503},
	file = {Andrews et Armstrong - 2017 - Unbiased instrumental variables estimation under k.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\AHCTDGWG\\Andrews et Armstrong - 2017 - Unbiased instrumental variables estimation under k.pdf:application/pdf},
}

@article{caner_testing_2009,
	title = {Testing, {Estimation} in {GMM} and {CUE} with {Nearly}-{Weak} {Identification}},
	volume = {29},
	issn = {0747-4938, 1532-4168},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07474930903451599},
	doi = {10.1080/07474930903451599},
	language = {en},
	number = {3},
	urldate = {2021-03-08},
	journal = {Econometric Reviews},
	author = {Caner, Mehmet},
	month = dec,
	year = {2009},
	pages = {330--363},
	file = {Caner - 2009 - Testing, Estimation in GMM and CUE with Nearly-Wea.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\YX6DUINZ\\Caner - 2009 - Testing, Estimation in GMM and CUE with Nearly-Wea.pdf:application/pdf},
}

@article{belloni_lasso_2011,
	title = {{LASSO} {Methods} for {Gaussian} {Instrumental} {Variables} {Models}},
	url = {http://arxiv.org/abs/1012.1297},
	abstract = {In this note, we propose to use sparse methods (e.g. LASSO, Post-LASSO, sqrt-LASSO, and Post-sqrt-LASSO) to form first-stage predictions and estimate optimal instruments in linear instrumental variables (IV) models with many instruments in the canonical Gaussian case. The methods apply even when the number of instruments is much larger than the sample size. We derive asymptotic distributions for the resulting IV estimators and provide conditions under which these sparsity-based IV estimators are asymptotically oracle-efficient. In simulation experiments, a sparsity-based IV estimator with a data-driven penalty performs well compared to recently advocated many-instrument-robust procedures. We illustrate the procedure in an empirical example using the Angrist and Krueger (1991) schooling data.},
	urldate = {2021-03-09},
	journal = {arXiv:1012.1297 [econ, math, stat]},
	author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian},
	month = feb,
	year = {2011},
	note = {arXiv: 1012.1297},
	keywords = {Mathematics - Statistics Theory, Economics - Econometrics, Statistics - Applications, Statistics - Methodology},
	file = {arXiv Fulltext PDF:C\:\\Users\\Hippo\\Zotero\\storage\\Z28SHK3X\\Belloni et al. - 2011 - LASSO Methods for Gaussian Instrumental Variables .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Hippo\\Zotero\\storage\\FKMEXAJC\\1012.html:text/html},
}

@article{hansen_estimation_2006,
	title = {Estimation with {Many} {Instrumental} {Variables}},
	abstract = {Using many valid instrumental variables has the potential to improve eﬃciency but makes the usual inference procedures inaccurate. We give corrected standard errors, an extension of Bekker (1994) to nonnormal disturbances, that adjust for many instruments. We ﬁnd that this adjustment is useful in empirical work, simulations, and in the asymptotic theory. Use of the corrected standard errors in t-ratios leads to an asymptotic approximation order that is the same when the number of instrumental variables grows as when the number of instruments is ﬁxed. We also give a version of the Kleibergen (2002) weak instrument statistic that is robust to many instruments.},
	language = {en},
	author = {Hansen, Christian and Hausman, Jerry and Newey, Whitney},
	year = {2006},
	pages = {57},
	file = {Hansen et Hausman - Estimation with Many Instrumental Variables.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\5VFKE5C4\\Hansen et Hausman - Estimation with Many Instrumental Variables.pdf:application/pdf},
}

@article{hansen_many_2004,
	title = {Many {Instruments}, {Weak} {Instruments}, and {Microeconometric} {Practices}},
	url = {https://eml.berkeley.edu/~powell/e242_f04/newey1.pdf},
	urldate = {2021-03-09},
	author = {Hansen, Christian and Hausman, Jerry and Newey, Whitney},
	year = {2004},
	file = {newey1.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\K4VLWCIP\\newey1.pdf:application/pdf},
}

@article{roodman_note_2009,
	title = {A {Note} on the {Theme} of {Too} {Many} {Instruments}},
	volume = {71},
	issn = {03059049, 14680084},
	url = {http://doi.wiley.com/10.1111/j.1468-0084.2008.00542.x},
	doi = {10.1111/j.1468-0084.2008.00542.x},
	abstract = {The difference and system generalized method of moments (GMM) estimators are growing in popularity. As implemented in popular software, the estimators easily generate instruments that are numerous and, in system GMM, potentially suspect. A large instrument collection overﬁts endogenous variables even as it weakens the Hansen test of the instruments’ joint validity. This paper reviews the evidence on the effects of instrument proliferation, and describes and simulates simple ways to control it. It illustrates the dangers by replicating Forbes [American Economic Review (2000) Vol. 90, pp. 869–887] on income inequality and Levine et al. [Journal of Monetary Economics] (2000) Vol. 46, pp. 31–77] on ﬁnancial sector development. Results in both papers appear driven by previously undetected endogeneity.},
	language = {en},
	number = {1},
	urldate = {2021-03-11},
	journal = {Oxford Bulletin of Economics and Statistics},
	author = {Roodman, David},
	month = feb,
	year = {2009},
	pages = {135--158},
	file = {Roodman - 2009 - A Note on the Theme of Too Many Instruments.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\8Y4WXWY3\\Roodman - 2009 - A Note on the Theme of Too Many Instruments.pdf:application/pdf},
}

@article{baum_binary_nodate,
	title = {Binary {Choice} {Models} with {Endogenous} {Regressors}},
	language = {en},
	journal = {instrumental variables},
	author = {Baum, Christopher F and Dong, Yingying and Lewbel, Arthur and Yang, Tao},
	pages = {80},
	file = {Baum et al. - Binary Choice Models with Endogenous Regressors.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\7UBRUD7J\\Baum et al. - Binary Choice Models with Endogenous Regressors.pdf:application/pdf},
}

@article{carrasco_efficient_2016,
	title = {Efficient {Estimation} with {Many} {Weak} {Instruments} {Using} {Regularization} {Techniques}},
	volume = {35},
	issn = {0747-4938, 1532-4168},
	url = {http://www.tandfonline.com/doi/full/10.1080/07474938.2015.1092806},
	doi = {10.1080/07474938.2015.1092806},
	language = {en},
	number = {8-10},
	urldate = {2021-03-15},
	journal = {Econometric Reviews},
	author = {Carrasco, Marine and Tchuente, Guy},
	month = nov,
	year = {2016},
	pages = {1609--1637},
	file = {Carrasco et Tchuente - 2016 - Efficient Estimation with Many Weak Instruments Us.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\TTKB6D6P\\Carrasco et Tchuente - 2016 - Efficient Estimation with Many Weak Instruments Us.pdf:application/pdf},
}

@article{chao_asymptotic_2012,
	title = {{ASYMPTOTIC} {DISTRIBUTION} {OF} {JIVE} {IN} {A} {HETEROSKEDASTIC} {IV} {REGRESSION} {WITH} {MANY} {INSTRUMENTS}},
	language = {en},
	journal = {Econometric Theory},
	author = {Chao, John C and Swanson, Norman R. and Newey, Whitney and Woutersen, Tlemen and Hausman, Jerry},
	year = {2012},
	pages = {46},
	file = {Chao - 2021 - ASYMPTOTIC DISTRIBUTION OF JIVE IN A HETEROSKEDAST.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\Q6IHR5JF\\Chao - 2021 - ASYMPTOTIC DISTRIBUTION OF JIVE IN A HETEROSKEDAST.pdf:application/pdf},
}

@article{sawa_finite-sample_1972,
	title = {Finite-{Sample} {Properties} of the k-{Class} {Estimators}},
	volume = {40},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/1912960},
	doi = {10.2307/1912960},
	abstract = {This paper is concerned with the so-called k-class estimators of structural parameters in a simultaneous system. The structural equation being estimated is assumed, as is common in other small-sample investigations, to consist of two endogenous variables; and the number of the exogenous variables (included or excluded) as well as the number of equations in the system are arbitrary so long as the identifiability condition of the estimated equation is satisfied. Moreover, we assume that the system contains no lagged endogenous variables and disturbance terms of each period are independently distributed as multivariate normal. The exact finite-sample moments of the k-class estimators are evaluated for 0 @{\textless} k {\textless} 1. For k {\textgreater} 1 it is proved that the estimator does not possess even the first-order moment. The exact moment functions are expanded in terms of the inverse of the noncentrality (or concentration) parameter. This expansion sheds more light on the comparative study of alternative k-class estimators. Numerical calculations of the mean square error and the bias for some specific cases are also given for illustrative purposes.},
	number = {4},
	urldate = {2021-03-15},
	journal = {Econometrica},
	author = {Sawa, Takamitsu},
	year = {1972},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {653--680},
}

@article{favara_credit_2015,
	title = {Credit {Supply} and the {Price} of {Housing}},
	volume = {105},
	issn = {0002-8282},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.20121416},
	doi = {10.1257/aer.20121416},
	abstract = {An exogenous expansion in mortgage credit has significant effects on house prices. This finding is established using US branching deregulations between 1994 and 2005 as instruments for credit. Credit increases for deregulated banks, but not in placebo samples. Such differential responses rule out demand-based explanations, and identify an exogenous credit supply shock. Because of geographic diver-sification, treated banks expand credit: housing demand increases, house prices rise, but to a lesser extent in areas with elastic housing supply, where the housing stock increases instead. In an instrumental variable sense, house prices are well explained by the credit expansion induced by deregulation. (JEL G21, G28, R21, R31)},
	language = {en},
	number = {3},
	urldate = {2021-03-15},
	journal = {American Economic Review},
	author = {Favara, Giovanni and Imbs, Jean},
	month = mar,
	year = {2015},
	pages = {958--992},
	file = {Favara et Imbs - 2015 - Credit Supply and the Price of Housing.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\2B6S5LCL\\Favara et Imbs - 2015 - Credit Supply and the Price of Housing.pdf:application/pdf},
}

@article{hummels_wage_2011,
	title = {The {Wage} {Effects} of {Offshoring}: {Evidence} from {Danish} {Matched} {Worker}-{Firm} {Data}},
	volume = {104},
	shorttitle = {The {Wage} {Effects} of {Offshoring}},
	doi = {10.1257/aer.104.6.1597},
	abstract = {We estimate how offshoring and exporting affect wages by skill type. Our data match the population of Danish workers to the universe of private-sector Danish firms, whose trade flows are broken down by product and origin and destination countries. Our data reveal new stylized facts about offshoring activities at the firm level, and allow us to both condition our identification on within-job-spell changes and construct instruments for offshoring and exporting that are time varying and uncorrelated with the wage setting of the firm. We find that within job spells, (1) offshoring tends to increase the high-skilled wage and decrease the low-skilled wage; (2) exporting tends to increase the wages of all skill types; (3) the net wage effect of trade varies substantially across workers of the same skill type; and (4) conditional on skill, the wage effect of offshoring exhibits additional variation depending on task characteristics. We then track the outcomes for workers after a job spell and find that those displaced from offshoring firms suffer greater earnings losses than other displaced workers, and that low-skilled workers suffer greater and more persistent earnings losses than high-skilled workers.Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at www.nber.org.},
	journal = {American Economic Review},
	author = {Hummels, David and Jorgensen, Rasmus and Munch, Jakob and Xiang, Chong},
	month = oct,
	year = {2011},
	file = {Version soumise:C\:\\Users\\Hippo\\Zotero\\storage\\MZYLUY4N\\Hummels et al. - 2011 - The Wage Effects of Offshoring Evidence from Dani.pdf:application/pdf},
}

@article{dobbie_effects_2018,
	title = {The {Effects} of {Pretrial} {Detention} on {Conviction}, {Future} {Crime}, and {Employment}: {Evidence} from {Randomly} {Assigned} {Judges}},
	volume = {108},
	url = {https://www.nber.org/system/files/working_papers/w22511/w22511.pdf},
	number = {2},
	urldate = {2021-03-15},
	journal = {American Economic Review},
	author = {Dobbie, Will and Goldin, Jacob and Yang, Crystal},
	month = feb,
	year = {2018},
	pages = {201--40},
	file = {w22511.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\UN2WASFX\\w22511.pdf:application/pdf},
}

@article{chesher_instrumental_2013,
	title = {An instrumental variable model of multiple discrete choice},
	volume = {4},
	issn = {1759-7331},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.3982/QE240},
	doi = {https://doi.org/10.3982/QE240},
	abstract = {This paper studies identification in multiple discrete choice models in which there may be endogenous explanatory variables, that is, explanatory variables that are not restricted to be distributed independently of the unobserved determinants of latent utilities. The model does not employ large support, special regressor, or control function restrictions; indeed, it is silent about the process that delivers values of endogenous explanatory variables, and in this respect it is incomplete. Instead, the model employs instrumental variable restrictions that require the existence of instrumental variables that are excluded from latent utilities and distributed independently of the unobserved components of utilities. We show that the model delivers set identification of latent utility functions and the distribution of unobserved heterogeneity, and we characterize sharp bounds on these objects. We develop easy-to-compute outer regions that, in parametric models, require little more calculation than what is involved in a conventional maximum likelihood analysis. The results are illustrated using a model that is essentially the conditional logit model of 41, but with potentially endogenous explanatory variables and instrumental variable restrictions. The method employed has wide applicability and for the first time brings instrumental variable methods to bear on structural models in which there are multiple unobservables in a structural equation.},
	language = {en},
	number = {2},
	urldate = {2021-03-17},
	journal = {Quantitative Economics},
	author = {Chesher, Andrew and Rosen, Adam M. and Smolinski, Konrad},
	year = {2013},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.3982/QE240},
	keywords = {C25, C26, endogeneity, incomplete models, instrumental variables, multiple discrete choice, Partial identification, random sets},
	pages = {157--196},
	file = {Full Text PDF:C\:\\Users\\Hippo\\Zotero\\storage\\D5CV4LUI\\Chesher et al. - 2013 - An instrumental variable model of multiple discret.pdf:application/pdf;Snapshot:C\:\\Users\\Hippo\\Zotero\\storage\\4PSB5HML\\QE240.html:text/html},
}

@article{baum_binary_nodate-1,
	title = {Binary {Choice} {Models} with {Endogenous} {Regressors}},
	language = {en},
	journal = {instrumental variables},
	author = {Baum, Christopher F and Dong, Yingying and Lewbel, Arthur and Yang, Tao},
	pages = {80},
	file = {Baum et al. - Binary Choice Models with Endogenous Regressors.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\WSFLSQUF\\Baum et al. - Binary Choice Models with Endogenous Regressors.pdf:application/pdf},
}

@article{li_binary_nodate,
	title = {Binary {Outcomes}, {OLS}, {2SLS} and {IV} {Probit}},
	language = {en},
	author = {Li, Chuhui and Poskitt, Donald S and Windmeijer, Frank and Zhao, Xueyan},
	pages = {23},
	file = {Li et al. - Binary Outcomes, OLS, 2SLS and IV Probit.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\2S7DFR27\\Li et al. - Binary Outcomes, OLS, 2SLS and IV Probit.pdf:application/pdf},
}

@article{clarke_estimating_nodate,
	title = {Estimating {Structural} {Mean} {Models} with {Multiple} {Instrumental} {Variables} {Using} the {Generalised} {Method} of {Moments}},
	abstract = {Instrumental variables analysis using genetic markers as instruments is now a widely used technique in epidemiology and biostatistics. As single markers tend to explain only a small proportion of phenotypic variation, there is increasing interest in using multiple genetic markers to obtain more precise estimates of causal parameters. Structural mean models (SMMs) are semiparametric models that use instrumental variables to identify causal parameters. Recently, interest has started to focus on using these models with multiple instruments, particularly for multiplicative and logistic SMMs. In this paper we show how additive, multiplicative and logistic SMMs with multiple orthogonal binary instrumental variables can be estimated efﬁciently in models with no further (continuous) covariates, using the generalised method of moments (GMM) estimator. We discuss how the Hansen J-test can be used to test for model misspeciﬁcation, and how standard GMM software routines can be used to ﬁt SMMs. We further show that multiplicative SMMs, like the additive SMM, identify a weighted average of local causal effects if selection is monotonic. We use these methods to reanalyse a study of the relationship between adiposity and hypertension using SMMs with two genetic markers as instruments for adiposity. We ﬁnd strong effects of adiposity on hypertension.},
	language = {en},
	author = {Clarke, Paul S and Palmer, Tom M and Windmeijer, Frank},
	pages = {22},
	file = {Clarke et al. - Estimating Structural Mean Models with Multiple In.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\8B2CIILA\\Clarke et al. - Estimating Structural Mean Models with Multiple In.pdf:application/pdf},
}

@article{andrews_consistent_1999,
	title = {Consistent {Moment} {Selection} {Procedures} for {Generalized} {Method} of {Moments} {Estimation}},
	volume = {67},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/2999544},
	abstract = {This paper considers a generalized method of moments (GMM) estimation problem in which one has a vector of moment conditions, some of which are correct and some incorrect. The paper introduces several procedures for consistently selecting the correct moment conditions. The procedures also can consistently determine whether there is a sufficient number of correct moment conditions to identify the unknown parameters of interest. The paper specifies moment selection criteria that are GMM analogues of the widely used BIC and AIC model selection criteria. (The latter is not consistent.) The paper also considers downward and upward testing procedures. All of the moment selection procedures discussed in this paper are based on the minimized values of the GMM criterion function for different vectors of moment conditions. The procedures are applicable in time-series and cross-sectional contexts. Application of the results of the paper to instrumental variables estimation problems yields consistent procedures for selecting instrumental variables.},
	number = {3},
	urldate = {2021-03-17},
	journal = {Econometrica},
	author = {Andrews, Donald W. K.},
	year = {1999},
	pages = {543--564},
	file = {JSTOR Full Text PDF:C\:\\Users\\Hippo\\Zotero\\storage\\CFQ8QGQE\\Andrews - 1999 - Consistent Moment Selection Procedures for General.pdf:application/pdf},
}

@article{chernozhukov_post-selection_2015,
	title = {Post-{Selection} and {Post}-{Regularization} {Inference} in {Linear} {Models} with {Many} {Controls} and {Instruments}},
	volume = {105},
	issn = {0002-8282},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.p20151022},
	doi = {10.1257/aer.p20151022},
	abstract = {We consider estimation of and inference about coefficients on endogenous variables in a linear instrumental variables model where the number of instruments and exogenous control variables are each allowed to be larger than the sample size. We work within an approximately sparse framework that maintains that the signal available in the instruments and control variables may be effectively captured by a small number of the available variables. We provide a LASSO-based method for this setting which provides uniformly valid inference about the coefficients on endogenous variables. We illustrate the method through an application to demand estimation.},
	language = {en},
	number = {5},
	urldate = {2021-03-17},
	journal = {American Economic Review},
	author = {Chernozhukov, Victor and Hansen, Christian and Spindler, Martin},
	month = may,
	year = {2015},
	pages = {486--490},
	file = {Chernozhukov et al. - 2015 - Post-Selection and Post-Regularization Inference i.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\T5FFDMQG\\Chernozhukov et al. - 2015 - Post-Selection and Post-Regularization Inference i.pdf:application/pdf},
}

@article{windmeijer_use_2019,
	doi = {10.1080/01621459.2018.1498346},
  url = {https://doi.org/10.1080/01621459.2018.1498346},
  year = {2018},
  month = nov,
  publisher = {Informa {UK} Limited},
  volume = {114},
  number = {527},
  pages = {1339--1350},
  author = {Frank Windmeijer and Helmut Farbmacher and Neil Davies and George Davey Smith},
  title = {On the Use of the Lasso for Instrumental Variables Estimation with Some Invalid Instruments},
  journal = {Journal of the American Statistical Association}
}

@article{carrasco_regularization_2012,
	title = {A regularization approach to the many instruments problem},
	volume = {170},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407612001248},
	doi = {10.1016/j.jeconom.2012.05.012},
	abstract = {This paper focuses on the estimation of a finite dimensional parameter in a linear model where the number of instruments is very large or infinite. In order to improve the small sample properties of standard instrumental variable (IV) estimators, we propose three modified IV estimators based on three different ways of inverting the covariance matrix of the instruments. These inverses involve a regularization or smoothing parameter. It should be stressed that no restriction on the number of instruments is needed and that all the instruments are used in the estimation. We show that the three estimators are asymptotically normal and attain the semiparametric efficiency bound. Higher-order analysis of the MSE reveals that the bias of the modified estimators does not depend on the number of instruments. Finally, we suggest a datadriven method for selecting the regularization parameter. Interestingly, our regularization techniques lead to a consistent nonparametric estimation of the optimal instrument.},
	language = {en},
	number = {2},
	urldate = {2021-03-29},
	journal = {Journal of Econometrics},
	author = {Carrasco, Marine},
	month = oct,
	year = {2012},
	pages = {383--398},
	file = {Carrasco - 2012 - A regularization approach to the many instruments .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\Y4TYQHHA\\Carrasco - 2012 - A regularization approach to the many instruments .pdf:application/pdf},
}

@article{carrasco_testing_2021,
	doi = {10.1093/ectj/utab020},
  url = {https://doi.org/10.1093/ectj/utab020},
  year = {2021},
  month = jul,
  publisher = {Oxford University Press ({OUP})},
  volume = {25},
  number = {1},
  pages = {71--97},
  author = {Marine Carrasco and Mohamed Doukali},
  title = {Testing overidentifying restrictions with many instruments and heteroscedasticity using regularised jackknife {IV}},
  journal = {The Econometrics Journal}
}

@article{marine_carrasco_efficient_2017,
	title = {Efficient {Estimation} {Using} {Regularized} {Jackknife} {IV} {Estimator}},
	issn = {21154430},
	url = {http://www.jstor.org/stable/10.15609/annaeconstat2009.128.0109},
	doi = {10.15609/annaeconstat2009.128.0109},
	language = {en},
	number = {128},
	urldate = {2021-03-29},
	journal = {Annals of Economics and Statistics},
	author = {{Marine Carrasco} and {Mohamed Doukali}},
	year = {2017},
	pages = {109},
	file = {Marine Carrasco et Mohamed Doukali - 2017 - Efficient Estimation Using Regularized Jackknife I.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\QDAQIBNW\\Marine Carrasco et Mohamed Doukali - 2017 - Efficient Estimation Using Regularized Jackknife I.pdf:application/pdf},
}

@article{carrasco_regularized_2015,
	title = {Regularized {LIML} for many instruments},
	volume = {186},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407615000421},
	doi = {10.1016/j.jeconom.2015.02.018},
	abstract = {The use of many moment conditions improves the asymptotic efficiency of the instrumental variables estimators. However, in finite samples, the inclusion of an excessive number of moments increases the bias. To solve this problem, we propose regularized versions of the limited information maximum likelihood (LIML) based on three different regularizations: Tikhonov, Landweber–Fridman, and principal components. Our estimators are consistent and asymptotically normal under heteroskedastic error. Moreover, they reach the semiparametric efficiency bound assuming homoskedastic error. We show that the regularized LIML estimators possess finite moments when the sample size is large enough. The higher order expansion of the mean square error (MSE) shows the dominance of regularized LIML over regularized two-staged least squares estimators. We devise a data driven selection of the regularization parameter based on the approximate MSE. A Monte Carlo study and two empirical applications illustrate the relevance of our estimators.},
	language = {en},
	number = {2},
	urldate = {2021-03-29},
	journal = {Journal of Econometrics},
	author = {Carrasco, Marine and Tchuente, Guy},
	month = jun,
	year = {2015},
	pages = {427--442},
	file = {Carrasco et Tchuente - 2015 - Regularized LIML for many instruments.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\HFS6ZUYI\\Carrasco et Tchuente - 2015 - Regularized LIML for many instruments.pdf:application/pdf},
}

@article{carrasco_generalization_2000,
	title = {{GENERALIZATION} {OF} {GMM} {TO} {A} {CONTINUUM} {OF} {MOMENT} {CONDITIONS}},
	volume = {16},
	issn = {0266-4666, 1469-4360},
	url = {https://www.cambridge.org/core/product/identifier/S0266466600166010/type/journal_article},
	doi = {10.1017/S0266466600166010},
	abstract = {This paper proposes a version of the generalized 
method of moments procedure that handles both the case 
where the number of moment conditions is finite and the 
case where there is a continuum of moment conditions. Typically, 
the moment conditions are indexed by an index parameter 
that takes its values in an interval. The objective function 
to minimize is then the norm of the moment conditions in 
a Hilbert space. The estimator is shown to be consistent 
and asymptotically normal. The optimal estimator is obtained 
by minimizing the norm of the moment conditions in the 
reproducing kernel Hilbert space associated with the covariance. 
We show an easy way to calculate this estimator. Finally, 
we study properties of a specification test using overidentifying 
restrictions. Results of this paper are useful in many 
instances where a continuum of moment conditions arises. 
Examples include efficient estimation of continuous time 
regression models, cross-sectional models that satisfy 
conditional moment restrictions, and scalar diffusion processes.},
	language = {en},
	number = {6},
	urldate = {2021-03-29},
	journal = {Econometric Theory},
	author = {Carrasco, Marine and Florens, Jean-Pierre},
	month = dec,
	year = {2000},
	pages = {797--834},
	file = {Carrasco et Florens - 2000 - GENERALIZATION OF GMM TO A CONTINUUM OF MOMENT CON.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\3BYAHU99\\Carrasco et Florens - 2000 - GENERALIZATION OF GMM TO A CONTINUUM OF MOMENT CON.pdf:application/pdf},
}

@article{hausman_instrumental_2012,
	title = {Instrumental variable estimation with heteroskedasticity and many instruments: {Instrumental} variable estimation},
	volume = {3},
	issn = {17597323},
	shorttitle = {Instrumental variable estimation with heteroskedasticity and many instruments},
	url = {http://doi.wiley.com/10.3982/QE89},
	doi = {10.3982/QE89},
	language = {en},
	number = {2},
	urldate = {2021-03-30},
	journal = {Quantitative Economics},
	author = {Hausman, Jerry A. and Newey, Whitney K. and Woutersen, Tiemen and Chao, John C. and Swanson, Norman R.},
	month = jul,
	year = {2012},
	pages = {211--255},
	file = {Hausman et al. - 2012 - Instrumental variable estimation with heteroskedas.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\RR55XJQD\\Hausman et al. - 2012 - Instrumental variable estimation with heteroskedas.pdf:application/pdf},
}

@article{angrist_jackknife_1999,
	title = {Jackknife {Instrumental} {Variables} {Estimation}},
	volume = {14},
	issn = {0883-7252},
	url = {https://www.jstor.org/stable/223249},
	abstract = {Two-stage-least-squares (2SLS) estimates are biased towards the probability limit of OLS estimates. This bias grows with the degree of over-identification and can generate highly misleading results. In this paper we propose two simple alternatives to 2SLS and limited-information-maximum-likelihood (LIML) estimators for models with more instruments than endogenous regressors. These estimators can be interpreted as instrumental variables procedures using an instrument that is independent of disturbances even in finite samples. Independence is achieved by using a 'leave-one-out' jackknife-type fitted value in place of the usual first stage equation. The new estimators are first order equivalent to 2SLS but with finite-sample properties superior, in terms of bias and coverage rate of confidence intervals, compared to those of 2SLS and similar to those of LIML, when there are many instruments.},
	number = {1},
	urldate = {2021-04-07},
	journal = {Journal of Applied Econometrics},
	author = {Angrist, J. D. and Imbens, G. W. and Krueger, A. B.},
	year = {1999},
	pages = {57--67},
	file = {JSTOR Full Text PDF:C\:\\Users\\Hippo\\Zotero\\storage\\T23TM4BC\\Angrist et al. - 1999 - Jackknife Instrumental Variables Estimation.pdf:application/pdf},
}

@article{spiess_bias_2017,
	title = {Bias {Reduction} in {Instrumental} {Variable} {Estimation} through {First}-{Stage} {Shrinkage}},
	author = {Spiess, Jann},
	year = {2017},
	file = {1708.06443.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\SRNRL28V\\1708.06443.pdf:application/pdf},
}

@article{bai_instrument_2010,
	title = {Instrument {Variable} {Estimation} in a {Data} {Rich} {Environment}},
	volume = {26},
	issn = {0266-4666, 1469-4360},
	url = {https://www.cambridge.org/core/product/identifier/S0266466609990727/type/journal_article},
	doi = {10.1017/S0266466609990727},
	abstract = {We consider estimation of parameters in a regression model with endogenous regressors. The endogenous regressors along with a large number of other endogenous variables are driven by a small number of unobservable exogenous common factors. We show that the estimated common factors can be used as instrumental variables and they are more efficient than the observed variables in our framework. Whereas standard optimal generalized method of moments estimator using a large number of instruments is biased and can be inconsistent, the factor instrumental variable estimator (FIV) is shown to be consistent and asymptotically normal, even if the number of instruments exceeds the sample size. Furthermore, FIV remains consistent even if the observed variables are invalid instruments as long as the unobserved common components are valid instruments. We also consider estimating panel data models in which all regressors are endogenous but share exogenous common factors. We show that valid instruments can be constructed from the endogenous regressors. Although single equation FIV requires no bias correction, the faster convergence rate of the panel estimator is such that a bias correction is necessary to obtain a zero-centered normal distribution.},
	language = {en},
	number = {6},
	urldate = {2021-04-08},
	journal = {Econometric Theory},
	author = {Bai, Jushan and Ng, Serena},
	month = dec,
	year = {2010},
	pages = {1577--1606},
	file = {Bai et Ng - 2010 - INSTRUMENTAL VARIABLE ESTIMATION IN A DATA RICH EN.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\TLXUFJRZ\\Bai et Ng - 2010 - INSTRUMENTAL VARIABLE ESTIMATION IN A DATA RICH EN.pdf:application/pdf},
}

@article{kang_instrumental_2016,
	doi = {10.1080/01621459.2014.994705},
  url = {https://doi.org/10.1080/01621459.2014.994705},
  year = {2016},
  month = jan,
  publisher = {Informa {UK} Limited},
  volume = {111},
  number = {513},
  pages = {132--144},
  author = {Hyunseung Kang and Anru Zhang and T. Tony Cai and Dylan S. Small},
  title = {Instrumental Variables Estimation With Some Invalid Instruments and its Application to Mendelian Randomization},
  journal = {Journal of the American Statistical Association}
}

@article{canan_instrumental_2017,
	title = {Instrumental {Variable} {Analyses} and {Selection} {Bias}},
	volume = {28},
	number = {3},
	journal = {Epidemiology},
	author = {Canan, Chelsea and Lesko, Catherine and Lau, Bryan},
	month = may,
	year = {2017},
	pages = {396--398},
	file = {nihms848953.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\I7WETZ4F\\nihms848953.pdf:application/pdf},
}

@article{chen_mostly_2021,
	title = {Mostly {Harmless} {Machine} {Learning}: {Learning} {Optimal} {Instruments} in {Linear} {IV} {Models}},
	abstract = {We oﬀer simple theoretical results that justify incorporating machine learning in the standard linear instrumental variable setting that is prevalent in empirical research in economics. The key idea is to use machine learning, combined with sample splitting, to predict the treatment variable from the instrument and any exogenous covariates, and then use this predicted treatment and the covariates as technical instruments to recover the coeﬃcients in the second-stage. This allows the researcher to extract nonlinear variation in the instrument that may dramatically improve estimation precision and robustness by boosting instrument strength. The key novelty of our approach is restricting the machine-learned predictions to those that are linear in the exogenous covariates, to avoid spurious identiﬁcation from non-linear relationships between the treatment and the covariates rather than with the instrument itself. We show that this approach delivers consistent and asymptotically normal estimates under weak conditions and that it is semi-parametrically eﬃcient under homoskedastic errors. We generalize to the case with heteroskedasticity using a sequential moment argument due to Chamberlain (1992). Our method preserves standard intuitions and interpretations of linear instrumental variable methods and provides a simple, user-friendly upgrade to the applied economics toolbox. We illustrate our method with an example in law and criminal justice, examining the causal eﬀect of appellate court reversals on district court sentencing decisions.},
	language = {en},
	author = {Chen, Jiafeng and Chen, Daniel L and Lewis, Greg},
	year = {2021},
	file = {Chen et al. - Mostly Harmless Machine Learning Learning Optimal.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\KJZ6ACZ9\\Chen et al. - Mostly Harmless Machine Learning Learning Optimal.pdf:application/pdf},
}

@article{ackerberg_improved_nodate,
	title = {Improved {Jive} {Estimators} for {Overidenti} ed {Linear} {Models} with and without {Heteroskedasticity}},
	abstract = {This paper examines, extends and applies work on estimators for overidenti ed linear instrumental variables models. In the rst part of the paper, we introduce two simple new variants of the JIVE estimator proposed by Phillips and Hale (1977), Blomquist and Dahlberg (1999), and Angrist, Imbens, and Krueger (1995, 1999). We show that our new estimators are superior to the existing JIVE estimator, signi cantly improving on its small sample bias properties. Our second theoretical contribution is to compare our new estimators to existing Nagar (1959) type estimators when there is heteroskedasticity in the model. We show that when there is heteroskedasticity, our estimators have superior properties to both the Nagar estimator and the related B2SLS estimator suggested in Donald and Newey (2001). These theoretical results are veri ed in a set of MonteCarlo experiments and then applied to estimating the returns to schooling using the data of Angrist and Krueger (1991).},
	language = {en},
	author = {Ackerberg, Daniel A and Devereux, Paul J},
	pages = {21},
	file = {Ackerberg et Devereux - Improved Jive Estimators for Overidenti ed Linear .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\W5JE55T4\\Ackerberg et Devereux - Improved Jive Estimators for Overidenti ed Linear .pdf:application/pdf},
}

@article{bun_weak_2010,
	title = {The weak instrument problem of the system {GMM} estimator in dynamic panel data models},
	volume = {13},
	issn = {1368-4221},
	url = {https://www.jstor.org/stable/23116949},
	abstract = {The system GMM estimator for dynamic panel data models combines moment conditions for the model in first differences with moment conditions for the model in levels. It has been shown to improve on the GMM estimator in the first differenced model in terms of bias and root mean squared error. However, we show in this paper that in the covariance stationary panel data AR(1) model the expected values of the concentration parameters in the differenced and levels equations for the cross-section at time t are the same when the variances of the individual heterogeneity and idiosyncratic errors are the same. This indicates a weak instrument problem also for the equation in levels. We show that the 2SLS biases relative to that of the OLS biases are then similar for the equations in differences and levels, as are the size distortions of the Wald tests. These results are shown to extend to the panel data GMM estimators.},
	number = {1},
	urldate = {2021-05-18},
	journal = {The Econometrics Journal},
	author = {Bun, Maurice J. G. and Windmeijer, Frank},
	year = {2010},
	note = {Publisher: [Royal Economic Society, Wiley]},
	pages = {95--126},
}

@article{bun_weak_2021,
	title = {The weak instrument problem of the system {GMM} estimator in dynamic panel data models},
	abstract = {The system GMM estimator for dynamic panel data models combines moment conditions for the model in first differences with moment conditions for the model in levels. It has been shown to improve on the GMM estimator in the first differenced model in terms of bias and root mean squared error. However, we show in this paper that in the covariance stationary panel data AR(1) model the expected values of the concentration parameters in the differenced and levels equations for the cross-section at time t are the same when the variances of the individual heterogeneity and idiosyncratic errors are the same. This indicates a weak instrument problem also for the equation in levels. We show that the 2SLS biases relative to that of the OLS biases are then similar for the equations in differences and levels, as are the size distortions of the Wald tests. These results are shown to extend to the panel data GMM estimators.},
	language = {en},
	author = {Bun, Maurice J G and Windmeijer, Frank},
	year = {2021},
	pages = {33},
	file = {Bun et Windmeijer - 2021 - The weak instrument problem of the system GMM esti.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\4KRQ4PA9\\Bun et Windmeijer - 2021 - The weak instrument problem of the system GMM esti.pdf:application/pdf},
}

@book{kraay_weak_2015,
	series = {Policy {Research} {Working} {Papers}},
	title = {Weak {Instruments} in {Growth} {Regressions}: {Implications} for {Recent} {Cross}-{Country} {Evidence} on {Inequality} and {Growth}},
	shorttitle = {Weak {Instruments} in {Growth} {Regressions}},
	url = {http://elibrary.worldbank.org/doi/book/10.1596/1813-9450-7494},
	language = {en},
	urldate = {2021-05-18},
	publisher = {The World Bank},
	author = {Kraay, Aart},
	month = nov,
	year = {2015},
	doi = {10.1596/1813-9450-7494},
	file = {Kraay - 2015 - Weak Instruments in Growth Regressions Implicatio.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\VC6G3V8B\\Kraay - 2015 - Weak Instruments in Growth Regressions Implicatio.pdf:application/pdf},
}

@article{k_newey_generalized_1985,
	title = {Generalized method of moments specification testing},
	volume = {29},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/030440768590154X},
	doi = {10.1016/0304-4076(85)90154-X},
	language = {en},
	number = {3},
	urldate = {2021-06-01},
	journal = {Journal of Econometrics},
	author = {K. Newey, Whitney},
	month = sep,
	year = {1985},
	pages = {229--256},
	file = {K. Newey - 1985 - Generalized method of moments specification testin.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\3CN9ACIZ\\K. Newey - 1985 - Generalized method of moments specification testin.pdf:application/pdf},
}

@article{bun_weak_2021-1,
	title = {The weak instrument problem of the system {GMM} estimator in dynamic panel data models},
	abstract = {The system GMM estimator for dynamic panel data models combines moment conditions for the model in first differences with moment conditions for the model in levels. It has been shown to improve on the GMM estimator in the first differenced model in terms of bias and root mean squared error. However, we show in this paper that in the covariance stationary panel data AR(1) model the expected values of the concentration parameters in the differenced and levels equations for the cross-section at time t are the same when the variances of the individual heterogeneity and idiosyncratic errors are the same. This indicates a weak instrument problem also for the equation in levels. We show that the 2SLS biases relative to that of the OLS biases are then similar for the equations in differences and levels, as are the size distortions of the Wald tests. These results are shown to extend to the panel data GMM estimators.},
	language = {en},
	author = {Bun, Maurice J G and Windmeijer, Frank},
	year = {2021},
	pages = {33},
	file = {Bun et Windmeijer - 2021 - The weak instrument problem of the system GMM esti.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\VHGVWD5V\\Bun et Windmeijer - 2021 - The weak instrument problem of the system GMM esti.pdf:application/pdf},
}

@article{bester_grouped_2016,
	title = {Grouped effects estimators in fixed effects models},
	volume = {190},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407613002030},
	doi = {10.1016/j.jeconom.2012.08.022},
	abstract = {We consider estimation of nonlinear panel data models with common and individual specific parameters. Fixed effects estimators are known to suffer from the incidental parameters problem, which can lead to large biases in estimates of common parameters. Pooled estimators, which ignore heterogeneity across individuals, are also generally inconsistent. We assume that individuals in the data are grouped on multiple levels where groups are defined by some observable external classification. We consider ‘‘group effects’’ estimators, where individual specific parameters are assumed common across groups at some level. We provide conditions under which group effects estimates of common parameters are asymptotically unbiased and normal. The conditions suggest a tradeoff between two sources of bias, one due to incidental parameters and the other due to misspecification of unobserved heterogeneity.},
	language = {en},
	number = {1},
	urldate = {2021-06-12},
	journal = {Journal of Econometrics},
	author = {Bester, C. Alan and Hansen, Christian B.},
	month = jan,
	year = {2016},
	pages = {197--208},
	file = {Bester et Hansen - 2016 - Grouped effects estimators in fixed effects models.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\M2VW7GPB\\Bester et Hansen - 2016 - Grouped effects estimators in fixed effects models.pdf:application/pdf},
}

@article{gilmour_interpretation_1996,
	title = {The {Interpretation} of {Mallows}'s {C} p -{Statistic}},
	volume = {45},
	issn = {00390526},
	url = {https://www.jstor.org/stable/10.2307/2348411?origin=crossref},
	doi = {10.2307/2348411},
	abstract = {When selecting variables in multiple-regression studies, the model with the lowest value of Mallows's C is often chosen. It is shown here that when the estimate of 2 comes from the full model an adjusted Cp property that E(Cp) = p. It is suggested that a procedure be adopted which involves testing whether th minimum CCp is really better than a simpler model. Tables approximating the null distribution of the test s given.},
	language = {en},
	number = {1},
	urldate = {2021-06-12},
	journal = {The Statistician},
	author = {Gilmour, Steven G.},
	year = {1996},
	pages = {49},
	file = {Gilmour - 1996 - The Interpretation of Mallows's C p -Statistic.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\23ZIRGTB\\Gilmour - 1996 - The Interpretation of Mallows's C p -Statistic.pdf:application/pdf},
}

@article{boucher_discussion_nodate,
	title = {Discussion {Bias} {2SLS} {Neural} {Networks}},
	language = {en},
	author = {Boucher, Hippolyte},
	pages = {3},
	file = {Boucher - Discussion Bias 2SLS Neural Networks.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\4TJRMFH2\\Boucher - Discussion Bias 2SLS Neural Networks.pdf:application/pdf},
}

@article{newey_nonparametric_2013-1,
	title = {Nonparametric {Instrumental} {Variables} {Estimation}},
	volume = {103},
	issn = {0002-8282},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.103.3.550},
	doi = {10.1257/aer.103.3.550},
	abstract = {In many economic models, objects of interest are functions which satisfy conditional moment restrictions. Economics does not restrict the functional form of these models, motivating nonparametric methods. In this paper we review identification results and describe a simple nonparametric instrumental variables (NPIV) estimator. We also consider a simple method of inference. In addition we show how the ability to uncover nonlinearities with conditional moment restrictions is related to the strength of the instruments. We point to applications where important nonlinearities can be found with NPIV and applications where they cannot.},
	language = {en},
	number = {3},
	urldate = {2021-06-12},
	journal = {American Economic Review},
	author = {Newey, Whitney K},
	month = may,
	year = {2013},
	pages = {550--556},
	file = {Newey - 2013 - Nonparametric Instrumental Variables Estimation.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\TW7BZYNV\\Newey - 2013 - Nonparametric Instrumental Variables Estimation.pdf:application/pdf},
}

@article{mogstad_policy_nodate,
	title = {Policy {Evaluation} with {Multiple} {Instrumental} {Variables}},
	abstract = {Marginal treatment eﬀect methods are widely used for causal inference and policy evaluation with instrumental variables. However, they fundamentally rely on the wellknown monotonicity (threshold-crossing) condition on treatment choice behavior. Recent research has shown that this condition cannot hold with multiple instruments unless treatment choice is eﬀectively homogeneous. Based on these ﬁndings, we develop a new marginal treatment eﬀect framework under a weaker, partial monotonicity condition. The partial monotonicity condition is implied by standard choice theory and allows for rich heterogeneity even in the presence of multiple instruments. The new framework can be viewed as having multiple diﬀerent choice models for the same observed treatment variable, all of which must be consistent with the data and with each other. Using this framework, we develop a methodology for partial identiﬁcation of clearly stated, policy-relevant target parameters while allowing for a wide variety of nonparametric shape restrictions and parametric functional form assumptions. We show how the methodology can be used to combine multiple instruments together to yield more informative empirical conclusions than one would obtain by using each instrument separately. The methodology provides a blueprint for extracting and aggregating information about treatment eﬀects from multiple controlled or natural experiments while still allowing for rich heterogeneity in both treatment eﬀects and choice behavior.},
	language = {en},
	author = {Mogstad, Magne and Torgovitsky, Alexander and Walters, Christopher R},
	pages = {33},
	file = {Mogstad et al. - Policy Evaluation with Multiple Instrumental Varia.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\KBSZMTYG\\Mogstad et al. - Policy Evaluation with Multiple Instrumental Varia.pdf:application/pdf},
}

@techreport{mogstad_causal_2019,
	address = {Cambridge, MA},
	title = {The {Causal} {Interpretation} of {Two}-{Stage} {Least} {Squares} with {Multiple} {Instrumental} {Variables}},
	url = {http://www.nber.org/papers/w25691.pdf},
	abstract = {Empirical researchers often combine multiple instrumental variables (IVs) for a single treatment using two-stage least squares (2SLS). When treatment effects are heterogeneous, a common justification for including multiple IVs is that the 2SLS estimand can be given a causal interpretation as a positively-weighted average of local average treatment effects (LATEs). This justification requires the well-known monotonicity condition. However, we show that with more than one instrument, this condition can only be satisfied if choice behavior is effectively homogenous. Based on this finding, we consider the use of multiple IVs under a weaker, partial monotonicity condition. We characterize empirically verifiable sufficient and necessary conditions for the 2SLS estimand to be a positively-weighted average of LATEs under partial monotonicity. We apply these results to an empirical analysis of the returns to college with multiple instruments. We show that the standard monotonicity condition is at odds with the data. Nevertheless, our empirical checks show that the 2SLS estimate retains a causal interpretation as a positively-weighted average of the effects of college attendance among complier groups.},
	language = {en},
	number = {w25691},
	urldate = {2021-06-12},
	institution = {National Bureau of Economic Research},
	author = {Mogstad, Magne and Torgovitsky, Alexander and Walters, Christopher},
	month = mar,
	year = {2019},
	doi = {10.3386/w25691},
	pages = {w25691},
	file = {Mogstad et al. - 2019 - The Causal Interpretation of Two-Stage Least Squar.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\SD2L5ID2\\Mogstad et al. - 2019 - The Causal Interpretation of Two-Stage Least Squar.pdf:application/pdf},
}

@article{noauthor_identification_2021,
	title = {Identification and {Estimation} of {Local} {Average} {Treatment} {Effects}},
	language = {en},
	year = {2021},
	pages = {10},
	file = {2021 - Identification and Estimation of Local Average Tre.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\4PYERP48\\2021 - Identification and Estimation of Local Average Tre.pdf:application/pdf},
}

@article{alsan_effect_2015,
	title = {The {Effect} of the {TseTse} {Fly} on {African} {Development}},
	volume = {105},
	issn = {0002-8282},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.20130604},
	doi = {10.1257/aer.20130604},
	abstract = {The TseTse ‡y is unique to Africa and transmits a parasite harmful to humans and lethal to livestock. This paper tests the hypothesis that the TseTse reduced the ability of Africans to generate an agricultural surplus historically. Ethnic groups inhabiting TseTse-suitable areas were less likely to use domesticated animals and the plow, less likely to be politically centralized and had a lower population density. These correlations are not found in the Tropics outside of Africa, where the ‡y does not exist. The evidence suggests current economic performance is a¤ected by the TseTse through the channel of precolonial political centralization.},
	language = {en},
	number = {1},
	urldate = {2021-09-13},
	journal = {American Economic Review},
	author = {Alsan, Marcella},
	month = jan,
	year = {2015},
	pages = {382--410},
	file = {Alsan - 2015 - The Effect of the TseTse Fly on African Developmen.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\383HEG34\\Alsan - 2015 - The Effect of the TseTse Fly on African Developmen.pdf:application/pdf},
}

@article{abdelgadir_political_nodate,
	title = {Political {Secularism} and {Muslim} {Integration} in the {West}: {Assessing} the {Effects} of the {French} {Headscarf} {Ban}},
	language = {en},
	author = {Abdelgadir, Aala and Fouka, Vasiliki},
	pages = {17},
	file = {Abdelgadir et Fouka - Political Secularism and Muslim Integration in the.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\29T9EY9Z\\Abdelgadir et Fouka - Political Secularism and Muslim Integration in the.pdf:application/pdf},
}

@article{maurin_behind_2019,
	title = {Behind the {Veil}: {The} {Effect} of {Banning} the {Islamic} {Veil} in {Schools}},
	language = {en},
	journal = {Behind the Veil},
	author = {Maurin, Éric},
	year = {2019},
	pages = {45},
	file = {Maurin - 2019 - Behind the Veil The Effect of Banning the Islamic.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\MCASN2L4\\Maurin - 2019 - Behind the Veil The Effect of Banning the Islamic.pdf:application/pdf},
}

@article{neidell_air_2004,
	title = {Air pollution, health, and socio-economic status: the effect of outdoor air quality on childhood asthma},
	volume = {23},
	issn = {01676296},
	shorttitle = {Air pollution, health, and socio-economic status},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167629604000864},
	doi = {10.1016/j.jhealeco.2004.05.002},
	abstract = {This paper estimates the effect of air pollution on child hospitalizations for asthma using naturally occurring seasonal variations in pollution within zip codes. Of the pollutants considered, carbon monoxide (CO) has a signiﬁcant effect on asthma for children ages 1–18: if 1998 pollution levels were at their 1992 levels, there would be a 5–14\% increase in asthma admissions. Also, households respond to information about pollution with avoidance behavior, suggesting it is important to account for these endogenous responses when measuring the effect of pollution on health. Finally, the effect of pollution is greater for children of lower socio-economic status (SES), indicating that pollution is one potential mechanism by which SES affects health.},
	language = {en},
	number = {6},
	urldate = {2021-09-13},
	journal = {Journal of Health Economics},
	author = {Neidell, Matthew J.},
	month = nov,
	year = {2004},
	pages = {1209--1236},
	file = {Neidell - 2004 - Air pollution, health, and socio-economic status .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\J66Z4JKK\\Neidell - 2004 - Air pollution, health, and socio-economic status .pdf:application/pdf},
}

@techreport{angrist_children_1996,
	address = {Cambridge, MA},
	title = {Children and {Their} {Parents}' {Labor} {Supply}: {Evidence} from {Exogenous} {Variation} in {Family} {Size}},
	shorttitle = {Children and {Their} {Parents}' {Labor} {Supply}},
	url = {http://www.nber.org/papers/w5778.pdf},
	language = {en},
	number = {w5778},
	urldate = {2021-09-14},
	institution = {National Bureau of Economic Research},
	author = {Angrist, Joshua and Evans, William},
	month = sep,
	year = {1996},
	doi = {10.3386/w5778},
	pages = {w5778},
	file = {Angrist et Evans - 1996 - Children and Their Parents' Labor Supply Evidence.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\8LCRHKK5\\Angrist et Evans - 1996 - Children and Their Parents' Labor Supply Evidence.pdf:application/pdf},
}

@article{pesaran_generalized_1994,
	title = {A {Generalized} {R}{\textasciicircum}2 {Criterion} for {Regression} {Models} {Estimated} by the {Instrumental} {Variables} {Method}},
	volume = {62},
	issn = {00129682},
	url = {https://www.jstor.org/stable/2951666?origin=crossref},
	doi = {10.2307/2951666},
	language = {en},
	number = {3},
	urldate = {2021-11-11},
	journal = {Econometrica},
	author = {Pesaran, M. Hashem and Smith, Richard J.},
	month = may,
	year = {1994},
	pages = {705},
	file = {Pesaran et Smith - 1994 - A Generalized R^2 Criterion for Regression Models .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\NDWKESWC\\Pesaran et Smith - 1994 - A Generalized R^2 Criterion for Regression Models .pdf:application/pdf},
}

@article{white_instrumental_1982,
	title = {Instrumental {Variables} {Regression} with {Independent} {Observations}},
	volume = {50},
	issn = {00129682},
	url = {https://www.jstor.org/stable/1912639?origin=crossref},
	doi = {10.2307/1912639},
	language = {en},
	number = {2},
	urldate = {2021-11-11},
	journal = {Econometrica},
	author = {White, Halbert},
	month = mar,
	year = {1982},
	pages = {483},
	file = {White - 1982 - Instrumental Variables Regression with Independent.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\F8EFDT35\\White - 1982 - Instrumental Variables Regression with Independent.pdf:application/pdf},
}

@article{hong_generalized_2003,
	title = {{GENERALIZED} {EMPIRICAL} {LIKELIHOOD}–{BASED} {MODEL} {SELECTION} {CRITERIA} {FOR} {MOMENT} {CONDITION} {MODELS}},
	volume = {19},
	issn = {0266-4666, 1469-4360},
	url = {http://www.journals.cambridge.org/abstract_S0266466603196028},
	doi = {10.1017/S0266466603196028},
	language = {en},
	number = {06},
	urldate = {2021-11-11},
	journal = {Econometric Theory},
	author = {Hong, Han and Preston, Bruce and Shum, Matthew},
	month = dec,
	year = {2003},
	file = {Hong et al. - 2003 - GENERALIZED EMPIRICAL LIKELIHOOD–BASED MODEL SELEC.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\XN8DK266\\Hong et al. - 2003 - GENERALIZED EMPIRICAL LIKELIHOOD–BASED MODEL SELEC.pdf:application/pdf},
}

@article{wang_wild_2021,
	title = {Wild {Bootstrap} for {Instrumental} {Variables} {Regressions} with {Weak} and {Few} {Clusters}},
	abstract = {We study the wild bootstrap inference for instrumental variable (quantile) regressions in the framework of a small number of large clusters, in which the number of clusters is viewed as ﬁxed and the number of observations for each cluster diverges to inﬁnity. For subvector inference, we show that the wild bootstrap Wald test with or without using the cluster-robust covariance matrix controls size asymptotically up to a small error as long as the parameters of endogenous variables are strongly identiﬁed in at least one of the clusters. We further develop a wild bootstrap Anderson-Rubin (AR) test for full-vector inference and show that it controls size asymptotically up to a small error even under weak or partial identiﬁcation for all clusters. We also ﬁnd that this property does not hold for other weak-instrument-robust test statistics. For instrumental variable quantile regressions, a novel gradient wild bootstrap procedure is developed to generate the bootstrap analogues of the Wald and AR statistics. We illustrate good ﬁnite-sample performance of the new inference methods using simulations. Finally, an empirical application of our methods suggests that there exists regional heterogeneity in the eﬀect of Chinese import competition on U.S. local labor markets.},
	language = {en},
	author = {Wang, Wenjie and Zhang, Yichong},
	year = {2021},
	pages = {104},
	file = {Wang et Zhang - Wild Bootstrap for Instrumental Variables Regressi.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\GQRL9PSX\\Wang et Zhang - Wild Bootstrap for Instrumental Variables Regressi.pdf:application/pdf},
}

@article{murray_avoiding_2006,
	title = {Avoiding {Invalid} {Instruments} and {Coping} with {Weak} {Instruments}},
	volume = {20},
	issn = {0895-3309},
	url = {https://pubs.aeaweb.org/doi/10.1257/jep.20.4.111},
	doi = {10.1257/jep.20.4.111},
	abstract = {Archimedes said, “Give me the place to stand, and a lever long enough, and I will move the Earth.” Economists have their own powerful lever: the instrumental variable estimator. The instrumental variable estimator can avoid the bias that ordinary least squares suffers when an explanatory variable in a regression is correlated with the regression's disturbance term. But, like Archimedes' lever, instrumental variable estimation requires both a valid instrument on which to stand and an instrument that isn't too short (or “too weak”). This paper briefly reviews instrumental variable estimation, discusses classic strategies for avoiding invalid instruments (instruments themselves correlated with the regression's disturbances), and describes recently developed strategies for coping with weak instruments (instruments only weakly correlated with the offending explanator).},
	language = {en},
	number = {4},
	urldate = {2021-11-11},
	journal = {Journal of Economic Perspectives},
	author = {Murray, Michael P},
	month = aug,
	year = {2006},
	pages = {111--132},
	file = {Murray - 2006 - Avoiding Invalid Instruments and Coping with Weak .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\LK2PHS3D\\Murray - 2006 - Avoiding Invalid Instruments and Coping with Weak .pdf:application/pdf},
}

@article{cornelissen_late_2016,
	title = {From {LATE} to {MTE}: {Alternative} methods for the evaluation of policy interventions},
	volume = {41},
	issn = {09275371},
	shorttitle = {From {LATE} to {MTE}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0927537116300562},
	doi = {10.1016/j.labeco.2016.06.004},
	language = {en},
	urldate = {2021-11-11},
	journal = {Labour Economics},
	author = {Cornelissen, Thomas and Dustmann, Christian and Raute, Anna and Schönberg, Uta},
	month = aug,
	year = {2016},
	pages = {47--60},
	file = {Cornelissen et al. - 2016 - From LATE to MTE Alternative methods for the eval.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\NIKGKBET\\Cornelissen et al. - 2016 - From LATE to MTE Alternative methods for the eval.pdf:application/pdf},
}

@article{fithian_optimal_2017,
	title = {Optimal {Inference} {After} {Model} {Selection}},
	url = {http://arxiv.org/abs/1410.2597},
	abstract = {To perform inference after model selection, we propose controlling the selective type I error; i.e., the error rate of a test given that it was performed. By doing so, we recover long-run frequency properties among selected hypotheses analogous to those that apply in the classical (non-adaptive) context. Our proposal is closely related to data splitting and has a similar intuitive justiﬁcation, but is more powerful. Exploiting the classical theory of Lehmann and Scheﬀ´e (1955), we derive most powerful unbiased selective tests and conﬁdence intervals for inference in exponential family models after arbitrary selection procedures. For linear regression, we derive new selective z-tests that generalize recent proposals for inference after model selection and improve on their power, and new selective t-tests that do not require knowledge of the error variance.},
	language = {en},
	urldate = {2021-11-11},
	journal = {arXiv:1410.2597 [math, stat]},
	author = {Fithian, William and Sun, Dennis and Taylor, Jonathan},
	month = apr,
	year = {2017},
	note = {arXiv: 1410.2597},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
	file = {Fithian et al. - 2017 - Optimal Inference After Model Selection.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\LLX9BJ8N\\Fithian et al. - 2017 - Optimal Inference After Model Selection.pdf:application/pdf},
}

@article{mogstad_using_2018,
	title = {Using {Instrumental} {Variables} for {Inference} {About} {Policy} {Relevant} {Treatment} {Parameters}},
	volume = {86},
	issn = {0012-9682},
	url = {https://www.econometricsociety.org/doi/10.3982/ECTA15463},
	doi = {10.3982/ECTA15463},
	abstract = {We propose a method for using instrumental variables (IV) to draw inference about causal effects for individuals other than those affected by the instrument at hand. Policy relevance and external validity turn on the ability to do this reliably. Our method exploits the insight that both the IV estimand and many treatment parameters can be expressed as weighted averages of the same underlying marginal treatment effects. Since the weights are identiﬁed, knowledge of the IV estimand generally places some restrictions on the unknown marginal treatment effects, and hence on the values of the treatment parameters of interest. We show how to extract information about the treatment parameter of interest from the IV estimand and, more generally, from a class of IV-like estimands that includes the two stage least squares and ordinary least squares estimands, among others. Our method has several applications. First, it can be used to construct nonparametric bounds on the average causal effect of a hypothetical policy change. Second, our method allows the researcher to ﬂexibly incorporate shape restrictions and parametric assumptions, thereby enabling extrapolation of the average effects for compliers to the average effects for different or larger populations. Third, our method can be used to test model speciﬁcation and hypotheses about behavior, such as no selection bias and/or no selection on gain.},
	language = {en},
	number = {5},
	urldate = {2021-12-22},
	journal = {Econometrica},
	author = {Mogstad, Magne and Santos, Andres and Torgovitsky, Alexander},
	year = {2018},
	pages = {1589--1619},
	file = {Mogstad et al. - 2018 - Using Instrumental Variables for Inference About P.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\CM537LIJ\\Mogstad et al. - 2018 - Using Instrumental Variables for Inference About P.pdf:application/pdf},
}

@article{windmeijer_use_2019-1,
	title = {On the {Use} of the {Lasso} for {Instrumental} {Variables} {Estimation} with {Some} {Invalid} {Instruments}},
	volume = {114},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2018.1498346},
	doi = {10.1080/01621459.2018.1498346},
	abstract = {We investigate the behavior of the Lasso for selecting invalid instruments in linear instrumental variables models for estimating causal effects of exposures on outcomes, as proposed recently by Kang et al. Invalid instruments are such that they fail the exclusion restriction and enter the model as explanatory variables. We show that for this setup, the Lasso may not consistently select the invalid instruments if these are relatively strong. We propose a median estimator that is consistent when less than 50\% of the instruments are invalid, and its consistency does not depend on the relative strength of the instruments, or their correlation structure. We show that this estimator can be used for adaptive Lasso estimation, with the resulting estimator having oracle properties. The methods are applied to a Mendelian randomization study to estimate the causal effect of body mass index (BMI) on diastolic blood pressure, using data on individuals from the UK Biobank, with 96 single nucleotide polymorphisms as potential instruments for BMI. Supplementary materials for this article are available online.},
	language = {en},
	number = {527},
	urldate = {2021-12-22},
	journal = {Journal of the American Statistical Association},
	author = {Windmeijer, Frank and Farbmacher, Helmut and Davies, Neil and Davey Smith, George},
	month = jul,
	year = {2019},
	pages = {1339--1350},
	file = {Windmeijer et al. - 2019 - On the Use of the Lasso for Instrumental Variables.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\7MCJHEVD\\Windmeijer et al. - 2019 - On the Use of the Lasso for Instrumental Variables.pdf:application/pdf},
}

@incollection{baltagi_expository_2012,
	title = {An {Expository} {Note} on the {Existence} of {Moments} of {Fuller} and {HFUL} {Estimators}},
	volume = {29},
	isbn = {978-1-78190-307-0 978-1-78190-308-7},
	url = {https://www.emerald.com/insight/content/doi/10.1108/S0731-9053(2012)0000029009/full/html},
	language = {en},
	urldate = {2022-01-17},
	booktitle = {Advances in {Econometrics}},
	publisher = {Emerald Group Publishing Limited},
	author = {Chao, John C. and Hausman, Jerry A. and Newey, Whitney K. and Swanson, Norman R. and Woutersen, Tiemen},
	month = jan,
	year = {2012},
	doi = {10.1108/S0731-9053(2012)0000029009},
	pages = {87--106},
	file = {Chao et al. - 2012 - An Expository Note on the Existence of Moments of .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\I9ZINPUQ\\Chao et al. - 2012 - An Expository Note on the Existence of Moments of .pdf:application/pdf},
}

@article{kiviet_instrument_2021,
	title = {Instrument approval by the {Sargan} test and its consequences for coefficient estimation},
	volume = {205},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165176521002123},
	doi = {10.1016/j.econlet.2021.109935},
	abstract = {Empirical econometric findings are often vindicated by supplementing them with the p-values of Sargan–Hansen tests for overidentifying restrictions, provided these exceed a chosen small nominal significance level. It is illustrated here that the probability that such tests reject instrument validity may often barely exceed small levels, even when instruments are seriously invalid, whereas even minor invalidity of instruments can severely undermine inference on regression coefficients by instrumental variable estimators. These uncomfortable patterns may be aggravated when particular valid or invalid instruments are relatively weak or strong.},
	language = {en},
	urldate = {2022-01-19},
	journal = {Economics Letters},
	author = {Kiviet, Jan F. and Kripfganz, Sebastian},
	month = aug,
	year = {2021},
	file = {Kiviet et Kripfganz - 2021 - Instrument approval by the Sargan test and its con.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\TUFB8NTM\\Kiviet et Kripfganz - 2021 - Instrument approval by the Sargan test and its con.pdf:application/pdf},
}

@article{lei_cross-validation_2017,
	title = {Cross-{Validation} with {Confidence}},
	url = {http://arxiv.org/abs/1703.07904},
	abstract = {Cross-validation is one of the most popular model selection methods in statistics and machine learning. Despite its wide applicability, traditional cross-validation methods tend to select overﬁtting models, due to the ignorance of the uncertainty in the testing sample. We develop a new, statistically principled inference tool based on cross-validation that takes into account the uncertainty in the testing sample. This new method outputs a set of highly competitive candidate models containing the best one with guaranteed probability. As a consequence, our method can achieve consistent variable selection in a classical linear regression setting, for which existing cross-validation methods require unconventional split ratios. When used for regularizing tuning parameter selection, the method can provide a further trade-oﬀ between prediction accuracy and model interpretability. We demonstrate the performance of the proposed method in several simulated and real data examples.},
	language = {en},
	urldate = {2022-01-19},
	journal = {arXiv:1703.07904 [stat]},
	author = {Lei, Jing},
	month = dec,
	year = {2017},
	note = {arXiv: 1703.07904},
	keywords = {Statistics - Methodology, Statistics - Machine Learning},
	annote = {Comment: 35 pages, 5 figures},
	file = {Lei - 2017 - Cross-Validation with Confidence.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\7DD4YGRN\\Lei - 2017 - Cross-Validation with Confidence.pdf:application/pdf},
}

@article{clarke_instrumental_2012,
	title = {Instrumental {Variable} {Estimators} for {Binary} {Outcomes}},
	volume = {107},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2012.734171},
	doi = {10.1080/01621459.2012.734171},
	abstract = {Instrumental variables (IVs) can be used to construct estimators of exposure effects on the outcomes of studies affected by non-ignorable selection of the exposure. Estimators which fail to adjust for the effects of non-ignorable selection will be biased and inconsistent. Such situations commonly arise in observational studies, but even randomised controlled trials can be affected by non-ignorable participant non-compliance. In this paper, we review IV estimators for studies in which the outcome is binary. Recent work on identification is interpreted using an integrated structural modelling and potential outcomes framework, within which we consider the links between different approaches developed in statistics and econometrics. The implicit assumptions required for bounding causal effects and pointidentification by each estimator are highlighted and compared within our framework. Finally, the implications for practice are discussed.},
	language = {en},
	number = {500},
	urldate = {2022-01-19},
	journal = {Journal of the American Statistical Association},
	author = {Clarke, Paul S. and Windmeijer, Frank},
	month = dec,
	year = {2012},
	pages = {1638--1652},
	file = {Clarke et Windmeijer - 2012 - Instrumental Variable Estimators for Binary Outcom.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\GKWMS53P\\Clarke et Windmeijer - 2012 - Instrumental Variable Estimators for Binary Outcom.pdf:application/pdf},
}

@article{windmeijer_confidence_2021,
	title = {The confidence interval method for selecting valid instrumental variables},
	volume = {83},
	issn = {1369-7412, 1467-9868},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/rssb.12449},
	doi = {10.1111/rssb.12449},
	abstract = {We propose a new method, the confidence interval (CI) method, to select valid instruments from a larger set of potential instruments for instrumental variable (IV) estimation of the causal effect of an exposure on an outcome. Invalid instruments are such that they fail the exclusion conditions and enter the model as explanatory variables. The CI method is based on the CIs of the per instrument causal effects estimates and selects the largest group with all CIs overlapping with each other as the set of valid instruments. Under a plurality rule, we show that the resulting standard IV, or two-­stage least squares (2SLS) estimator has oracle properties. This result is the same as for the hard thresholding with voting (HT) method of Guo et al. (Journal of the Royal Statistical Society : Series B, 2018, 80, 793–­815). Unlike the HT method, the number of instruments selected as valid by the CI method is guaranteed to be monotonically decreasing for decreasing values of the tuning parameter. For the CI method, we can therefore use a downward testing procedure based on the Sargan (Econometrica, 1958, 26, 393–­415) test for overidentifying restrictions and a main advantage of the CI downward testing method is that it selects the model with the largest number of instruments selected as valid that passes the Sargan test.},
	language = {en},
	number = {4},
	urldate = {2022-01-19},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Windmeijer, Frank and Liang, Xiaoran and Hartwig, Fernando P. and Bowden, Jack},
	month = sep,
	year = {2021},
	pages = {752--776},
	file = {Windmeijer et al. - 2021 - The confidence interval method for selecting valid.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\NFKPWVGI\\Windmeijer et al. - 2021 - The confidence interval method for selecting valid.pdf:application/pdf},
}

@article{mogstad_identication_2017,
	title = {Identiﬁcation and {Extrapolation} with {Instrumental} {Variables}},
	abstract = {Instrumental variables (IV) are widely used in economics to address selection on unobservables. Standard IV methods produce estimates of causal eﬀects that are speciﬁc to individuals whose behavior can be manipulated by the instrument at hand. In many cases, these individuals are not the same as those who would be induced to treatment by an intervention or policy of interest to the researcher. The average causal eﬀect for the two groups can diﬀer signiﬁcantly if the eﬀect of the treatment varies systematically with unobserved factors that are correlated with treatment choice. We review the implications of this type of unobserved heterogeneity for the interpretation of standard IV methods and for their relevance to policy evaluation. We argue that drawing inference about policy relevant parameters typically requires extrapolating from the individuals aﬀected by the instrument to the individuals who would be induced to treatment by the policy under consideration. We discuss a variety of alternatives to standard IV methods that can be used to perform this extrapolation rigorously. We show that many of these approaches can be nested as special cases of a general framework that embraces the possibility of partial identiﬁcation.},
	language = {en},
	author = {Mogstad, Magne and Torgovitsky, Alexander},
	year = {2017},
	pages = {49},
	file = {Mogstad et Torgovitsky - Identiﬁcation and Extrapolation with Instrumental .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\5APEB4XI\\Mogstad et Torgovitsky - Identiﬁcation and Extrapolation with Instrumental .pdf:application/pdf},
}

@article{torgovitsky_minimum_2017,
	title = {Minimum distance from independence estimation of nonseparable instrumental variables models},
	volume = {199},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407617300441},
	doi = {10.1016/j.jeconom.2017.01.009},
	abstract = {I develop a semiparametric minimum distance from independence estimator for a nonseparable instrumental variables model. An independence condition identifies the model for many types of discrete and continuous instruments. The estimator is taken as the parameter value that most closely satisfies this independence condition. Implementing the estimator requires a quantile regression of the endogenous variables on the instrument, so the procedure is two-step, with a finite or infinite-dimensional nuisance parameter in the first step. I prove consistency and establish asymptotic normality for a parametric, but flexibly nonlinear outcome equation. The consistency of the nonparametric bootstrap is also shown. I illustrate the use of the estimator by estimating the returns to schooling using data from the 1979 National Longitudinal Survey.},
	language = {en},
	number = {1},
	urldate = {2022-01-19},
	journal = {Journal of Econometrics},
	author = {Torgovitsky, Alexander},
	month = jul,
	year = {2017},
	pages = {35--48},
	file = {Torgovitsky - 2017 - Minimum distance from independence estimation of n.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\EYW3VPKW\\Torgovitsky - 2017 - Minimum distance from independence estimation of n.pdf:application/pdf},
}

@article{hausman_asymptotic_2005,
	title = {Asymptotic properties of the {Hahn}–{Hausman} test for weak-instruments},
	volume = {89},
	issn = {01651765},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165176505002314},
	doi = {10.1016/j.econlet.2005.06.007},
	abstract = {This paper provides weak-instrument asymptotic representations of tests for instrument validity by Hahn and Hausman’s (HH) [Hahn, J., Hausman, J., 2002. A new specification test for the validity of instrumental variables. Econometrica 70, 163–189.], and uses these representations to compute asymptotic power against weak or irrelevant instruments. The HH tests were proposed as pretests, and the asymptotic properties of post-test inferences, conditional on the tests failing to reject instrument validity, are also examined.},
	language = {en},
	number = {3},
	urldate = {2022-01-19},
	journal = {Economics Letters},
	author = {Hausman, Jerry and Stock, James H. and Yogo, Motohiro},
	month = dec,
	year = {2005},
	pages = {333--342},
	file = {Hausman et al. - 2005 - Asymptotic properties of the Hahn–Hausman test for.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\54ZRXNTY\\Hausman et al. - 2005 - Asymptotic properties of the Hahn–Hausman test for.pdf:application/pdf},
}

@article{lavergne_model_nodate,
	title = {Model {Selection} and {Cross}-{Validation}},
	language = {en},
	author = {Lavergne, Pascal},
	pages = {14},
	file = {Lavergne - Model Selection and Cross-Validation.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\WJ9N6HT5\\Lavergne - Model Selection and Cross-Validation.pdf:application/pdf},
}

@article{narita_algorithm_2021,
	title = {Algorithm is {Experiment}: {Machine} {Learning}, {Market} {Design}, and {Policy} {Eligibility} {Rules}},
	shorttitle = {Algorithm is {Experiment}},
	url = {http://arxiv.org/abs/2104.12909},
	abstract = {Algorithms produce a growing portion of decisions and recommendations both in policy and business. Such algorithmic decisions are natural experiments (conditionally quasirandomly assigned instruments) since the algorithms make decisions based only on observable input variables. We use this observation to develop a treatment-eﬀect estimator for a class of stochastic and deterministic decision-making algorithms. Our estimator is shown to be consistent and asymptotically normal for well-deﬁned causal eﬀects. A key special case of our estimator is a multidimensional regression discontinuity design. We apply our estimator to evaluate the eﬀect of the Coronavirus Aid, Relief, and Economic Security (CARES) Act, where hundreds of billions of dollars worth of relief funding is allocated to hospitals via an algorithmic rule. Our estimates suggest that the relief funding has little eﬀect on COVID19-related hospital activity levels. Naive OLS and IV estimates exhibit substantial selection bias.},
	language = {en},
	urldate = {2022-01-31},
	journal = {arXiv:2104.12909 [cs, econ, stat]},
	author = {Narita, Yusuke and Yata, Kohei},
	month = dec,
	year = {2021},
	note = {arXiv: 2104.12909},
	keywords = {Economics - Econometrics, Statistics - Methodology, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Narita et Yata - 2021 - Algorithm is Experiment Machine Learning, Market .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\MESJX4J7\\Narita et Yata - 2021 - Algorithm is Experiment Machine Learning, Market .pdf:application/pdf},
}

@article{shao_asymptotic_1997,
	title = {An {Asymptotic} {Theory} for {Linear} {Model} {Selection}},
	volume = {7},
	abstract = {In the problem of selecting a linear model to approximate the true un known regression model, some necessary and/or sufficient conditions are estab lished for the asymptotic validity of various model selection procedures such as Akaike's AIC, Mallows' Cp, Shibata's FPEa, Schwarz' BIC, generalized AIC, cross validation, and generalized cross-validation. It is found that these selection proce dures can be classified into three classes according to their asymptotic behavior. Under some fairly weak conditions, the selection procedures in one class are asymp totically valid if there exist fixed-dimension correct models; the selection procedures in another class are asymptotically valid if no fixed-dimension correct model exists. The procedures in the third class are compromises of the procedures in the first two classes. Some empirical results are also presented.},
	language = {en},
	number = {2},
	journal = {Statistica Sinica},
	author = {Shao, Jun},
	year = {1997},
	pages = {23},
	file = {Shao - 2022 - AN ASYMPTOTIC THEORY FOR LINEAR MODEL SELECTION.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\F2D9R2ZC\\Shao - 2022 - AN ASYMPTOTIC THEORY FOR LINEAR MODEL SELECTION.pdf:application/pdf},
}

@article{arlot_survey_2010,
	title = {A survey of cross-validation procedures for model selection},
	volume = {4},
	issn = {1935-7516},
	url = {https://projecteuclid.org/journals/statistics-surveys/volume-4/issue-none/A-survey-of-cross-validation-procedures-for-model-selection/10.1214/09-SS054.full},
	doi = {10.1214/09-SS054},
	abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its (apparent) universality. Many results exist on model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
	language = {en},
	number = {none},
	urldate = {2022-02-14},
	journal = {Statistics Surveys},
	author = {Arlot, Sylvain and Celisse, Alain},
	month = jan,
	year = {2010},
	file = {Arlot et Celisse - 2010 - A survey of cross-validation procedures for model .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\F748CML5\\Arlot et Celisse - 2010 - A survey of cross-validation procedures for model .pdf:application/pdf},
}

@article{lavergne_statistical_nodate,
	title = {Statistical {Learning}},
	language = {en},
	author = {Lavergne, Pascal},
	pages = {29},
	file = {Lavergne - Statistical Learning.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\WG9EU2CC\\Lavergne - Statistical Learning.pdf:application/pdf},
}

@article{lavergne_statistical_nodate-1,
	title = {Statistical {Learning} - {Model} {Selection}},
	language = {en},
	author = {Lavergne, Pascal},
	pages = {23},
	file = {Lavergne - Statistical Learning.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\92N4949Y\\Lavergne - Statistical Learning.pdf:application/pdf},
}

@article{lavergne_statistical_nodate-2,
	title = {Statistical {Learning} - {Regressor} {Selection}},
	language = {en},
	author = {Lavergne, Pascal},
	pages = {23},
	file = {Lavergne - Statistical Learning.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\SLRW6C3J\\Lavergne - Statistical Learning.pdf:application/pdf},
}

@article{lavergne_statistical_nodate-3,
	title = {Statistical {Learning} - {Classification}},
	language = {en},
	author = {Lavergne, Pascal},
	pages = {24},
	file = {Lavergne - Statistical Learning.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\JNVMBB44\\Lavergne - Statistical Learning.pdf:application/pdf},
}

@article{lavergne_statistical_nodate-4,
	title = {Statistical {Learning} - {Bootstrap} and {Model} {Selection}},
	language = {en},
	author = {Lavergne, Pascal},
	pages = {22},
	file = {Lavergne - Statistical Learning.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\D3S4B5MC\\Lavergne - Statistical Learning.pdf:application/pdf},
}

@article{lavergne_statistical_nodate-5,
	title = {Statistical {Learning} - {Nonparametric} {Regression}},
	language = {en},
	author = {Lavergne, Pascal},
	pages = {23},
	file = {Lavergne - Statistical Learning.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\P99ID5SB\\Lavergne - Statistical Learning.pdf:application/pdf},
}

@article{belloni_sparse_2012-1,
	title = {Sparse {Models} and {Methods} for {Optimal} {Instruments} {With} an {Application} to {Eminent} {Domain}},
	volume = {80},
	issn = {0012-9682},
	url = {http://doi.wiley.com/10.3982/ECTA9626},
	doi = {10.3982/ECTA9626},
	language = {en},
	number = {6},
	urldate = {2022-02-14},
	journal = {Econometrica},
	author = {Belloni, A. and Chernozhukov, V. and Chen, Daniel and Hansen, C.},
	year = {2012},
	pages = {2369--2429},
	file = {2012 - Sparse Models and Methods for Optimal Instruments .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\HIFKREGT\\2012 - Sparse Models and Methods for Optimal Instruments .pdf:application/pdf},
}

@article{belloni_inference_2012,
	title = {Inference on {Treatment} {Effects} {After} {Selection} {Amongst} {High}-{Dimensional} {Controls}},
	url = {http://arxiv.org/abs/1201.0224},
	abstract = {We propose robust methods for inference on the eﬀect of a treatment variable on a scalar outcome in the presence of very many controls. Our setting is a partially linear model with possibly non-Gaussian and heteroscedastic disturbances where the number of controls may be much larger than the sample size. To make informative inference feasible, we require the model to be approximately sparse; that is, we require that the eﬀect of confounding factors can be controlled for up to a small approximation error by conditioning on a relatively small number of controls whose identities are unknown. The latter condition makes it possible to estimate the treatment eﬀect by selecting approximately the right set of controls. We develop a novel estimation and uniformly valid inference method for the treatment eﬀect in this setting, called the “post-double-selection” method. Our results apply to Lasso-type methods used for covariate selection as well as to any other model selection method that is able to ﬁnd a sparse model with good approximation properties.},
	language = {en},
	urldate = {2022-02-14},
	journal = {arXiv:1201.0224 [econ, stat]},
	author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian},
	month = may,
	year = {2012},
	note = {arXiv: 1201.0224},
	keywords = {Economics - Econometrics, Statistics - Applications, Statistics - Methodology},
	file = {Belloni et al. - 2012 - Inference on Treatment Effects After Selection Amo.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\X5J5FQCY\\Belloni et al. - 2012 - Inference on Treatment Effects After Selection Amo.pdf:application/pdf},
}

@article{belloni_high-dimensional_2014,
	title = {High-{Dimensional} {Methods} and {Inference} on {Structural} and {Treatment} {Effects}},
	volume = {28},
	issn = {0895-3309},
	url = {https://pubs.aeaweb.org/doi/10.1257/jep.28.2.29},
	doi = {10.1257/jep.28.2.29},
	abstract = {Data with a large number of variables relative to the sample size—“high-dimensional data”—are readily available and increasingly common in empirical economics. Highdimensional data arise through a combination of two phenomena. First, the data may be inherently high dimensional in that many different characteristics per observation are available. For example, the US Census collects information on hundreds of individual characteristics and scanner datasets record transaction-level data for households across a wide range of products. Second, even when the number of available variables is relatively small, researchers rarely know the exact functional form with which the small number of variables enter the model of interest. Researchers are thus faced with a large set of potential variables formed by different ways of interacting and transforming the underlying variables. This paper provides an overview of how innovations in “data mining” can be adapted and modified to provide high-quality inference about model parameters. Note that we use the term “data mining” in a modern sense which denotes a principled search for “true” predictive power that guards against false discovery and overfitting, does not erroneously equate in-sample fit to out-of-sample predictive ability, and accurately accounts for using the same data to examine many different hypotheses or models.},
	language = {en},
	number = {2},
	urldate = {2022-02-14},
	journal = {Journal of Economic Perspectives},
	author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian},
	month = may,
	year = {2014},
	pages = {29--50},
	file = {Belloni et al. - 2014 - High-Dimensional Methods and Inference on Structur.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\X8FTK92H\\Belloni et al. - 2014 - High-Dimensional Methods and Inference on Structur.pdf:application/pdf},
}

@article{belloni_inference_2014,
	title = {Inference in {High} {Dimensional} {Panel} {Models} with an {Application} to {Gun} {Control}},
	url = {http://arxiv.org/abs/1411.6507},
	abstract = {We consider estimation and inference in panel data models with additive unobserved individual speciﬁc heterogeneity in a high dimensional setting. The setting allows the number of time varying regressors to be larger than the sample size. To make informative estimation and inference feasible, we require that the overall contribution of the time varying variables after eliminating the individual speciﬁc heterogeneity can be captured by a relatively small number of the available variables whose identities are unknown. This restriction allows the problem of estimation to proceed as a variable selection problem. Importantly, we treat the individual speciﬁc heterogeneity as ﬁxed eﬀects which allows this heterogeneity to be related to the observed time varying variables in an unspeciﬁed way and allows that this heterogeneity may be non-zero for all individuals. Within this framework, we provide procedures that give uniformly valid inference over a ﬁxed subset of parameters in the canonical linear ﬁxed eﬀects model and over coeﬃcients on a ﬁxed vector of endogenous variables in panel data instrumental variables models with ﬁxed eﬀects and many instruments. An input to developing the properties of our proposed procedures is the use of a variant of the Lasso estimator that allows for a grouped data structure where data across groups are independent and dependence within groups is unrestricted. We provide formal conditions within this structure under which the proposed Lasso variant selects a sparse model with good approximation properties. We present simulation results in support of the theoretical developments and illustrate the use of the methods in an application aimed at estimating the eﬀect of gun prevalence on crime rates.},
	language = {en},
	urldate = {2022-02-14},
	journal = {arXiv:1411.6507 [econ, stat]},
	author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian and Kozbur, Damian},
	month = nov,
	year = {2014},
	note = {arXiv: 1411.6507},
	keywords = {Economics - Econometrics, Statistics - Methodology},
	file = {Belloni et al. - 2014 - Inference in High Dimensional Panel Models with an.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\NYACDK69\\Belloni et al. - 2014 - Inference in High Dimensional Panel Models with an.pdf:application/pdf},
}

@article{ding_model_2018,
	title = {Model {Selection} {Techniques} -- {An} {Overview}},
	volume = {35},
	issn = {1053-5888, 1558-0792},
	url = {http://arxiv.org/abs/1810.09583},
	doi = {10.1109/MSP.2018.2867638},
	abstract = {In the era of “big data”, analysts usually explore various statistical models or machine learning methods for observed data in order to facilitate scientiﬁc discoveries or gain predictive power. Whatever data and ﬁtting procedures are employed, a crucial step is to select the most appropriate model or method from a set of candidates. Model selection is a key ingredient in data analysis for reliable and reproducible statistical inference or prediction, and thus central to scientiﬁc studies in ﬁelds such as ecology, economics, engineering, ﬁnance, political science, biology, and epidemiology. There has been a long history of model selection techniques that arise from researches in statistics, information theory, and signal processing. A considerable number of methods have been proposed, following different philosophies and exhibiting varying performances. The purpose of this article is to bring a comprehensive overview of them, in terms of their motivation, large sample performance, and applicability. We provide integrated and practically relevant discussions on theoretical properties of state-ofthe-art model selection approaches. We also share our thoughts on some controversial views on the practice of model selection.},
	language = {en},
	number = {6},
	urldate = {2022-02-14},
	journal = {IEEE Signal Processing Magazine},
	author = {Ding, Jie and Tarokh, Vahid and Yang, Yuhong},
	month = nov,
	year = {2018},
	note = {arXiv: 1810.09583},
	keywords = {Economics - Econometrics, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Information Theory, Physics - Applied Physics},
	pages = {16--34},
	annote = {Comment: accepted by IEEE SIGNAL PROCESSING MAGAZINE},
	file = {Ding et al. - 2018 - Model Selection Techniques -- An Overview.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\3RS984NP\\Ding et al. - 2018 - Model Selection Techniques -- An Overview.pdf:application/pdf},
}

@article{noh_efficient_2012,
	title = {Efficient model selection in semivarying coefficient models},
	volume = {6},
	issn = {1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-6/issue-none/Efficient-model-selection-in-semivarying-coefficient-models/10.1214/12-EJS762.full},
	doi = {10.1214/12-EJS762},
	abstract = {Varying coeﬃcient models are useful extensions of classical linear models. In practice, some of the coeﬃcients may be just constant, while other coeﬃcients are varying. Several methods have been developed to utilize the information that some coeﬃcient functions are constant to improve estimation eﬃciency. However, in order for such methods to really work, the information about which coeﬃcient functions are constant should be given in advance. In this paper, we propose a computationally eﬃcient method to discriminate in a consistent way the constant coeﬃcient functions from the varying ones. Additionally, we compare the performance of our proposal with that of previous methods developed for the same purpose in terms of model selection accuracy and computing time.},
	language = {en},
	number = {none},
	urldate = {2022-02-14},
	journal = {Electronic Journal of Statistics},
	author = {Noh, Hohsuk and Van Keilegom, Ingrid},
	month = jan,
	year = {2012},
	file = {Noh and Van Keilegom - 2012 - Efficient model selection in semivarying coefficie.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\FTIER8B7\\Noh and Van Keilegom - 2012 - Efficient model selection in semivarying coefficie.pdf:application/pdf},
}

@article{shao_linear_1993,
	title = {Linear {Model} {Selection} by {Cross}-{Validation}},
	volume = {88},
	language = {en},
	number = {422},
	journal = {Journal of the American Statistical Association},
	author = {Shao, Jun},
	year = {1993},
	pages = {10},
	file = {2022 - Linear Model Selection by Cross-Validation.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\5GJMTI35\\2022 - Linear Model Selection by Cross-Validation.pdf:application/pdf},
}

@article{sanquetta_selection_2018,
	title = {Selection criteria for linear regression models to estimate individual tree biomasses in the {Atlantic} {Rain} {Forest}, {Brazil}},
	volume = {13},
	issn = {1750-0680},
	url = {https://cbmjournal.biomedcentral.com/articles/10.1186/s13021-018-0112-6},
	doi = {10.1186/s13021-018-0112-6},
	abstract = {Background:  Biomass models are useful for several purposes, especially for quantifying carbon stocks and dynamics in forests. Selecting appropriate equations from a fitted model is a process which can involves several criteria, some widely used and others used to a lesser extent. This study analyzes six selection criteria for models fitted to six sets of individual biomass collected from woody indigenous species of the Tropical Atlantic Rain Forest in Brazil. Six models were examined and the respective fitted equations evaluated by the residual sum of squares, adjusted coefficient of determination, absolute and relative estimates of the standard error of estimate, and Akaike and Schwartz (Bayesian) information criteria. The aim of this study was to analyze the numeric behavior of these model selection criteria and discuss the ease of interpretation of them. The importance of residual analysis in model selection is stressed.
Results:  The adjusted coefficient of determination ( Ra2dj. ) and the standard error of estimate in percentage (Syx\%) are relative model selection criteria and are not affected by sample size and scale of the response variable. The sum of squared residuals (SSR), the absolute standard error of estimate (Syx), the Akaike information criterion and the Schwartz information criterion, in turn, depend on these quantities. The best fit model was always the same within a given data set regardless the model selection criteria considered (except for SSR in two cases), indicating they tend to converge to a common result. However, such criteria are not always closely related across different data sets. General model selection criteria are indicative of the average goodness of fit, but do not capture bias and outlier effects. Graphical residual analysis is a useful tool to this detection and must always be used in model selection.
Conclusions:  It is concluded that the criteria for model selection tend to lead to a common result, regardless their mathematical formulation and statistical significance. Relative measures of goodness of fitting are easier to interpret than the absolute ones. Careful graphical residual analysis must always be used to confirm the performance of the models.},
	language = {en},
	number = {1},
	urldate = {2022-02-14},
	journal = {Carbon Balance and Management},
	author = {Sanquetta, Carlos Roberto and Dalla Corte, Ana Paula and Behling, Alexandre and de Oliveira Piva, Luani Rosa and Péllico Netto, Sylvio and Rodrigues, Aurélio Lourenço and Sanquetta, Mateus Niroh Inoue},
	month = dec,
	year = {2018},
	pages = {25},
	file = {Sanquetta et al. - 2018 - Selection criteria for linear regression models to.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\JQ59IMHY\\Sanquetta et al. - 2018 - Selection criteria for linear regression models to.pdf:application/pdf},
}

@article{ronchetti_robust_2022,
	title = {Robust {Linear} {Model} {Selection} by {Cross}-{Validation}},
	language = {en},
	author = {Ronchetti, Elvezio and Field, Christopher and Blanchard, Wade},
	year = {2022},
	pages = {8},
	file = {Ronchetti et al. - 2022 - Robust Linear Model Selection by Cross-Validation.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\RNNAUMUS\\Ronchetti et al. - 2022 - Robust Linear Model Selection by Cross-Validation.pdf:application/pdf},
}

@article{kadane_methods_2004,
	title = {Methods and {Criteria} for {Model} {Selection}},
	volume = {99},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214504000000269},
	doi = {10.1198/016214504000000269},
	language = {en},
	number = {465},
	urldate = {2022-02-14},
	journal = {Journal of the American Statistical Association},
	author = {Kadane, Joseph B and Lazar, Nicole A},
	month = mar,
	year = {2004},
	pages = {279--290},
	file = {Kadane and Lazar - 2004 - Methods and Criteria for Model Selection.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\VFKWUMXJ\\Kadane and Lazar - 2004 - Methods and Criteria for Model Selection.pdf:application/pdf},
}

@article{efron_estimation_2014,
	title = {Estimation and {Accuracy} {After} {Model} {Selection}},
	volume = {109},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2013.823775},
	doi = {10.1080/01621459.2013.823775},
	language = {en},
	number = {507},
	urldate = {2022-02-14},
	journal = {Journal of the American Statistical Association},
	author = {Efron, Bradley},
	month = jul,
	year = {2014},
	pages = {991--1007},
	file = {Efron - 2014 - Estimation and Accuracy After Model Selection.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\J586PQA6\\Efron - 2014 - Estimation and Accuracy After Model Selection.pdf:application/pdf},
}

@incollection{chakrabarti_aic_2011,
	title = {{AIC}, {BIC} and {Recent} {Advances} in {Model} {Selection}},
	isbn = {978-0-444-51862-0},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444518620500186},
	language = {en},
	urldate = {2022-02-15},
	booktitle = {Philosophy of {Statistics}},
	publisher = {Elsevier},
	author = {Chakrabarti, Arijit and Ghosh, Jayanta K.},
	year = {2011},
	doi = {10.1016/B978-0-444-51862-0.50018-6},
	pages = {583--605},
	file = {Chakrabarti and Ghosh - 2011 - AIC, BIC and Recent Advances in Model Selection.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\P6THPM44\\Chakrabarti and Ghosh - 2011 - AIC, BIC and Recent Advances in Model Selection.pdf:application/pdf},
}

@article{shen_inference_2004,
	title = {Inference {After} {Model} {Selection}},
	volume = {99},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214504000001097},
	doi = {10.1198/016214504000001097},
	language = {en},
	number = {467},
	urldate = {2022-02-15},
	journal = {Journal of the American Statistical Association},
	author = {Shen, Xiaotong and Huang, Hsin-Cheng and Ye, Jimmy},
	month = sep,
	year = {2004},
	pages = {751--762},
	file = {Shen et al. - 2004 - Inference After Model Selection.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\3FYCTCU9\\Shen et al. - 2004 - Inference After Model Selection.pdf:application/pdf},
}

@article{liang_exact_2004,
	title = {Exact {Minimax} {Strategies} for {Predictive} {Density} {Estimation}, {Data} {Compression}, and {Model} {Selection}},
	volume = {50},
	issn = {0018-9448},
	url = {http://ieeexplore.ieee.org/document/1347357/},
	doi = {10.1109/TIT.2004.836922},
	abstract = {For location and scale families of distributions and related settings of linear regression, we determine minimax procedures for predictive density estimation, for universal data compression, and for the minimum description length (MDL) criterion for model selection. The analysis gives the best invariant and indeed minimax procedure for predictive density estimation by directly verifying extended Bayes properties or, alternatively, by general aspects of decision theory on groups which are shown to simplify in the case of Kullback–Leibler loss. An exact minimax rule is generalized Bayes using a uniform (Lebesgue measure) prior on the location and log-scale parameters, which is made proper by conditioning on an initial set of observations.},
	language = {en},
	number = {11},
	urldate = {2022-02-15},
	journal = {IEEE Transactions on Information Theory},
	author = {Liang, F. and Barron, A.},
	month = nov,
	year = {2004},
	pages = {2708--2726},
	file = {Liang and Barron - 2004 - Exact Minimax Strategies for Predictive Density Es.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\N82RDJ5X\\Liang and Barron - 2004 - Exact Minimax Strategies for Predictive Density Es.pdf:application/pdf},
}

@techreport{ayres_shooting_2002,
	address = {Cambridge, MA},
	title = {Shooting {Down} the {More} {Guns}, {Less} {Crime} {Hypothesis}},
	url = {http://www.nber.org/papers/w9336.pdf},
	language = {en},
	number = {w9336},
	urldate = {2022-02-16},
	institution = {National Bureau of Economic Research},
	author = {Ayres, Ian and Donohue, John},
	month = nov,
	year = {2002},
	doi = {10.3386/w9336},
	pages = {w9336},
	file = {w9336.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\8NCEHDCK\\w9336.pdf:application/pdf},
}

@article{rao_model_2001,
	title = {On {Model} {Selection}},
	volume = {38},
	journal = {IMS Lecture Notes - Monograph Series},
	author = {Rao and Wu},
	year = {2001},
	file = {1215540960.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ESFAC9V8\\1215540960.pdf:application/pdf},
}

@article{shao_bootstrap_1996,
	title = {Bootstrap {Model} {Selection}},
	volume = {91},
	url = {https://www-jstor-org.gorgone.univ-toulouse.fr/stable/pdf/2291661.pdf?refreqid=excelsior%3A4fb80c2419ad939713408e8baff9e9f3&ab_segments=&origin=},
	number = {434},
	urldate = {2022-02-14},
	journal = {Journal of the American Statistical Association},
	author = {Shao, Jun},
	year = {1996},
	pages = {655--665},
	file = {2022 - Bootstrap Model Selection.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\CM2DF6D6\\2022 - Bootstrap Model Selection.pdf:application/pdf},
}

@article{windmeijer_testing_2021,
	title = {Testing underidentification in linear models, with applications to dynamic panel and asset pricing models},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030440762100097X},
	doi = {10.1016/j.jeconom.2021.03.007},
	language = {en},
	urldate = {2022-02-16},
	journal = {Journal of Econometrics},
	author = {Windmeijer, Frank},
	month = apr,
	year = {2021},
	pages = {S030440762100097X},
	file = {Windmeijer - Testing Over- and Underidenti…cation in Linear Mod.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\JH32WT4R\\Windmeijer - Testing Over- and Underidenti…cation in Linear Mod.pdf:application/pdf},
}

@misc{lavergne_caret_nodate,
	title = {caret cheat sheet},
	url = {https://cours21-22.ut-capitole.fr/pluginfile.php/937819/mod_resource/content/0/caret.pdf},
	urldate = {2022-02-14},
	author = {Lavergne, Pascal},
	file = {caret.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\J7EI2VMH\\caret.pdf:application/pdf},
}

@article{bates_cross-validation_2021,
	doi = {10.48550/ARXIV.2104.00673},
  url = {https://arxiv.org/abs/2104.00673},
  author = {Bates,  Stephen and Hastie,  Trevor and Tibshirani,  Robert},
  keywords = {Methodology (stat.ME),  Statistics Theory (math.ST),  Computation (stat.CO),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Mathematics,  FOS: Mathematics},
  title = {Cross-validation: what does it estimate and how well does it do it?},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{windmeijer_note_1995,
	title = {A {Note} on {R2} in the {Instrumental} {Variables} {Model}},
	url = {https://mpra.ub.uni-muenchen.de/102511/1/MPRA_paper_102511.pdf},
	urldate = {2022-01-19},
	author = {Windmeijer, Frank},
	year = {1995},
	file = {MPRA_paper_102511.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ZRGAVEGT\\MPRA_paper_102511.pdf:application/pdf},
}

@article{lavergne_selection_1998,
	title = {Selection of regressors in econometrics: parametric and nonparametric methods selection of regressors in econometrics},
	volume = {17},
	issn = {0747-4938, 1532-4168},
	shorttitle = {Selection of regressors in econometrics},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07474939808800415},
	doi = {10.1080/07474939808800415},
	abstract = {The present paper addresses the selection-of-regressors issue into a general discrimination framework. We show how this framework is useful in unifying various procedures for selecting regressors and helpful in understanding the different strategies underlying these procedures. We review selection of regressors in linear, nonlinear and nonparametric regression models. In each case we successively consider model selection criteria and hypothesis testing procedures.},
	language = {en},
	number = {3},
	urldate = {2022-02-28},
	journal = {Econometric Reviews},
	author = {Lavergne, Pascal},
	month = jan,
	year = {1998},
	pages = {227--273},
	file = {Lavergne - 1998 - Selection of regressors in econometrics parametri.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\SJSM3CF2\\Lavergne - 1998 - Selection of regressors in econometrics parametri.pdf:application/pdf},
}

@article{hansen_challenges_2005,
	title = {{CHALLENGES} {FOR} {ECONOMETRIC} {MODEL} {SELECTION}},
	volume = {21},
	issn = {0266-4666, 1469-4360},
	url = {http://www.journals.cambridge.org/abstract_S0266466605050048},
	doi = {10.1017/S0266466605050048},
	language = {en},
	number = {01},
	urldate = {2022-02-28},
	journal = {Econometric Theory},
	author = {Hansen, Bruce E.},
	month = feb,
	year = {2005},
	file = {Hansen - 2005 - CHALLENGES FOR ECONOMETRIC MODEL SELECTION.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ZWX8ZWLH\\Hansen - 2005 - CHALLENGES FOR ECONOMETRIC MODEL SELECTION.pdf:application/pdf},
}

@article{berk_valid_2013-1,
	title = {Valid post-selection inference},
	volume = {41},
	issn = {0090-5364},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-41/issue-2/Valid-post-selection-inference/10.1214/12-AOS1077.full},
	doi = {10.1214/12-AOS1077},
	language = {en},
	number = {2},
	urldate = {2022-04-02},
	journal = {The Annals of Statistics},
	author = {Berk, Richard and Brown, Lawrence and Buja, Andreas and Zhang, Kai and Zhao, Linda},
	month = apr,
	year = {2013},
	file = {Berk-Brown-Buja-Zhang-Zhao-AoS2013-PoSI.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\NHKGUCNG\\Berk-Brown-Buja-Zhang-Zhao-AoS2013-PoSI.pdf:application/pdf},
}

@article{guo_confidence_2017,
	title = {Confidence {Intervals} for {Causal} {Effects} with {Invalid} {Instruments} using {Two}-{Stage} {Hard} {Thresholding} with {Voting}},
	url = {http://arxiv.org/abs/1603.05224},
	abstract = {A major challenge in instrumental variables (IV) analysis is to ﬁnd instruments that are valid, or have no direct effect on the outcome and are ignorable. Typically one is unsure whether all of the putative IVs are in fact valid. We propose a general inference procedure in the presence of invalid IVs, called Two-Stage Hard Thresholding (TSHT) with voting. TSHT uses two hard thresholding steps to select strong instruments and generate candidate sets of valid IVs. Voting takes the candidate sets and uses majority and plurality rules to determine the true set of valid IVs. In low dimensions, if the sufﬁcient and necessary identiﬁcation condition under invalid instruments is met, which is more general than the so-called 50\% rule or the majority rule, our proposal (i) correctly selects valid IVs, (ii) consistently estimates the causal effect, (iii) produces valid conﬁdence intervals for the causal effect, and (iv) has oracle-optimal width. In high dimensions, we establish nearly identical results without oracle-optimality. In simulations, our proposal outperforms traditional and recent methods in the invalid IV literature. We also apply our method to re-analyze the causal effect of education on earnings.},
	language = {en},
	urldate = {2022-04-20},
	journal = {arXiv:1603.05224 [math, stat]},
	author = {Guo, Zijian and Kang, Hyunseung and Cai, T. Tony and Small, Dylan S.},
	month = aug,
	year = {2017},
	note = {arXiv: 1603.05224},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
	annote = {Comment: The title is revised to highlight the two important parts of the proposed method, Two-Stage Hard Thresholding and Voting},
	file = {Guo et al. - 2017 - Confidence Intervals for Causal Effects with Inval.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\46FNIKF9\\Guo et al. - 2017 - Confidence Intervals for Causal Effects with Inval.pdf:application/pdf},
}

@article{kolesar_identification_2015,
	title = {Identification and {Inference} {With} {Many} {Invalid} {Instruments}},
	volume = {33},
	issn = {0735-0015, 1537-2707},
	url = {http://www.tandfonline.com/doi/full/10.1080/07350015.2014.978175},
	doi = {10.1080/07350015.2014.978175},
	language = {en},
	number = {4},
	urldate = {2022-04-20},
	journal = {Journal of Business \& Economic Statistics},
	author = {Kolesár, Michal and Chetty, Raj and Friedman, John and Glaeser, Edward and Imbens, Guido W.},
	month = oct,
	year = {2015},
	pages = {474--484},
	file = {Kolesár et al. - 2015 - Identification and Inference With Many Invalid Ins.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\S5BWCACB\\43701558.pdf:application/pdf;w17519.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\WJK8HN24\\w17519.pdf:application/pdf},
}

@article{zucchini_introduction_2000,
	title = {An {Introduction} to {Model} {Selection}},
	volume = {44},
	issn = {00222496},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249699912762},
	doi = {10.1006/jmps.1999.1276},
	language = {en},
	number = {1},
	urldate = {2022-04-25},
	journal = {Journal of Mathematical Psychology},
	author = {Zucchini, Walter},
	month = mar,
	year = {2000},
	pages = {41--61},
	file = {Zucchini - 2000 - An Introduction to Model Selection.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ZTMLB7GT\\Zucchini - 2000 - An Introduction to Model Selection.pdf:application/pdf},
}

@article{guo_confidence_2017-1,
	title = {Confidence {Intervals} for {Causal} {Effects} with {Invalid} {Instruments} using {Two}-{Stage} {Hard} {Thresholding} with {Voting}},
	url = {http://arxiv.org/abs/1603.05224},
	abstract = {A major challenge in instrumental variables (IV) analysis is to ﬁnd instruments that are valid, or have no direct effect on the outcome and are ignorable. Typically one is unsure whether all of the putative IVs are in fact valid. We propose a general inference procedure in the presence of invalid IVs, called Two-Stage Hard Thresholding (TSHT) with voting. TSHT uses two hard thresholding steps to select strong instruments and generate candidate sets of valid IVs. Voting takes the candidate sets and uses majority and plurality rules to determine the true set of valid IVs. In low dimensions, if the sufﬁcient and necessary identiﬁcation condition under invalid instruments is met, which is more general than the so-called 50\% rule or the majority rule, our proposal (i) correctly selects valid IVs, (ii) consistently estimates the causal effect, (iii) produces valid conﬁdence intervals for the causal effect, and (iv) has oracle-optimal width. In high dimensions, we establish nearly identical results without oracle-optimality. In simulations, our proposal outperforms traditional and recent methods in the invalid IV literature. We also apply our method to re-analyze the causal effect of education on earnings.},
	language = {en},
	urldate = {2022-04-25},
	journal = {arXiv:1603.05224 [math, stat]},
	author = {Guo, Zijian and Kang, Hyunseung and Cai, T. Tony and Small, Dylan S.},
	month = aug,
	year = {2017},
	note = {arXiv: 1603.05224},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
	annote = {Comment: The title is revised to highlight the two important parts of the proposed method, Two-Stage Hard Thresholding and Voting},
	file = {Guo et al. - 2017 - Confidence Intervals for Causal Effects with Inval.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\CZPS2ZIR\\Guo et al. - 2017 - Confidence Intervals for Causal Effects with Inval.pdf:application/pdf},
}

@article{kolesar_identification_2015-1,
	title = {Identification and {Inference} {With} {Many} {Invalid} {Instruments}},
	volume = {33},
	issn = {0735-0015, 1537-2707},
	url = {http://www.tandfonline.com/doi/full/10.1080/07350015.2014.978175},
	doi = {10.1080/07350015.2014.978175},
	language = {en},
	number = {4},
	urldate = {2022-04-25},
	journal = {Journal of Business \& Economic Statistics},
	author = {Kolesár, Michal and Chetty, Raj and Friedman, John and Glaeser, Edward and Imbens, Guido W.},
	month = oct,
	year = {2015},
	pages = {474--484},
	file = {Kolesár et al. - 2015 - Identification and Inference With Many Invalid Ins.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\H869C5HP\\Kolesár et al. - 2015 - Identification and Inference With Many Invalid Ins.pdf:application/pdf},
}

@article{masten_salvaging_2021,
	title = {Salvaging {Falsified} {Instrumental} {Variable} {Models}},
	volume = {89},
	issn = {0012-9682},
	url = {https://www.econometricsociety.org/doi/10.3982/ECTA17969},
	doi = {10.3982/ECTA17969},
	abstract = {What should researchers do when their baseline model is falsiﬁed? We recommend reporting the set of parameters that are consistent with minimally nonfalsiﬁed models. We call this the falsiﬁcation adaptive set (FAS). This set generalizes the standard baseline estimand to account for possible falsiﬁcation. Importantly, it does not require the researcher to select or calibrate sensitivity parameters. In the classical linear IV model with multiple instruments, we show that the FAS has a simple closed-form expression that only depends on a few 2SLS coefﬁcients. We apply our results to an empirical study of roads and trade. We show how the FAS complements traditional overidentiﬁcation tests by summarizing the variation in estimates obtained from alternative nonfalsiﬁed models.},
	language = {en},
	number = {3},
	urldate = {2022-04-28},
	journal = {Econometrica},
	author = {Masten, Matthew A. and Poirier, Alexandre},
	year = {2021},
	pages = {1449--1469},
	file = {Masten et Poirier - 2021 - Salvaging Falsified Instrumental Variable Models.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\BJI8HCE9\\Masten et Poirier - 2021 - Salvaging Falsified Instrumental Variable Models.pdf:application/pdf},
}

@article{masten_salvaging_2020,
	title = {Salvaging {Falsified} {Instrumental} {Variable} {Models}},
	url = {http://arxiv.org/abs/1812.11598},
	abstract = {What should researchers do when their baseline model is refuted? We provide four constructive answers. First, researchers can measure the extent of falsiﬁcation. To do this, we consider continuous relaxations of the baseline assumptions of concern. We then deﬁne the falsiﬁcation frontier: The smallest relaxations of the baseline model which are not refuted. This frontier provides a quantitative measure of the extent of falsiﬁcation. Second, researchers can present the identiﬁed set for the parameter of interest under the assumption that the true model lies somewhere on this frontier. We call this the falsiﬁcation adaptive set. This set generalizes the standard baseline estimand to account for possible falsiﬁcation. Importantly, it does not require the researcher to select or calibrate sensitivity parameters. Third, researchers can present the identiﬁed set for a speciﬁc point on this frontier. Finally, as a sensitivity analysis, researchers can present identiﬁed sets for points beyond the frontier. To illustrate these four ways of salvaging falsiﬁed models, we study overidentifying restrictions in two instrumental variable models: a homogeneous eﬀects linear model, and heterogeneous eﬀect models with either binary or continuous outcomes. In the linear model, we consider the classical overidentifying restrictions implied when multiple instruments are observed. We generalize these conditions by considering continuous relaxations of the exclusion restrictions. By suﬃciently weakening the assumptions, a falsiﬁed baseline model becomes non-falsiﬁed. This lets us derive the falsiﬁcation adaptive set, which has a simple closed form expression that depends only on a few 2SLS regression coeﬃcients. We obtain similar results in the heterogeneous eﬀect models, where we derive identiﬁed sets for marginal distributions of potential outcomes, falsiﬁcation frontiers, and falsiﬁcation adaptive sets under continuous relaxations of the instrument exogeneity assumptions. We apply our results to four diﬀerent empirical studies: Duranton, Morrow, and Turner (2014), Alesina, Giuliano, and Nunn (2013), Acemoglu, Johnson, and Robinson (2001), and Nevo (2001). We show how our results, especially the falsiﬁcation adaptive set, can help researchers go beyond the binary pass/fail outcome of a speciﬁcation test and instead summarize the variation in estimates obtained from alternative non-falsiﬁed models.},
	language = {en},
	urldate = {2022-04-28},
	journal = {arXiv:1812.11598 [econ, stat]},
	author = {Masten, Matthew A. and Poirier, Alexandre},
	month = jan,
	year = {2020},
	note = {arXiv: 1812.11598},
	keywords = {Economics - Econometrics, Statistics - Methodology},
	annote = {Comment: 66 pages with 61 page appendix},
	file = {Masten et Poirier - 2020 - Salvaging Falsified Instrumental Variable Models.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\SGEGSZ7Z\\Masten et Poirier - 2020 - Salvaging Falsified Instrumental Variable Models.pdf:application/pdf},
}

@article{chen_one_2021,
	title = {The {One} {Standard} {Error} {Rule} for {Model} {Selection}: {Does} {It} {Work}?},
	volume = {4},
	issn = {2571-905X},
	shorttitle = {The {One} {Standard} {Error} {Rule} for {Model} {Selection}},
	url = {https://www.mdpi.com/2571-905X/4/4/51},
	doi = {10.3390/stats4040051},
	abstract = {Previous research provided a lot of discussion on the selection of regularization parameters when it comes to the application of regularization methods for high-dimensional regression. The popular “One Standard Error Rule” (1se rule) used with cross validation (CV) is to select the most parsimonious model whose prediction error is not much worse than the minimum CV error. This paper examines the validity of the 1se rule from a theoretical angle and also studies its estimation accuracy and performances in applications of regression estimation and variable selection, particularly for Lasso in a regression framework. Our theoretical result shows that when a regression procedure produces the regression estimator converging relatively fast to the true regression function, the standard error estimation formula in the 1se rule is justiﬁed asymptotically. The numerical results show the following: 1. the 1se rule in general does not necessarily provide a good estimation for the intended standard deviation of the cross validation error. The estimation bias can be 50–100\% upwards or downwards in various situations; 2. the results tend to support that 1se rule usually outperforms the regular CV in sparse variable selection and alleviates the over-selection tendency of Lasso; 3. in regression estimation or prediction, the 1se rule often performs worse. In addition, comparisons are made over two real data sets: Boston Housing Prices (large sample size n, small/moderate number of variables p) and Bardet–Biedl data (large p, small n). Data guided simulations are done to provide insight on the relative performances of the 1se rule and the regular CV.},
	language = {en},
	number = {4},
	urldate = {2022-04-28},
	journal = {Stats},
	author = {Chen, Yuchen and Yang, Yuhong},
	month = nov,
	year = {2021},
	pages = {868--892},
	file = {Chen et Yang - 2021 - The One Standard Error Rule for Model Selection D.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\PM89TCRB\\Chen et Yang - 2021 - The One Standard Error Rule for Model Selection D.pdf:application/pdf},
}

@article{kang_simple_2016,
	title = {A simple and robust confidence interval for causal effects with possibly invalid instruments},
	url = {http://arxiv.org/abs/1504.03718},
	abstract = {Instrumental variables have been widely used to estimate the causal effect of a treatment on an outcome. Existing conﬁdence intervals for causal effects based on instrumental variables assume that all of the putative instrumental variables are valid; a valid instrumental variable is a variable that affects the outcome only by affecting the treatment and is not related to unmeasured confounders. However, in practice, some of the putative instrumental variables are likely to be invalid. This paper presents a simple and general approach to construct a conﬁdence interval that is robust to possibly invalid instruments. The robust conﬁdence interval has theoretical guarantees on having the correct coverage and can also be used to assess the sensitivity of inference when instrumental variables assumptions are violated. The paper also shows that the robust conﬁdence interval outperforms traditional conﬁdence intervals popular in instrumental variables literature when invalid instruments are present. The new approach is applied to a developmental economics study of the causal effect of income on food expenditures.},
	language = {en},
	urldate = {2022-04-28},
	journal = {arXiv:1504.03718 [stat]},
	author = {Kang, Hyunseung and Cai, T. Tony and Small, Dylan S.},
	month = jul,
	year = {2016},
	note = {arXiv: 1504.03718},
	keywords = {Statistics - Methodology},
	file = {Kang et al. - 2016 - A simple and robust confidence interval for causal.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\9FNDWXDL\\Kang et al. - 2016 - A simple and robust confidence interval for causal.pdf:application/pdf},
}

@article{masten_salvaging_2020-1,
	title = {Salvaging {Falsified} {Instrumental} {Variable} {Models}},
	url = {http://arxiv.org/abs/1812.11598},
	abstract = {What should researchers do when their baseline model is refuted? We provide four constructive answers. First, researchers can measure the extent of falsiﬁcation. To do this, we consider continuous relaxations of the baseline assumptions of concern. We then deﬁne the falsiﬁcation frontier: The smallest relaxations of the baseline model which are not refuted. This frontier provides a quantitative measure of the extent of falsiﬁcation. Second, researchers can present the identiﬁed set for the parameter of interest under the assumption that the true model lies somewhere on this frontier. We call this the falsiﬁcation adaptive set. This set generalizes the standard baseline estimand to account for possible falsiﬁcation. Importantly, it does not require the researcher to select or calibrate sensitivity parameters. Third, researchers can present the identiﬁed set for a speciﬁc point on this frontier. Finally, as a sensitivity analysis, researchers can present identiﬁed sets for points beyond the frontier. To illustrate these four ways of salvaging falsiﬁed models, we study overidentifying restrictions in two instrumental variable models: a homogeneous eﬀects linear model, and heterogeneous eﬀect models with either binary or continuous outcomes. In the linear model, we consider the classical overidentifying restrictions implied when multiple instruments are observed. We generalize these conditions by considering continuous relaxations of the exclusion restrictions. By suﬃciently weakening the assumptions, a falsiﬁed baseline model becomes non-falsiﬁed. This lets us derive the falsiﬁcation adaptive set, which has a simple closed form expression that depends only on a few 2SLS regression coeﬃcients. We obtain similar results in the heterogeneous eﬀect models, where we derive identiﬁed sets for marginal distributions of potential outcomes, falsiﬁcation frontiers, and falsiﬁcation adaptive sets under continuous relaxations of the instrument exogeneity assumptions. We apply our results to four diﬀerent empirical studies: Duranton, Morrow, and Turner (2014), Alesina, Giuliano, and Nunn (2013), Acemoglu, Johnson, and Robinson (2001), and Nevo (2001). We show how our results, especially the falsiﬁcation adaptive set, can help researchers go beyond the binary pass/fail outcome of a speciﬁcation test and instead summarize the variation in estimates obtained from alternative non-falsiﬁed models.},
	language = {en},
	urldate = {2022-04-28},
	journal = {arXiv:1812.11598 [econ, stat]},
	author = {Masten, Matthew A. and Poirier, Alexandre},
	month = jan,
	year = {2020},
	note = {arXiv: 1812.11598},
	keywords = {Economics - Econometrics, Statistics - Methodology},
	annote = {Comment: 66 pages with 61 page appendix},
	file = {Masten et Poirier - 2020 - Salvaging Falsified Instrumental Variable Models.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\WPEK8FCD\\Masten et Poirier - 2020 - Salvaging Falsified Instrumental Variable Models.pdf:application/pdf},
}

@article{dobbie_online_nodate,
	title = {Online {Appendix} {The} {Eﬀects} of {Pre}-{Trial} {Detention} on {Conviction}, {Future} {Crime}, and {Employment}: {Evidence} from {Randomly} {Assigned} {Judges}},
	language = {en},
	author = {Dobbie, Will and Goldin, Jacob and Yang, Crystal S},
	pages = {39},
	file = {Dobbie et al. - Online Appendix The Eﬀects of Pre-Trial Detention .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\WZG99SFG\\Dobbie et al. - Online Appendix The Eﬀects of Pre-Trial Detention .pdf:application/pdf},
}

@article{dobbie_online_nodate-1,
	title = {Online {Appendix} {The} {Eﬀects} of {Pre}-{Trial} {Detention} on {Conviction}, {Future} {Crime}, and {Employment}: {Evidence} from {Randomly} {Assigned} {Judges}},
	language = {en},
	author = {Dobbie, Will and Goldin, Jacob and Yang, Crystal S},
	pages = {39},
	file = {Dobbie et al. - Online Appendix The Eﬀects of Pre-Trial Detention .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\IXGZXRUD\\Dobbie et al. - Online Appendix The Eﬀects of Pre-Trial Detention .pdf:application/pdf},
}

@article{andrews_unbiased_nodate,
	title = {Unbiased {Instrumental} {Variables} {Estimation} {Under} {Known} {First}-{Stage} {Sign}},
	abstract = {We derive mean-unbiased estimators for the structural parameter in instrumental variables models with a single endogenous regressor where the sign of one or more ﬁrst stage coeﬃcients is known. In the case with a single instrument, there is a unique non-randomized unbiased estimator based on the reduced-form and ﬁrst-stage regression estimates. For cases with multiple instruments we propose a class of unbiased estimators and show that an estimator within this class is eﬃcient when the instruments are strong. We show numerically that unbiasedness does not come at a cost of increased dispersion in models with a single instrument: in this case the unbiased estimator is less dispersed than the 2SLS estimator. Our ﬁnite-sample results apply to normal models with known variance for the reduced-form errors, and imply analogous results under weak instrument asymptotics with an unknown error distribution.},
	language = {en},
	author = {Andrews, Isaiah and Armstrong, Timothy B},
	pages = {36},
	file = {Andrews et Armstrong - Unbiased Instrumental Variables Estimation Under K.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\YLEIAS6H\\Andrews et Armstrong - Unbiased Instrumental Variables Estimation Under K.pdf:application/pdf},
}

@article{andrews_unbiased_nodate-1,
	title = {Unbiased {Instrumental} {Variables} {Estimation} {Under} {Known} {First}-{Stage} {Sign}},
	abstract = {We derive mean-unbiased estimators for the structural parameter in instrumental variables models with a single endogenous regressor where the sign of one or more ﬁrst stage coeﬃcients is known. In the case with a single instrument, there is a unique non-randomized unbiased estimator based on the reduced-form and ﬁrst-stage regression estimates. For cases with multiple instruments we propose a class of unbiased estimators and show that an estimator within this class is eﬃcient when the instruments are strong. We show numerically that unbiasedness does not come at a cost of increased dispersion in models with a single instrument: in this case the unbiased estimator is less dispersed than the 2SLS estimator. Our ﬁnite-sample results apply to normal models with known variance for the reduced-form errors, and imply analogous results under weak instrument asymptotics with an unknown error distribution.},
	language = {en},
	author = {Andrews, Isaiah and Armstrong, Timothy B},
	pages = {36},
	file = {Andrews et Armstrong - Unbiased Instrumental Variables Estimation Under K.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\MNNK6QWU\\Andrews et Armstrong - Unbiased Instrumental Variables Estimation Under K.pdf:application/pdf},
}

@article{armstrong_finite-sample_nodate,
	title = {Finite-{Sample} {Optimal} {Estimation} and {Inference} on {Average} {Treatment} {Effects} {Under} {Unconfoundedness}},
	language = {en},
	author = {Armstrong, Tim and Kolesár, Michal},
	pages = {45},
	file = {Armstrong et Kolesár - Finite-Sample Optimal Estimation and Inference on .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\7QJYPW8Z\\Armstrong et Kolesár - Finite-Sample Optimal Estimation and Inference on .pdf:application/pdf},
}

@article{stevenson_distortion_2018,
	doi = {10.1093/jleo/ewy019},
  url = {https://doi.org/10.1093/jleo/ewy019},
  year = {2018},
  pages = {511--542},
  volume = {34},
  number = {4},
  month = sep,
  publisher = {Oxford University Press ({OUP})},
  author = {Megan T Stevenson},
  title = {Distortion of Justice: How the Inability to Pay Bail Affects Case Outcomes},
  journal = {The Journal of Law,  Economics,  and Organization}
}

@article{windmeijer_weak_nodate,
	title = {Weak {Instruments}, {First}-{Stage} {Heteroskedasticity} and the {Robust} {F}-test},
	abstract = {This paper is concerned with the …ndings related to the robust …rst-stage F-statistic in the Monte Carlo analysis of Andrews (2018), who found in a heteroskedastic design that even for very large values of the robust F-statistic, the standard 2SLS con…dence intervals had large coverage distortions. This …nding appears to discredit the robust F-statistic as a test for underidenti…cation. However, it is shown here that large values of the robust F-statistic do imply that there is …rst-stage information, but this may not be utilised well by the 2SLS estimator, or the standard GMM estimator. An estimator that corrects for this is a robust GMM estimator, with the robust weight matrix not based on the structural residuals, but on the …rst-stage residuals. For the grouped data setting of Andrews (2018), this estimator gives the weights to the group speci…c estimators according to the group speci…c concentration parameters in the same way as 2SLS does under homoskedasticity, which is formally shown using weak instrument asymptotics. This estimator is much better behaved than the 2SLS estimator in this design, behaving well in terms of relative bias and Wald test size distortion at more ‘standard’ values of the robust F-statistic. We further derive the conditions under which the Stock and Yogo (2005) weak instruments critical values apply to the robust F-statistic in relation to the behaviour of this GMM estimator.},
	language = {en},
	author = {Windmeijer, Frank},
	pages = {22},
	file = {Windmeijer - Weak Instruments, First-Stage Heteroskedasticity a.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\M4KEWE7T\\Windmeijer - Weak Instruments, First-Stage Heteroskedasticity a.pdf:application/pdf},
}

@article{kling_incarceration_2006,
	title = {Incarceration {Length}, {Employment}, and {Earnings}},
	volume = {96},
	language = {en},
	number = {3},
	journal = {American Economic Review},
	author = {Kling, Jeffrey R},
	year = {2006},
	pages = {863--876},
	file = {Kling - 2006 - Incarceration Length, Employment, and Earnings.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\Z8VAH6BV\\Kling - 2006 - Incarceration Length, Employment, and Earnings.pdf:application/pdf},
}

@article{mellon_rain_2021,
	title = {Rain, {Rain}, {Go} {Away}: 176 potential exclusion-restriction violations for studies using weather as an instrumental variable},
	abstract = {Instrumental variable (IV) analysis assumes that the instrument only aﬀects the dependent variable via its relationship with the independent variable. Other possible causal routes from the IV to the dependent variable are exclusion-restriction violations and make the instrument invalid. Weather has been widely used as an instrumental variable in social science to predict many diﬀerent variables. The use of weather to instrument diﬀerent independent variables represents strong prima facie evidence of exclusion violations for all studies using weather as an IV. A review of 217 social science studies reveals 176 variables which have been linked to weather, all of which represent potential exclusion violations. I conclude with practical steps to systematically review existing literature to identify possible exclusion violations when using IV designs. I demonstrate how sensitivity analysis can quantify the vulnerability of a particular IV estimate to exclusion restriction violations in the literature.},
	language = {en},
	author = {Mellon, Jonathan},
	year = {2021},
	pages = {111},
	file = {Mellon - Rain, Rain, Go Away 176 potential exclusion-restr.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\V6B79728\\Mellon - Rain, Rain, Go Away 176 potential exclusion-restr.pdf:application/pdf},
}

@article{angrist_interpretation_2000,
	title = {The {Interpretation} of {Instrumental} {Variables} {Estimators} in {Simultaneous} {Equations} {Models} with an {Application} to the {Demand} for {Fish}},
	language = {en},
	journal = {Review of Economic Studies},
	author = {Angrist, Joshua D and Graddy, Kathryn and Imbens, Guido},
	year = {2000},
	pages = {29},
	file = {Angrist et al. - 2000 - The Interpretation of Instrumental Variables Estim.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\9QD5WAB2\\Angrist et al. - 2000 - The Interpretation of Instrumental Variables Estim.pdf:application/pdf},
}

@article{angrist_instrumental_2001,
	title = {Instrumental {Variables} and the {Search} for {Identification}: {From} {Supply} and {Demand} to {Natural} {Experiments}},
	volume = {15},
	language = {en},
	number = {4},
	journal = {Journal of Economic Perspectives},
	author = {Angrist, Joshua D and Krueger, Alan B},
	year = {2001},
	pages = {79},
	file = {Angrist et Krueger - Instrumental Variables and the Search for Identifi.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\GW6U7XY9\\Angrist et Krueger - Instrumental Variables and the Search for Identifi.pdf:application/pdf},
}

@book{bartik_who_1991,
	edition = {W.E. Upjohn Institute},
	title = {Who {Benefits} from {State} and {Local} {Economic} {Development} {Policies}?},
	author = {Bartik, Timothy},
	year = {1991},
}

@article{artes_rain_2014,
	title = {The rain in {Spain}: {Turnout} and partisan voting in {Spanish} elections},
	volume = {34},
	issn = {01762680},
	shorttitle = {The rain in {Spain}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0176268014000068},
	doi = {10.1016/j.ejpoleco.2014.01.005},
	abstract = {This paper uses detailed data on election day rainfall from more than 3000 weather stations as an instrument to estimate the causal effect of turnout on electoral results in Spanish General Elections. The first stage results show that rainfall on election day decreases turnout. Second stage results show that conservatives are greatly hurt by higher turnout. Surprisingly, I find that the main leftwing party is not the beneficiary of higher turnout, but rather other smaller parties. In both stages, I control for local economic conditions and find that higher unemployment increases turnout, and that increases in unemployment benefit the conservative party at the expense of leftwing parties. In combination, the results point to turnout having two components, a more volatile one, which is affected by weather, and a more structural one, which depends on economic conditions such as unemployment.},
	language = {en},
	urldate = {2022-05-23},
	journal = {European Journal of Political Economy},
	author = {Artés, Joaquín},
	month = jun,
	year = {2014},
	pages = {126--141},
	file = {Artés - 2014 - The rain in Spain Turnout and partisan voting in .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\LGI7PAHR\\Artés - 2014 - The rain in Spain Turnout and partisan voting in .pdf:application/pdf},
}

@article{skouras_electoral_2014,
	title = {Electoral misgovernance cycles: evidence from wildfires and tax evasion in {Greece}},
	volume = {159},
	issn = {0048-5829, 1573-7101},
	shorttitle = {Electoral misgovernance cycles},
	url = {http://link.springer.com/10.1007/s11127-013-0071-0},
	doi = {10.1007/s11127-013-0071-0},
	abstract = {We present detailed empirical evidence from Greece that around elections, misgovernance results in signiﬁcant increases in wildﬁres and tax evasion and has important economic implications: these effects have led to the destruction of property or loss of government revenue estimated at 8 \% of GDP. There are two plausible reasons why misgovernance might intensify around elections: (i) attention and effort of elected ofﬁcials is directed to campaigning instead of governing; and (ii) the misgovernance may beneﬁt special interests and serve as a pork barrel transfer that is hard to monitor or control. Empirically, we ﬁnd that redistributive politics are likely a dominant cause of electoral misgovernance. In the case of wildﬁres we also ﬁnd evidence that political competition tends to increase electoral misgovernance; furthermore, electoral misgovernance helps incumbents get reelected. While misgovernance may manifest differently among countries, our analysis suggests that electoral cycles everywhere may be much more multifaceted and harmful than previous literature suggests.},
	language = {en},
	number = {3-4},
	urldate = {2022-05-23},
	journal = {Public Choice},
	author = {Skouras, Spyros and Christodoulakis, Nicos},
	month = jun,
	year = {2014},
	pages = {533--559},
	file = {Skouras et Christodoulakis - 2014 - Electoral misgovernance cycles evidence from wild.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\Y5QNXIYQ\\Skouras et Christodoulakis - 2014 - Electoral misgovernance cycles evidence from wild.pdf:application/pdf},
}

@article{didelez_mendelian_2007,
	title = {Mendelian randomization as an instrumental variable approach to causal inference},
	volume = {16},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280206077743},
	doi = {10.1177/0962280206077743},
	abstract = {In epidemiological research, the causal effect of a modifiable phenotype or exposure on a disease is often of public health interest. Randomized controlled trials to investigate this effect are not always possible and inferences based on observational data can be confounded. However, if we know of a gene closely linked to the phenotype without direct effect on the disease, it can often be reasonably assumed that the gene is not itself associated with any confounding factors — a phenomenon called Mendelian randomization. These properties define an instrumental variable and allow estimation of the causal effect, despite the confounding, under certain model restrictions. In this paper, we present a formal framework for causal inference based on Mendelian randomization and suggest using directed acyclic graphs to check model assumptions by visual inspection. This framework allows us to address limitations of the Mendelian randomization technique that have often been overlooked in the medical literature.},
	language = {en},
	number = {4},
	urldate = {2022-05-23},
	journal = {Statistical Methods in Medical Research},
	author = {Didelez, Vanessa and Sheehan, Nuala},
	month = aug,
	year = {2007},
	pages = {309--330},
	file = {Didelez et Sheehan - 2007 - Mendelian randomization as an instrumental variabl.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\YSA75EQC\\Didelez et Sheehan - 2007 - Mendelian randomization as an instrumental variabl.pdf:application/pdf},
}

@article{hall_large_2003,
	title = {The large sample behaviour of the generalized method of moments estimator in misspecified models},
	volume = {114},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407603000897},
	doi = {10.1016/S0304-4076(03)00089-7},
	abstract = {This paper presents the limiting distribution theory for the GMM estimator when the estimation is based on a population moment condition which is subject to non-local (or ÿxed) misspeciÿcation. It is shown that if the parameter vector is overidentiÿed then the weighting matrix plays a far more fundamental role than it does in the corresponding analysis for correctly speciÿed models. Speciÿcally, the rate of convergence of the estimator depends on the rate of convergence of the weighting matrix to its probability limit. The analysis is presented for four particular choices of weighting matrix which are commonly used in practice. In each case the limiting distribution theory is di erent, and also di erent from the limiting distribution in a correctly speciÿed model. Statistics are proposed which allow the researcher to test hypotheses about the parameters in misspeciÿed models.},
	language = {en},
	number = {2},
	urldate = {2022-05-23},
	journal = {Journal of Econometrics},
	author = {Hall, Alastair R. and Inoue, Atsushi},
	month = jun,
	year = {2003},
	pages = {361--394},
	file = {Hall et Inoue - 2003 - The large sample behaviour of the generalized meth.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\F5D7GFBT\\Hall et Inoue - 2003 - The large sample behaviour of the generalized meth.pdf:application/pdf},
}

@article{andrews_measuring_2017,
	title = {Measuring the {Sensitivity} of {Parameter} {Estimates} to {Estimation} {Moments}},
	volume = {132},
	abstract = {We propose a local measure of the relationship between parameter estimates and the moments of the data they depend on. Our measure can be computed at negligible cost even for complex structural models. We argue that reporting this measure can increase the transparency of structural estimates, making it easier for readers to predict the way violations of identifying assumptions would affect the results. When the key assumptions are orthogonality between error terms and excluded instruments, we show that our measure provides a natural extension of the omitted variables bias formula for nonlinear models. We illustrate with applications to published articles in several ﬁelds of economics.},
	language = {en},
	number = {4},
	journal = {Quaterly Journal of Economics},
	author = {Andrews, Isaiah and Gentzkow, Matthew and Shapiro, Jesse M},
	year = {2017},
	pages = {1553--1992},
	file = {Andrews et al. - Measuring the Sensitivity of Parameter Estimates t.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\KTD8QGBM\\Andrews et al. - Measuring the Sensitivity of Parameter Estimates t.pdf:application/pdf},
}

@article{abadie_instrumental_nodate,
	title = {Instrumental {Variable} {Estimation} with {First}-{Stage} {Heterogeneity}},
	abstract = {We propose a simple data-driven procedure that exploits heterogeneity in the ﬁrst stage correlation between an instrument and an endogenous variable to improve the asymptotic mean squared error (MSE) of instrumental variable estimators. We show that the resulting gains in asymptotic MSE can be quite large in settings where there is substantial heterogeneity in the ﬁrst-stage parameters. We also show that a naive procedure used in some applied work, which consists of selecting the composition of the sample based on the value of the ﬁrst-stage tstatistic, may cause substantial over-rejection of a null hypothesis on a second stage parameter. We apply the methods to study 1) the return to schooling using the minimum school leaving age as the exogenous instrument and 2) the eﬀect of local economic conditions on voter turnout using energy supply shocks as the source of identiﬁcation.},
	language = {en},
	author = {Abadie, Alberto and Gu, Jiaying},
	pages = {74},
	file = {Abadie et Gu - Instrumental Variable Estimation with First-Stage .pdf:C\:\\Users\\Hippo\\Zotero\\storage\\EFKR6XMY\\Abadie et Gu - Instrumental Variable Estimation with First-Stage .pdf:application/pdf},
}

@article{didelez_mendelian_2007-1,
	title = {Mendelian randomization as an instrumental variable approach to causal inference},
	volume = {16},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280206077743},
	doi = {10.1177/0962280206077743},
	abstract = {In epidemiological research, the causal effect of a modifiable phenotype or exposure on a disease is often of public health interest. Randomized controlled trials to investigate this effect are not always possible and inferences based on observational data can be confounded. However, if we know of a gene closely linked to the phenotype without direct effect on the disease, it can often be reasonably assumed that the gene is not itself associated with any confounding factors — a phenomenon called Mendelian randomization. These properties define an instrumental variable and allow estimation of the causal effect, despite the confounding, under certain model restrictions. In this paper, we present a formal framework for causal inference based on Mendelian randomization and suggest using directed acyclic graphs to check model assumptions by visual inspection. This framework allows us to address limitations of the Mendelian randomization technique that have often been overlooked in the medical literature.},
	language = {en},
	number = {4},
	urldate = {2022-05-28},
	journal = {Statistical Methods in Medical Research},
	author = {Didelez, Vanessa and Sheehan, Nuala},
	month = aug,
	year = {2007},
	pages = {309--330},
	file = {Didelez et Sheehan - 2007 - Mendelian randomization as an instrumental variabl.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\A3FLNSFU\\Didelez et Sheehan - 2007 - Mendelian randomization as an instrumental variabl.pdf:application/pdf},
}

@article{sharpe_re-evaluating_2019,
	title = {Re-evaluating the impact of immigration on the {U}.{S}. rental housing market},
	volume = {111},
	issn = {00941190},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0094119019300233},
	doi = {10.1016/j.jue.2019.04.001},
	language = {en},
	urldate = {2022-05-28},
	journal = {Journal of Urban Economics},
	author = {Sharpe, Jamie},
	month = may,
	year = {2019},
	pages = {14--34},
	file = {Sharpe - 2019 - Re-evaluating the impact of immigration on the U.S.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\EW3LK7LX\\Sharpe - 2019 - Re-evaluating the impact of immigration on the U.S.pdf:application/pdf},
}

@misc{singh_automatic_2021,
	title = {Automatic {Kappa} {Weighting} for {Instrumental} {Variable} {Models} of {Complier} {Treatment} {Effects}},
	url = {http://arxiv.org/abs/1909.05244},
	abstract = {We propose debiased machine learning estimators for complier parameters, such as local average treatment eﬀect, with high dimensional covariates. To do so, we characterize the doubly robust moment function for the entire class of complier parameters as the combination of Wald and κ weight formulations. We directly estimate the κ weights, rather than their components, in order to eliminate the numerically unstable step of inverting propensity scores of high dimensional covariates. We prove our estimator is balanced, consistent, asymptotically normal, and semiparametrically eﬃcient, and use it to estimate the eﬀect of 401(k) participation on the distribution of net ﬁnancial assets.},
	language = {en},
	urldate = {2022-06-03},
	publisher = {arXiv},
	author = {Singh, Rahul and Sun, Liyang},
	month = nov,
	year = {2021},
	keywords = {Mathematics - Statistics Theory, Economics - Econometrics, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 68 pages, 5 figures, 2 tables},
	file = {Singh et Sun - 2021 - Automatic Kappa Weighting for Instrumental Variabl.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\G9DBA2BL\\Singh et Sun - 2021 - Automatic Kappa Weighting for Instrumental Variabl.pdf:application/pdf},
}

@techreport{chernozhukov_automatic_2021,
	title = {Automatic {Debiased} {Machine} {Learning} of {Causal} and {Structural} {Effects}},
	url = {http://arxiv.org/abs/1809.05224},
	abstract = {Many causal and structural effects depend on regressions. Examples include policy effects, average derivatives, regression decompositions, average treatment effects, causal mediation, and parameters of economic structural models. The regressions may be high dimensional, making machine learning useful. Plugging machine learners into identifying equations can lead to poor inference due to bias from regularization and/or model selection. This paper gives automatic debiasing for linear and nonlinear functions of regressions. The debiasing is automatic in using Lasso and the function of interest without the full form of the bias correction. The debiasing can be applied to any regression learner, including neural nets, random forests, Lasso, boosting, and other high dimensional methods. In addition to providing the bias correction we give standard errors that are robust to misspecification, convergence rates for the bias correction, and primitive conditions for asymptotic inference for estimators of a variety of estimators of structural and causal effects. The automatic debiased machine learning is used to estimate the average treatment effect on the treated for the NSW job training data and to estimate demand elasticities from Nielsen scanner data while allowing preferences to be correlated with prices and income.},
	number = {arXiv:1809.05224},
	urldate = {2022-06-03},
	institution = {arXiv},
	author = {Chernozhukov, Victor and Newey, Whitney K. and Singh, Rahul},
	month = apr,
	year = {2021},
	note = {arXiv:1809.05224 [econ, math, stat]
type: article},
	keywords = {Mathematics - Statistics Theory, Economics - Econometrics},
	file = {arXiv Fulltext PDF:C\:\\Users\\Hippo\\Zotero\\storage\\ZYGJZS6Z\\Chernozhukov et al. - 2021 - Automatic Debiased Machine Learning of Causal and .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Hippo\\Zotero\\storage\\8HFXD6F2\\1809.html:text/html},
}

@article{armstrong_bias-aware_nodate,
	title = {Bias-{Aware} {Inference} in {Regularized} {Regression} {Models}},
	abstract = {We consider inference on a regression coeﬃcient under a constraint on the magnitude of the control coeﬃcients. We show that a class of estimators based on an auxiliary regularized regression of the regressor of interest on control variables exactly solves a tradeoﬀ between worst-case bias and variance. We derive “bias-aware” conﬁdence intervals (CIs) based on these estimators, which take into account possible bias when forming the critical value. We show that these estimators and CIs are near-optimal in ﬁnite samples for mean squared error and CI length. Our ﬁnite-sample results are based on an idealized setting with normal regression errors with known homoskedastic variance, and we provide conditions for asymptotic validity with unknown and possibly heteroskedastic error distribution. Focusing on the case where the constraint on the magnitude of control coeﬃcients is based on an p norm (p ≥ 1), we derive rates of convergence for optimal estimators and CIs under high-dimensional asymptotics that allow the number of regressors to increase more quickly than the number of observations.},
	language = {en},
	author = {Armstrong, Timothy B and Kolesár, Michal and Kwon, Soonwoo},
	pages = {38},
	file = {Armstrong et al. - Bias-Aware Inference in Regularized Regression Mod.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\GL78RFRP\\Armstrong et al. - Bias-Aware Inference in Regularized Regression Mod.pdf:application/pdf},
}

@article{barron_risk_1999,
	title = {Risk bounds for model selection via penalization},
	volume = {113},
	issn = {0178-8051, 1432-2064},
	url = {https://link.springer.com/10.1007/s004400050210},
	doi = {10.1007/s004400050210},
	abstract = {Performance bounds for criteria for model selection are developed using recent theory for sieves. The model selection criteria are based on an empirical loss or contrast function with an added penalty term motivated by empirical process theory and roughly proportional to the number of parameters needed to describe the model divided by the number of observations. Most of our examples involve density or regression estimation settings and we focus on the problem of estimating the unknown density or regression function. We show that the quadratic risk of the minimum penalized empirical contrast estimator is bounded by an index of the accuracy of the sieve. This accuracy index quantiﬁes the trade-off among the candidate models between the approximation error and parameter dimension relative to sample size.},
	language = {en},
	number = {3},
	urldate = {2022-06-03},
	journal = {Probability Theory and Related Fields},
	author = {Barron, Andrew and Birgé, Lucien and Massart, Pascal},
	month = feb,
	year = {1999},
	pages = {301--413},
	file = {Barron et al. - 1999 - Risk bounds for model selection via penalization.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\QH4EXFIX\\Barron et al. - 1999 - Risk bounds for model selection via penalization.pdf:application/pdf},
}

@article{graddy_markets_2006,
	title = {Markets: {The} {Fulton} {Fish} {Market}},
	volume = {20},
	issn = {0895-3309},
	shorttitle = {Markets},
	url = {https://pubs.aeaweb.org/doi/10.1257/jep.20.2.207},
	doi = {10.1257/jep.20.2.207},
	abstract = {The Fulton Fish Market was a colorful part of the New York City landscape that operated on Fulton Street in Manhattan for over 150 years. In 2005 the market moved from the South Street Seaport in lower Manhattan to Hunts Point in the South Bronx. The Fulton Fish Market—now called The New Fulton Fish Market—is one of the world's largest fish markets, second in size only to Tsukiji, the famous fish market in Tokyo. To economists, it may seem that a large centralized market with well-informed buyers and sellers should also be a very competitive market. But fish is a highly differentiated product. Buyers often wish to examine fish themselves, or have their agents do so. The centralized market performs an important function in matching fish to buyers. The high level of product differentiation and the institutional structure in the Fulton fish market can lead to patterns of behavior that suggest imperfect competition and a segmented market. At times in the past, the repeated nature of price setting and extensive knowledge of the sellers may have created the basis for tacit collusion and allowed the dealers to gather economic rents by exploiting the different elasticities and buying patterns. Additional economic rents resulted from subsidies. Before reforms in 1995, lax regulation of the market provided fertile ground for organized crime.},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {Journal of Economic Perspectives},
	author = {Graddy, Kathryn},
	month = may,
	year = {2006},
	pages = {207--220},
	file = {Graddy - 2006 - Markets The Fulton Fish Market.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\5I84AHAE\\Graddy - 2006 - Markets The Fulton Fish Market.pdf:application/pdf},
}

@article{masten_random_nodate,
	title = {Random {Coeﬃcients} on {Endogenous} {Variables} in {Simultaneous} {Equations} {Models}},
	abstract = {This paper considers a classical linear simultaneous equations model with random coeﬃcients on the endogenous variables. Simultaneous equations models are used to study social interactions, strategic interactions between ﬁrms, and market equilibrium. Random coeﬃcient models allow for heterogeneous marginal eﬀects. I show that random coeﬃcient seemingly unrelated regression models with common regressors are not point identiﬁed, which implies random coeﬃcient simultaneous equations models are not point identiﬁed. Important features of these models, however, can be identiﬁed. For twoequation systems, I give two sets of suﬃcient conditions for point identiﬁcation of the coeﬃcients’ marginal distributions conditional on exogenous covariates. The ﬁrst allows for small support continuous instruments under tail restrictions on the distributions of unobservables which are necessary for point identiﬁcation. The second requires full support instruments, but allows for nearly arbitrary distributions of unobservables. I discuss how to generalize these results to many equation systems, where I focus on linear-in-means models with heterogeneous endogenous social interaction eﬀects. I give suﬃcient conditions for point identiﬁcation of the distributions of these endogenous social eﬀects. I propose a consistent nonparametric kernel estimator for these distributions based on the identiﬁcation arguments. I apply my results to the Add Health data to analyze peer eﬀects in education.},
	language = {en},
	journal = {REVIEW OF ECONOMIC STUDIES},
	author = {Masten, Matthew A},
	pages = {61},
	file = {Masten - Random Coeﬃcients on Endogenous Variables in Simul.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\H47KH4Y8\\Masten - Random Coeﬃcients on Endogenous Variables in Simul.pdf:application/pdf},
}

@article{masten_salvaging_2021-1,
	title = {Salvaging {Falsified} {Instrumental} {Variable} {Models}},
	volume = {89},
	issn = {0012-9682},
	url = {https://www.econometricsociety.org/doi/10.3982/ECTA17969},
	doi = {10.3982/ECTA17969},
	abstract = {What should researchers do when their baseline model is falsiﬁed? We recommend reporting the set of parameters that are consistent with minimally nonfalsiﬁed models. We call this the falsiﬁcation adaptive set (FAS). This set generalizes the standard baseline estimand to account for possible falsiﬁcation. Importantly, it does not require the researcher to select or calibrate sensitivity parameters. In the classical linear IV model with multiple instruments, we show that the FAS has a simple closed-form expression that only depends on a few 2SLS coefﬁcients. We apply our results to an empirical study of roads and trade. We show how the FAS complements traditional overidentiﬁcation tests by summarizing the variation in estimates obtained from alternative nonfalsiﬁed models.},
	language = {en},
	number = {3},
	urldate = {2022-07-06},
	journal = {Econometrica},
	author = {Masten, Matthew A. and Poirier, Alexandre},
	year = {2021},
	pages = {1449--1469},
	file = {Masten et Poirier - 2021 - Salvaging Falsified Instrumental Variable Models.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\GNXD2DZV\\Masten et Poirier - 2021 - Salvaging Falsified Instrumental Variable Models.pdf:application/pdf},
}

@article{masten_identification_2018,
	title = {Identification of {Treatment} {Effects} {Under} {Conditional} {Partial} {Independence}},
	volume = {86},
	issn = {0012-9682},
	url = {https://www.econometricsociety.org/doi/10.3982/ECTA14481},
	doi = {10.3982/ECTA14481},
	abstract = {Conditional independence of treatment assignment from potential outcomes is a commonly used but nonrefutable assumption. We derive identiﬁed sets for various treatment effect parameters under nonparametric deviations from this conditional independence assumption. These deviations are deﬁned via a conditional treatment assignment probability, which makes it straightforward to interpret. Our results can be used to assess the robustness of empirical conclusions obtained under the baseline conditional independence assumption.},
	language = {en},
	number = {1},
	urldate = {2022-07-06},
	journal = {Econometrica},
	author = {Masten, Matthew A. and Poirier, Alexandre},
	year = {2018},
	pages = {317--351},
	file = {Masten et Poirier - 2018 - Identification of Treatment Effects Under Conditio.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\ZGIZRW8Z\\Masten et Poirier - 2018 - Identification of Treatment Effects Under Conditio.pdf:application/pdf},
}

@article{clarke_instrumental_2012-1,
	title = {Instrumental {Variable} {Estimators} for {Binary} {Outcomes}},
	volume = {107},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2012.734171},
	doi = {10.1080/01621459.2012.734171},
	abstract = {Instrumental variables (IVs) can be used to construct estimators of exposure effects on the outcomes of studies affected by non-ignorable selection of the exposure. Estimators which fail to adjust for the effects of non-ignorable selection will be biased and inconsistent. Such situations commonly arise in observational studies, but even randomised controlled trials can be affected by non-ignorable participant non-compliance. In this paper, we review IV estimators for studies in which the outcome is binary. Recent work on identification is interpreted using an integrated structural modelling and potential outcomes framework, within which we consider the links between different approaches developed in statistics and econometrics. The implicit assumptions required for bounding causal effects and pointidentification by each estimator are highlighted and compared within our framework. Finally, the implications for practice are discussed.},
	language = {en},
	number = {500},
	urldate = {2022-07-07},
	journal = {Journal of the American Statistical Association},
	author = {Clarke, Paul S. and Windmeijer, Frank},
	month = dec,
	year = {2012},
	pages = {1638--1652},
	file = {Clarke et Windmeijer - 2012 - Instrumental Variable Estimators for Binary Outcom.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\MLMFP7I7\\Clarke et Windmeijer - 2012 - Instrumental Variable Estimators for Binary Outcom.pdf:application/pdf},
}

@article{liang_selecting_nodate,
	title = {Selecting {Valid} {Instrumental} {Variables} in {Linear} {Models} with {Multiple} {Exposure} {Variables}: {Adaptive} {Lasso} and the {Median}-of-{Medians} {Estimator}},
	abstract = {In a linear instrumental variables (IV) setting for estimating the causal eﬀects of multiple confounded exposure/treatment variables on an outcome, we investigate the adaptive Lasso method for selecting valid instrumental variables from a set of available instruments that may contain invalid ones. An instrument is invalid if it fails the exclusion conditions and enters the model as an explanatory variable. We extend the results as developed in Windmeijer et al. (2019) for the single exposure model to the multiple exposures case. In particular we propose a median-of-medians estimator and show that the conditions on the minimum number of valid instruments under which this estimator is consistent for the causal eﬀects are only moderately stronger than the simple majority rule that applies to the median estimator for the single exposure case. The adaptive Lasso method which uses the initial median-ofmedians estimator for the penalty weights achieves consistent selection with oracle properties of the resulting IV estimator. This is conﬁrmed by some Monte Carlo simulation results. We apply the method to estimate the causal eﬀects of educational attainment and cognitive ability on body mass index (BMI) in a Mendelian Randomization setting.},
	language = {en},
	author = {Liang, Xiaoran and Sanderson, Eleanor and Windmeijer, Frank},
	pages = {30},
	file = {Liang et al. - Selecting Valid Instrumental Variables in Linear M.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\Y6QYA8WD\\Liang et al. - Selecting Valid Instrumental Variables in Linear M.pdf:application/pdf},
}

@article{conley_plausibly_2012,
	title = {{PLAUSIBLY} {EXOGENOUS}},
	volume = {94},
	issn = {0034-6535},
	url = {https://www.jstor.org/stable/41349174},
	abstract = {Instrumental variable (IV) methods are widely used to identify causal effects in models with endogenous explanatory variables. Often the instrument exclusion restriction that underlies the validity of the usual IV inference is suspect; that is, instruments are only plausibly exogenous. We present practical methods for performing inference while relaxing the exclusion restriction. We illustrate the approaches with empirical examples that examine the effect of 401(k) participation on asset accumulation, price elasticity of demand for margarine, and returns to schooling. We find that inference is informative even with a substantial relaxation of the exclusion restriction in two of the three cases.},
	number = {1},
	urldate = {2022-07-21},
	journal = {The Review of Economics and Statistics},
	author = {Conley, Timothy G. and Hansen, Christian B. and Rossi, Peter E.},
	year = {2012},
	note = {Publisher: The MIT Press},
	pages = {260--272},
	file = {JSTOR Full Text PDF:C\:\\Users\\Hippo\\Zotero\\storage\\CAVMELZN\\Conley et al. - 2012 - PLAUSIBLY EXOGENOUS.pdf:application/pdf},
}

@article{maasoumi_behavior_1982,
	title = {On the behavior of inconsistent instrumental variable estimators},
	volume = {19},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/030440768290001X},
	doi = {10.1016/0304-4076(82)90001-X},
	language = {en},
	number = {2-3},
	urldate = {2022-08-15},
	journal = {Journal of Econometrics},
	author = {Maasoumi, Esfandiar and Phillips, Peter C.B.},
	month = aug,
	year = {1982},
	pages = {183--201},
	file = {Maasoumi et Phillips - 1982 - On the behavior of inconsistent instrumental varia.pdf:C\:\\Users\\Hippo\\Zotero\\storage\\QRZTEJTU\\Maasoumi et Phillips - 1982 - On the behavior of inconsistent instrumental varia.pdf:application/pdf},
}
